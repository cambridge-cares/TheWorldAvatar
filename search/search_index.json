{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to twa","text":""},{"location":"#what-is-twa","title":"What is <code>twa</code>","text":"<p><code>twa</code> is a Python wrapper for TheWorldAvatar project. The code is heavily based on the py4j package, which enables Python programs running in a Python interpreter to dynamically access Java objects in a Java Virtual Machine. It has a precedent python package, <code>py4jps</code>, which is now deprecated.</p>"},{"location":"#notes-to-developers","title":"Notes to developers","text":"<p>The aim of <code>twa</code> is to provide Python access to the Java classes and methods in <code>TheWorldAvatar</code> project. The Python-Java communication, handled by the py4j package, happens via the local network sockets. The main interaction point between a Python and Java is provided by the py4j.java_gateway.JavaGateway class. This class is wrapped within the <code>twa.JPSGateway</code> class for convenience. The <code>JPSGateway</code> class is the parent class for any installed java resources that one wishes to access. Although, it is not recommended to use it directly, the <code>JPSGateway</code> class can be useful in experimenting with different resources without installing them first, as it allows to change the resources at runtime.</p> <p>However, it is important to understand that not all <code>TheWorldAvatar</code> classes/functions in Java are provided with a high-level abstraction in <code>twa</code>. Therefore, the java project documentation should also be consulted with to know which Java objects to call to perform a desired task. Additionally, not all <code>TheWorldAvatar</code> classes can be accessed. Namely, any servlet depending classes can not be instantiated in Python without running the Apache Tomcat server first. Since this has not been tested, it is not guaranteed that running the Apache Tomcat server would fix the problem. However, this should not be an issue for the <code>twa</code> users, given that the main purpose of the wrapper is to use the client-side <code>TheWorldAvatar</code> Java code to perform knowledge graph operations (e.g. queries and updates). Should the developers wish to develop agents (server-side code which normally developed in Java) in Python using <code>twa</code>, the native Python class <code>DerivationAgent</code> should be used.</p>"},{"location":"#authors","title":"Authors","text":"<p>Jiaru Bai</p> <p>Daniel Nurkowski</p>"},{"location":"contributing/","title":"Contributing","text":"<p>Collaboration is at the heart of The World Avatar project. For details, please visit the contributing guide.</p>"},{"location":"contributing/#package-release","title":"Package release","text":"<p>NOTE: Before making the package release, please remove all sub-folders and <code>resources_registry.json</code> file in <code>python_wrapper/twa/resources</code> folder to prevent incorrect packing of Java resources. For more information, please refer to this issue.</p> <p>Maintainers who package and publish the most up-to-date codes from the feature branches handle the distribution of package <code>twa</code> on PyPI and Test-PyPI. If you want to release the package independently, i.e. become a maintainer, please contact the repository's administrator to indicate your interest.</p> <p>The release procedure is currently semi-automated and requires a few items:</p> <ul> <li>Your Test-PyPI and PyPI account and password</li> <li>The version number x.x.x for the release</li> <li>Clone of <code>TheWorldAvatar</code> repository on your local machine</li> <li>The feature branch you are working on is ready to be merged back to the main branch (a Pull Request should already be created and reviewed by a senior developer)</li> </ul> <p>Please merge the newest main branch to your feature branch once these details are ready. The release process can then be started by using the commands below, depending on the operating system you're using.</p> <p>REMEMBER TO CHANGE THE CORRECT VALUES IN THE COMMANDS BELOW!</p> <p><code>(Windows)</code></p> <pre><code>cd \\absolute_path_to\\TheWorldAvatar\\JPS_BASE_LIB\\python_wrapper\nrelease_twa_to_pypi.sh -v x.x.x\n</code></pre> <p><code>(Linux)</code> <pre><code>cd /absolute_path_to/TheWorldAvatar/JPS_BASE_LIB/python_wrapper\n./release_twa_to_pypi.sh -v x.x.x\n</code></pre></p> <p>Please follow the instructions presented in the console once the process has begun. If everything goes well, two changes should be done automatically during the release process, specifically in python script <code>JPS_BASE_LIB/python_wrapper/twa/__init__.py</code> <pre><code>__version__ = \"x.x.x\"\n</code></pre></p> <p>and <code>JPS_BASE_LIB/python_wrapper/setup.py</code> <pre><code>version='x.x.x',\n</code></pre></p> <p>where <code>x.x.x</code> matches the version number used in your release.</p> <p>These two changes should be committed to the feature branch.</p> <p>Finally, merge the Pull Request of the feature branch back into the <code>main</code> branch.</p>"},{"location":"install/","title":"Installation","text":""},{"location":"install/#prerequisite","title":"Prerequisite","text":"<ul> <li>You need Python &gt;=3.8 to run the <code>twa</code>. You can install Python by going to the official Python download page</li> <li>You also need to install a Java Runtime Environment version 11</li> </ul>"},{"location":"install/#virtual-environment-setup","title":"Virtual environment setup","text":"<p>It is highly recommended to use a virtual environment before installing the <code>twa</code> package. The virtual environment can be created as follows:</p> <p><code>(Windows)</code></p> <pre><code>python -m venv twa_venv\ntwa_venv\\Scripts\\activate.bat\n</code></pre> <p><code>(Linux)</code> <pre><code>python3 -m venv twa_venv\nsource twa_venv/bin/activate\n</code></pre></p> <p>The above commands will create and activate the virtual environment <code>twa_venv</code> in the current directory. The terminal display for new commands will be as follows (to facilitate direct copying and pasting of commands from this documentation into the command line, the virtual environment prefix will be omitted throughout the remainder of the documentation): <pre><code>(twa_venv) $\n</code></pre></p> <p>Alternatively, if one wish to use conda for managing environments, please follow the instructions provided on the conda website.</p>"},{"location":"install/#installation-via-pip","title":"Installation via pip","text":"<p>To install the <code>twa</code> simply run the following command:</p> <pre><code>pip install twa\n</code></pre> <p>The above command will install the <code>twa</code> package including the <code>JpsBaseLib</code> Java library that has been packaged together with the Python code.</p>"},{"location":"install/#for-developers-installation-from-the-version-controlled-source","title":"[For developers] Installation from the version-controlled source","text":"<p>This type of installation is only for the developers. To install <code>twa</code> directly from its repository you need to first clone the <code>TheWorldAvatar</code> project. Then simply navigate to the <code>TheWorldAvatar\\JPS_BASE_LIB\\python_wrapper</code> directory and execute the following commands: <pre><code># build and install\npip install .\n\n# or build for in-place development\npip install -e .\n\n# or use the provided \"install_wrapper.sh\" convenience script,\n# that can create virtual environment and install the twa package in one go\n# build and install\ninstall_wrapper.sh -v -i\n# or build for in-place development\ninstall_wrapper.sh -v -i -e\n</code></pre></p> <p>The above commands will install the <code>twa</code> Python package only. To include the JpsBaseLib Java library, i.e. the <code>JPS_BASE_LIB</code> library, please follow the below steps:</p> <ol> <li>Navigate to the <code>TheWorldAvatar\\JPS_BASE_LIB</code> directory and build the <code>JPS_BASE_LIB</code> project: <pre><code>mvn clean install -DskipTests\n</code></pre></li> <li>Go to the <code>JPS_BASE_LIB/target</code> directory and copy the main project jar file, <code>jps-base-lib.jar</code>, and the entire <code>lib</code> folder containing the project dependencies into a temporary directory, let us call it <code>tmp_JpsBaseLib</code>.</li> <li>Run the following command in the terminal (with the virtual environment where <code>twa</code> is installed activated, e.g. <code>twa_venv</code>): <pre><code>jpsrm install JpsBaseLib &lt;path_to_the_tmp_JpsBaseLib_directory&gt; --jar jps-base-lib.jar\n</code></pre></li> <li>After successful installation you can access the <code>JpsBaseLib</code> resource (classes and methods) in <code>twa</code> by simply importing it: <pre><code>from twa.resources import JpsBaseLib\n</code></pre></li> <li>Remove the no longer needed <code>tmp_JpsBaseLib</code> directory.</li> </ol>"},{"location":"install/#for-developers-installing-additional-java-resources","title":"[For developers] Installing additional java resources","text":"<p>The <code>twa</code> project can be easily extended to provide wrapping for other <code>TheWorldAvatar</code> java projects. To do that, all resource files and their dependencies must be collated into a single directory, with the main jar file located at the directory root. The <code>JpsBaseLib pom.xml</code> file shows an example of how to do it with maven. If you wish to do it for other <code>TheWorldAvatar</code> project, simply copy the <code>maven-jar-plugin</code> and <code>maven-dependency-plugin</code> plugins into the project pom file and add the <code>net.sf.py4j</code> dependency. These changes will collate all the project dependencies into the <code>target\\lib</code> directory and include the required <code>py4j</code> package in your project. Once that is done and the project is successfully built, the <code>twa</code> resource manager command-line utility, <code>jpsrm</code>, can be used to install and register the resource. Here are the steps:</p> <ol> <li>Copy the project main jar file and the entire <code>lib</code> folder a temporary directory, e.g., <code>tmp_dir</code>.</li> <li>Run the following command in the terminal (with the virtual environment where <code>twa</code> is installed activated, e.g. <code>twa_venv</code>): <pre><code>jpsrm install &lt;YourResourceName&gt; &lt;from&gt; --jar JARFILE\n</code></pre> where <code>jpsrm</code> is the <code>twa</code> resource manager, <code>&lt;YourResourceName&gt;</code> is the name you wish to assign to your java resource, e.g. <code>JpsBaseLib</code> in the previous section. The <code>&lt;from&gt;</code> argument is the absolute path to the <code>tmp_dir</code> with all the java project files and the <code>--jar</code> option is used to provide a name of the main jar file, <code>JARFILE</code>, to be used for communication. <p>NOTE that the <code>&lt;YourResourceName&gt;</code> MUST follow Python's classes names requirements, otherwise it will be impossible to import it in Python.</p> </li> <li>After the successful installation you can access the resource (classes and methods) in <code>twa</code> by simply importing it: <pre><code>from twa.resources import YourResourceName\n</code></pre></li> <li>Remove the no longer needed <code>tmp_dir</code> directory.</li> </ol>"},{"location":"install/#for-developer-jpsrm-resource-manager","title":"[For developer] <code>jpsrm</code> resource manager","text":"<p><code>jpsrm</code> is a resource manager to effectively manage the Java packages in <code>twa</code>. To see all <code>jpsrm</code> commands and options, run <code>jpsrm -h</code> in the terminal.</p> <p>NOTE The <code>jpsrm</code> includes a developer-only convenience command <code>devinstall</code> which will run all the installation steps for the <code>JpsBaseLib</code> resource. The command will only work if:  - the <code>JPS_BASE_LIB</code> project is present and was successfully built  - the <code>twa</code> project was installed in a developer mode (-e option) inside the <code>TheWorldAvatar</code> repository</p> <p>Here is how to execute the <code>devinstall</code> command:</p> <pre><code># execute devinstall\njpsrm devinstall\n</code></pre>"},{"location":"wishlist/","title":"Bug reports/feature requests","text":"<p>To report bugs or request features, please post it as a new issue in TWA GitHub Issues with a <code>python-wrapper</code> label.</p> <p>For existing (and previous) issues/feature requests, plese check here.</p>"},{"location":"api/base_ontology/","title":"BaseOntology","text":"<p>Here we provide base data models that can be used to define new ontologies. The base data models are classes which inherit from pydantic.BaseModel and define fields as annotated attributes.</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.T","title":"T  <code>module-attribute</code>","text":"<pre><code>T = TypeVar('T')\n</code></pre> <p>A type variable to represent any type in Python. This is used as placeholder for any concept in the ontologies.</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph","title":"KnowledgeGraph","text":"<p>               Bases: <code>BaseModel</code></p> <p>This class is used to represent a knowledge graph consists of Pydantic objects in the Python memory.</p> <p>Attributes:</p> Name Type Description <code>ontology_lookup</code> <code>Dict[str, BaseOntology]</code> <p>A class variable to store the lookup dictionary of ontologies</p> <code>class_lookup</code> <code>Dict[str, BaseClass]</code> <p>A class variable to store the lookup dictionary of classes</p> <code>property_lookup</code> <code>Dict[str, BaseProperty]</code> <p>A class variable to store the lookup dictionary of properties</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph.graph","title":"graph  <code>classmethod</code>","text":"<pre><code>graph() -&gt; Graph\n</code></pre> <p>This method is used to retrieve the knowledge graph in Python memory.</p> <p>Returns:</p> Name Type Description <code>Graph</code> <code>Graph</code> <p>The rdflib.Graph object of the knowledge graph</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef graph(cls) -&gt; Graph:\n    \"\"\"\n    This method is used to retrieve the knowledge graph in Python memory.\n\n    Returns:\n        Graph: The rdflib.Graph object of the knowledge graph\n    \"\"\"\n    g = Graph()\n    for iri, o in cls.construct_object_lookup().items():\n        g += o.graph()\n    return g\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph.all_triples_of_nodes","title":"all_triples_of_nodes  <code>classmethod</code>","text":"<pre><code>all_triples_of_nodes(iris: Union[str, list]) -&gt; Graph\n</code></pre> <p>This method is used to retrieve all (in-coming and out-going) triples of the given nodes in the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>iris</code> <code>str or list</code> <p>The IRI of the nodes to be retrieved</p> required <p>Returns:</p> Name Type Description <code>Graph</code> <code>Graph</code> <p>The rdflib.Graph object of the triples of the given nodes</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef all_triples_of_nodes(cls, iris: Union[str, list]) -&gt; Graph:\n    \"\"\"\n    This method is used to retrieve all (in-coming and out-going) triples of the given nodes in the knowledge graph.\n\n    Args:\n        iris (str or list): The IRI of the nodes to be retrieved\n\n    Returns:\n        Graph: The rdflib.Graph object of the triples of the given nodes\n    \"\"\"\n    # ensure iris is a list\n    if isinstance(iris, str):\n        iris = [iris]\n\n    # convert strings to URIRef if necessary\n    iris = [URIRef(iri) if isinstance(iri, str) else iri for iri in iris]\n\n    source_g = cls.graph()\n    result_g = Graph()\n\n    # add triples to result_graph\n    for iri in iris:\n        for triple in source_g.triples((iri, None, None)):\n            result_g.add(triple)\n        for triple in source_g.triples((None, None, iri)):\n            result_g.add(triple)\n    return result_g\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph.construct_object_lookup","title":"construct_object_lookup  <code>classmethod</code>","text":"<pre><code>construct_object_lookup() -&gt; Dict[str, BaseClass]\n</code></pre> <p>This method is used to retrieve all BaseClass (pydantic) objects created in Python memory.</p> <p>Returns:</p> Type Description <code>Dict[str, BaseClass]</code> <p>A dictionary of BaseClass (pydantic) objects with their IRIs as keys</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef construct_object_lookup(cls) -&gt; Dict[str, BaseClass]:\n    \"\"\"\n    This method is used to retrieve all BaseClass (pydantic) objects created in Python memory.\n\n    Returns:\n        A dictionary of BaseClass (pydantic) objects with their IRIs as keys\n    \"\"\"\n    if cls.class_lookup is None:\n        return {}\n    return {i: o for clz in cls.class_lookup.values() if bool(clz.object_lookup) for i, o in clz.object_lookup.items()}\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph.get_object_from_lookup","title":"get_object_from_lookup  <code>classmethod</code>","text":"<pre><code>get_object_from_lookup(iri: str) -&gt; Union[BaseClass, None]\n</code></pre> <p>This method is used to retrieve an object from Python memory given its IRI.</p> <p>Parameters:</p> Name Type Description Default <code>iri</code> <code>str</code> <p>IRI of the object to be retrieved</p> required <p>Returns:</p> Type Description <code>Union[BaseClass, None]</code> <p>The pydantic object of the given IRI if exist, otherwise return None.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef get_object_from_lookup(cls, iri: str) -&gt; Union[BaseClass, None]:\n    \"\"\"\n    This method is used to retrieve an object from Python memory given its IRI.\n\n    Args:\n        iri (str): IRI of the object to be retrieved\n\n    Returns:\n        The pydantic object of the given IRI if exist, otherwise return None.\n    \"\"\"\n    return cls.construct_object_lookup().get(iri, None)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.KnowledgeGraph.clear_object_lookup","title":"clear_object_lookup  <code>classmethod</code>","text":"<pre><code>clear_object_lookup()\n</code></pre> <p>This method is used to clear the object lookup dictionary in Python memory.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef clear_object_lookup(cls):\n    \"\"\" This method is used to clear the object lookup dictionary in Python memory. \"\"\"\n    for cls in cls.class_lookup.values():\n        cls.clear_object_lookup()\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology","title":"BaseOntology","text":"<p>               Bases: <code>BaseModel</code></p> <p>This class is used to represent an ontology which consists of a list of BaseClass and ObjectProperty/DatatypeProperty.</p> <p>Attributes:</p> Name Type Description <code>base_url</code> <code>str</code> <p>The base URL to be used to construct the namespace IRI, the default value is 'https://www.theworldavatar.com/kg/'</p> <code>namespace</code> <code>str</code> <p>The namespace of the ontology, e.g. 'ontolab'</p> <code>namespace_iri</code> <code>str</code> <p>The namespace IRI of the ontology, e.g. 'https://www.theworldavatar.com/kg/ontolab'</p> <code>class_lookup</code> <code>Dict[str, BaseClass]</code> <p>A dictionary of BaseClass classes with their rdf:type as keys</p> <code>object_property_lookup</code> <code>Dict[str, ObjectProperty]</code> <p>A dictionary of ObjectProperty classes with their predicate IRI as keys</p> <code>data_property_lookup</code> <code>Dict[str, DatatypeProperty]</code> <p>A dictionary of DatatypeProperty classes with their predicate IRI as keys</p> <code>rdfs_comment</code> <code>Set[str]</code> <p>The comment of the ontology</p> <code>owl_versionInfo</code> <code>str</code> <p>The version of the ontology</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.is_dev_mode","title":"is_dev_mode  <code>classmethod</code>","text":"<pre><code>is_dev_mode()\n</code></pre> <p>This method returns whether the KnowledgeGraph is in development mode.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef is_dev_mode(cls):\n    \"\"\"This method returns whether the KnowledgeGraph is in development mode.\"\"\"\n    return cls._dev_mode\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.set_dev_mode","title":"set_dev_mode  <code>classmethod</code>","text":"<pre><code>set_dev_mode()\n</code></pre> <p>This method sets the KnowledgeGraph to development mode, where duplicate class or property registration will be allowed that the existing ones will be overwritten.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef set_dev_mode(cls):\n    \"\"\"This method sets the KnowledgeGraph to development mode, where duplicate class or property registration will be allowed that the existing ones will be overwritten.\"\"\"\n    cls._dev_mode = True\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.set_prod_mode","title":"set_prod_mode  <code>classmethod</code>","text":"<pre><code>set_prod_mode()\n</code></pre> <p>This method sets the KnowledgeGraph to production mode, where duplicate class or property registration will raise an error.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef set_prod_mode(cls):\n    \"\"\"This method sets the KnowledgeGraph to production mode, where duplicate class or property registration will raise an error.\"\"\"\n    cls._dev_mode = False\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.export_to_graph","title":"export_to_graph  <code>classmethod</code>","text":"<pre><code>export_to_graph(g: Graph = None) -&gt; Graph\n</code></pre> <p>This method is used to export the ontology to a rdflib.Graph object. It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The rdflib.Graph object to which the ontology will be exported</p> <code>None</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef export_to_graph(cls, g: Graph = None) -&gt; Graph:\n    \"\"\"\n    This method is used to export the ontology to a rdflib.Graph object.\n    It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.\n\n    Args:\n        g (Graph): The rdflib.Graph object to which the ontology will be exported\n    \"\"\"\n    if g is None:\n        g = Graph()\n    # metadata\n    g.add((URIRef(cls.namespace_iri), RDF.type, OWL.Ontology))\n    g.add((URIRef(cls.namespace_iri), DC.date, Literal(datetime.now().isoformat())))\n    if bool(cls.rdfs_comment):\n        if isinstance(cls.rdfs_comment, str):\n            g.add((URIRef(cls.namespace_iri), RDFS.comment, Literal(cls.rdfs_comment)))\n        elif isinstance(cls.rdfs_comment, set):\n            for comment in cls.rdfs_comment:\n                g.add((URIRef(cls.namespace_iri), RDFS.comment, Literal(comment)))\n    if bool(cls.owl_versionInfo):\n        g.add((URIRef(cls.namespace_iri), OWL.versionInfo, Literal(cls.owl_versionInfo)))\n    # handle all classes\n    if bool(cls.class_lookup):\n        for clz in cls.class_lookup.values():\n            g = clz._export_to_owl(g)\n    # handle all object and data properties\n    property_domain_range_lookup = KnowledgeGraph._construct_property_domain_range_lookup()\n    if bool(cls.object_property_lookup):\n        for prop in cls.object_property_lookup.values():\n            g = prop._export_to_owl(\n                g,\n                property_domain_range_lookup.get(prop.predicate_iri, {'rdfs_domain': set()})['rdfs_domain'],\n                property_domain_range_lookup.get(prop.predicate_iri, {'rdfs_range': set()})['rdfs_range'],\n            )\n    # handle all data properties\n    if bool(cls.data_property_lookup):\n        for prop in cls.data_property_lookup.values():\n            g = prop._export_to_owl(\n                g,\n                property_domain_range_lookup.get(prop.predicate_iri, {'rdfs_domain': set()})['rdfs_domain'],\n                property_domain_range_lookup.get(prop.predicate_iri, {'rdfs_range': set()})['rdfs_range'],\n            )\n\n    return g\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.export_to_triple_store","title":"export_to_triple_store  <code>classmethod</code>","text":"<pre><code>export_to_triple_store(sparql_client: PySparqlClient)\n</code></pre> <p>This method is used to export the ontology to a triplestore. It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.</p> <p>Parameters:</p> Name Type Description Default <code>sparql_client</code> <code>PySparqlClient</code> <p>The PySparqlClient object that connects to the triplestore</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef export_to_triple_store(cls, sparql_client: PySparqlClient):\n    \"\"\"\n    This method is used to export the ontology to a triplestore.\n    It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.\n\n    Args:\n        sparql_client (PySparqlClient): The PySparqlClient object that connects to the triplestore\n    \"\"\"\n    g = cls.export_to_graph()\n\n    # upload to triplestore\n    sparql_client.upload_graph(g)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseOntology.export_to_owl","title":"export_to_owl  <code>classmethod</code>","text":"<pre><code>export_to_owl(file_path: str, format: str = 'ttl')\n</code></pre> <p>This method is used to export the ontology to an ontology file. It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The path of the ontology file to be exported to</p> required <code>format</code> <code>str</code> <p>The format of the ontology file, the default value is 'ttl'</p> <code>'ttl'</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef export_to_owl(cls, file_path: str, format: str = 'ttl'):\n    \"\"\"\n    This method is used to export the ontology to an ontology file.\n    It operates at the TBox level, i.e. it only exports the classes and properties of the ontology.\n\n    Args:\n        file_path (str): The path of the ontology file to be exported to\n        format (str): The format of the ontology file, the default value is 'ttl'\n    \"\"\"\n    g = cls.export_to_graph()\n\n    # serialize\n    g.serialize(destination=file_path, format=format)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseProperty","title":"BaseProperty","text":"<pre><code>BaseProperty(*args, **kwargs)\n</code></pre> <p>               Bases: <code>set</code>, <code>Generic[T]</code></p> <p>Base class that is inherited by ObjectProperty and DatatypeProperty.</p> <p>Attributes:</p> Name Type Description <code>rdfs_isDefinedBy</code> <code>Type[BaseOntology]</code> <p>The ontology that defines the property</p> <code>predicate_iri</code> <code>str</code> <p>The predicate IRI of the property</p> <code>owl_minQualifiedCardinality</code> <code>int</code> <p>The minimum qualified cardinality of the property (default is 0)</p> <code>owl_maxQualifiedCardinality</code> <code>int</code> <p>The maximum qualified cardinality of the property (default is None, meaning infinite)</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseProperty.retrieve_cardinality","title":"retrieve_cardinality  <code>classmethod</code>","text":"<pre><code>retrieve_cardinality() -&gt; Tuple[int, int]\n</code></pre> <p>This method is used to retrieve the cardinality of the property.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: The minimum and maximum cardinality of the property</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef retrieve_cardinality(cls) -&gt; Tuple[int, int]:\n    \"\"\"\n    This method is used to retrieve the cardinality of the property.\n\n    Returns:\n        Tuple[int, int]: The minimum and maximum cardinality of the property\n    \"\"\"\n    return cls.owl_minQualifiedCardinality, cls.owl_maxQualifiedCardinality\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseProperty.create_from_base","title":"create_from_base  <code>classmethod</code>","text":"<pre><code>create_from_base(class_name: str, ontology: Type[BaseOntology], min_cardinality: Optional[int] = 0, max_cardinality: Optional[int] = None) -&gt; Type[BaseProperty]\n</code></pre> <p>This method is used to create a new property class from the calling class. The new property class will inherit the min and max cardinality from the calling class if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>class_name</code> <code>str</code> <p>The name of the new property class</p> required <code>ontology</code> <code>Type[BaseOntology]</code> <p>The ontology that defines the property</p> required <code>min_cardinality</code> <code>Optional[int]</code> <p>The minimum qualified cardinality of the property (defaults to 0)</p> <code>0</code> <code>max_cardinality</code> <code>Optional[int]</code> <p>The maximum qualified cardinality of the property (defaults to None meaning infinite)</p> <code>None</code> <p>Returns:</p> Type Description <code>Type[BaseProperty]</code> <p>Type[BaseProperty]: The new property class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef create_from_base(\n    cls,\n    class_name: str,\n    ontology: Type[BaseOntology],\n    min_cardinality: Optional[int] = 0,\n    max_cardinality: Optional[int] = None,\n) -&gt; Type[BaseProperty]:\n    \"\"\"\n    This method is used to create a new property class from the calling class.\n    The new property class will inherit the min and max cardinality from the calling class if not specified.\n\n    Args:\n        class_name (str): The name of the new property class\n        ontology (Type[BaseOntology]): The ontology that defines the property\n        min_cardinality (Optional[int], optional): The minimum qualified cardinality of the property (defaults to 0)\n        max_cardinality (Optional[int], optional): The maximum qualified cardinality of the property (defaults to None meaning infinite)\n\n    Returns:\n        Type[BaseProperty]: The new property class\n    \"\"\"\n    # NOTE we inherit cardinality from the calling cls if not specified\n    return type(class_name, (cls,), {\n        'rdfs_isDefinedBy': ontology,\n        'owl_minQualifiedCardinality': min_cardinality if bool(min_cardinality) else cls.owl_minQualifiedCardinality,\n        'owl_maxQualifiedCardinality': max_cardinality if bool(max_cardinality) else cls.owl_maxQualifiedCardinality,\n    })\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass","title":"BaseClass","text":"<pre><code>BaseClass(**data)\n</code></pre> <p>               Bases: <code>BaseModel</code></p> <p>Base class for all the Python classes that are used to define the classes in ontology.</p> <p>Attributes:</p> Name Type Description <code>rdfs_isDefinedBy</code> <code>BaseOntology</code> <p>The ontology that defines the class</p> <code>rdf_type</code> <code>str</code> <p>The rdf:type of the class</p> <code>object_lookup</code> <code>Dict[str, BaseClass]</code> <p>A dictionary that maps the IRI of the object to the object</p> <code>rdfs_comment</code> <code>str</code> <p>The comment of the instance</p> <code>rdfs_label</code> <code>str</code> <p>The label of the instance</p> <code>instance_iri</code> <code>str</code> <p>The IRI of the instance</p> <p>Example: class MyClass(BaseClass):     myObjectProperty: MyObjectProperty[MyOtherClass]     myDatatypeProperty: MyDatatypeProperty[str]</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def __init__(self, **data):\n    # handle the case when rdfs_comment and rdfs_label are provided as a non-set value\n    if 'rdfs_comment' in data and not isinstance(data['rdfs_comment'], set):\n        if isinstance(data['rdfs_comment'], list):\n            data['rdfs_comment'] = set(data['rdfs_comment'])\n        else:\n            data['rdfs_comment'] = {data['rdfs_comment']}\n    if 'rdfs_label' in data and not isinstance(data['rdfs_label'], set):\n        if isinstance(data['rdfs_label'], list):\n            data['rdfs_label'] = set(data['rdfs_label'])\n        else:\n            data['rdfs_label'] = {data['rdfs_label']}\n    super().__init__(**data)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.rdfs_isDefinedBy","title":"rdfs_isDefinedBy  <code>class-attribute</code>","text":"<pre><code>rdfs_isDefinedBy: BaseOntology = None\n</code></pre> <p>NOTE for all subclasses, one can just use <code>rdfs_isDefinedBy = MyOntology</code>, see this discussion in Pydantic</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.rdf_type","title":"rdf_type  <code>class-attribute</code>","text":"<pre><code>rdf_type: str = OWL_BASE_URL + 'Class'\n</code></pre> <p>NOTE rdf_type is the automatically generated IRI of the class which can also be accessed at the instance level.</p>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.model_post_init","title":"model_post_init","text":"<pre><code>model_post_init(__context: Any) -&gt; None\n</code></pre> <p>The post init process of the BaseClass. It sets the instance_iri if it is not set. It also registers the object to the lookup dictionary of the class.</p> <p>Parameters:</p> Name Type Description Default <code>__context</code> <code>Any</code> <p>Any other context that is needed for the post init process</p> required <p>Returns:</p> Name Type Description <code>None</code> <code>None</code> <p>It calls the super().model_post_init(__context) to finish the post init process</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def model_post_init(self, __context: Any) -&gt; None:\n    \"\"\"\n    The post init process of the BaseClass.\n    It sets the instance_iri if it is not set.\n    It also registers the object to the lookup dictionary of the class.\n\n    Args:\n        __context (Any): Any other context that is needed for the post init process\n\n    Returns:\n        None: It calls the super().model_post_init(__context) to finish the post init process\n    \"\"\"\n    if not bool(self.instance_iri):\n        self.instance_iri = self.__class__.init_instance_iri()\n    # set new instance to the global look up table, so that we can avoid creating the same instance multiple times\n    self._register_object()\n    return super().model_post_init(__context)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.retrieve_subclass","title":"retrieve_subclass  <code>classmethod</code>","text":"<pre><code>retrieve_subclass(iri: str) -&gt; Type[BaseClass]\n</code></pre> <p>This function retrieves the subclass of the current class based on the IRI. If the IRI is the same as the rdf:type of the current class, it will return the current class itself.</p> <p>Parameters:</p> Name Type Description Default <code>iri</code> <code>str</code> <p>The IRI of the subclass</p> required <p>Returns:</p> Type Description <code>Type[BaseClass]</code> <p>Type[BaseClass]: The subclass of the BaseClass</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef retrieve_subclass(cls, iri: str) -&gt; Type[BaseClass]:\n    \"\"\"\n    This function retrieves the subclass of the current class based on the IRI.\n    If the IRI is the same as the rdf:type of the current class, it will return the current class itself.\n\n    Args:\n        iri (str): The IRI of the subclass\n\n    Returns:\n        Type[BaseClass]: The subclass of the BaseClass\n    \"\"\"\n    if iri == cls.rdf_type:\n        return cls\n    return cls.construct_subclass_dictionary()[iri]\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.construct_subclass_dictionary","title":"construct_subclass_dictionary  <code>classmethod</code>","text":"<pre><code>construct_subclass_dictionary() -&gt; Dict[str, Type[BaseClass]]\n</code></pre> <p>This function constructs a dictionary that maps the rdf:type to the subclass of the BaseClass.</p> <p>Returns:</p> Type Description <code>Dict[str, Type[BaseClass]]</code> <p>Dict[str, Type[BaseClass]]: The dictionary that maps the rdf:type to the subclass of the BaseClass</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef construct_subclass_dictionary(cls) -&gt; Dict[str, Type[BaseClass]]:\n    \"\"\"\n    This function constructs a dictionary that maps the rdf:type to the subclass of the BaseClass.\n\n    Returns:\n        Dict[str, Type[BaseClass]]: The dictionary that maps the rdf:type to the subclass of the BaseClass\n    \"\"\"\n    subclass_dict = {}\n    for clz in cls.__subclasses__():\n        subclass_dict[clz.rdf_type] = clz\n        # recursively add the subclass of the subclass\n        subclass_dict.update(clz.construct_subclass_dictionary())\n    return subclass_dict\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.push_all_instances_to_kg","title":"push_all_instances_to_kg  <code>classmethod</code>","text":"<pre><code>push_all_instances_to_kg(sparql_client: PySparqlClient, recursive_depth: int = 0, force_overwrite_local: bool = False)\n</code></pre> <p>This function pushes all the instances of the class to the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>sparql_client</code> <code>PySparqlClient</code> <p>The SPARQL client that is used to push the data to the KG</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion</p> <code>0</code> <code>force_overwrite_local</code> <code>bool</code> <p>Whether to force overwrite the local values with the remote values</p> <code>False</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef push_all_instances_to_kg(\n    cls,\n    sparql_client: PySparqlClient,\n    recursive_depth: int = 0,\n    force_overwrite_local: bool = False,\n):\n    \"\"\"\n    This function pushes all the instances of the class to the knowledge graph.\n\n    Args:\n        sparql_client (PySparqlClient): The SPARQL client that is used to push the data to the KG\n        recursive_depth (int): The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion\n        force_overwrite_local (bool): Whether to force overwrite the local values with the remote values\n    \"\"\"\n    g_to_remove = Graph()\n    g_to_add = Graph()\n    cls.pull_from_kg(cls.object_lookup.keys(), sparql_client, recursive_depth, force_overwrite_local)\n    for obj in cls.object_lookup.values():\n        g_to_remove, g_to_add = obj._collect_diff_to_graph(g_to_remove, g_to_add, recursive_depth)\n    sparql_client.delete_and_insert_graphs(g_to_remove, g_to_add)\n    return g_to_remove, g_to_add\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.clear_object_lookup","title":"clear_object_lookup  <code>classmethod</code>","text":"<pre><code>clear_object_lookup()\n</code></pre> <p>This function clears the lookup dictionary of the class.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef clear_object_lookup(cls):\n    \"\"\"\n    This function clears the lookup dictionary of the class.\n    \"\"\"\n    if cls.object_lookup is not None:\n        iris = list(cls.object_lookup.keys())\n        for i in iris:\n            del cls.object_lookup[i]\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.pull_from_kg","title":"pull_from_kg  <code>classmethod</code>","text":"<pre><code>pull_from_kg(iris: List[str], sparql_client: PySparqlClient, recursive_depth: int = 0, force_overwrite_local: bool = False) -&gt; List[BaseClass]\n</code></pre> <p>This function pulls the objects from the KG based on the given IRIs.</p> <p>Parameters:</p> Name Type Description Default <code>iris</code> <code>List[str]</code> <p>The list of IRIs of the objects that one wants to pull from the KG</p> required <code>sparql_client</code> <code>PySparqlClient</code> <p>The SPARQL client that is used to pull the data from the KG</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion</p> <code>0</code> <code>force_overwrite_local</code> <code>bool</code> <p>Whether to force overwrite the local values with the remote values</p> <code>False</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>The rdf:type of the IRI provided does not match the calling class</p> <p>Returns:</p> Type Description <code>List[BaseClass]</code> <p>List[BaseClass]: A list of objects that are pulled from the KG</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef pull_from_kg(\n    cls,\n    iris: List[str],\n    sparql_client: PySparqlClient,\n    recursive_depth: int = 0,\n    force_overwrite_local: bool = False,\n) -&gt; List[BaseClass]:\n    \"\"\"\n    This function pulls the objects from the KG based on the given IRIs.\n\n    Args:\n        iris (List[str]): The list of IRIs of the objects that one wants to pull from the KG\n        sparql_client (PySparqlClient): The SPARQL client that is used to pull the data from the KG\n        recursive_depth (int): The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion\n        force_overwrite_local (bool): Whether to force overwrite the local values with the remote values\n\n    Raises:\n        ValueError: The rdf:type of the IRI provided does not match the calling class\n\n    Returns:\n        List[BaseClass]: A list of objects that are pulled from the KG\n    \"\"\"\n    if isinstance(iris, str):\n        iris = [iris]\n    iris = set(iris)\n    # if the iris are not provided, then just return empty list\n    if not bool(iris):\n        return []\n    # prepare the list to be returned\n    instance_lst = []\n\n    # check if any of the iris are loading\n    i_loading = set()\n    for i in iris:\n        if KnowledgeGraph._is_iri_been_loading(i):\n            # for those that are loading, use string here and remove it from query\n            instance_lst.append(i)\n            i_loading.add(i)\n        else:\n            # for those that are not loading, indicate they are to be loaded now\n            KnowledgeGraph._add_iri_to_loading(i)\n    iris = iris - i_loading\n\n    # behaviour of recursive_depth: 0 means no recursion, -1 means infinite recursion, n means n-level recursion\n    flag_pull = abs(recursive_depth) &gt; 0\n    recursive_depth = max(recursive_depth - 1, 0) if recursive_depth &gt; -1 else max(recursive_depth - 1, -1)\n    # TODO what do we do with undefined properties in python class? - write a warning message or we can add them to extra_fields https://docs.pydantic.dev/latest/concepts/models/#extra-fields\n    # return format: {iri: {predicate: {object}}}\n    node_dct = sparql_client.get_outgoing_and_attributes(iris)\n    for iri, props in node_dct.items():\n        # TODO optimise the time complexity of the following code when the number of instances is large\n        # check if the rdf:type of the instance matches the calling class or any of its subclasses\n        target_clz_rdf_types = set(props.get(RDF.type.toPython(), [])) # NOTE this supports instance instantiated with multiple rdf:type\n        if not target_clz_rdf_types:\n            raise ValueError(f\"The instance {iri} has no rdf:type, retrieved outgoing links and attributes: {props}.\")\n        cls_subclasses = set(cls.construct_subclass_dictionary().keys())\n        cls_subclasses.add(cls.rdf_type)\n        intersection = target_clz_rdf_types &amp; cls_subclasses\n        if intersection:\n            if len(intersection) == 1:\n                target_clz_rdf_type = next(iter(intersection))\n            else:\n                # NOTE instead of using the first element of the intersection\n                # we find the deepest subclass as target_clz_rdf_type\n                # so that the created object could inherite all the properties of its parent classes\n                # which prevents the loss of information\n                parent_classes = set()\n                for c in intersection:\n                    if c in parent_classes:\n                        # skip if it's already a parent class\n                        continue\n                    for other in intersection:\n                        if other != c and issubclass(cls.retrieve_subclass(c), cls.retrieve_subclass(other)):\n                            parent_classes.add(other)\n                deepest_subclasses = intersection - parent_classes\n                if len(deepest_subclasses) &gt; 1:\n                    # TODO [future] add support for allowing users to specify the target class\n                    KnowledgeGraph._remove_iri_from_loading(iri)\n                    raise ValueError(\n                        f\"\"\"The instance {iri} is of type {target_clz_rdf_types}.\n                        Amongst the pulling class {cls.__name__} ({cls.rdf_type})\n                        and its subclasses ({cls.construct_subclass_dictionary()}),\n                        there exist classes that are not in the same branch of the inheritance tree,\n                        including {deepest_subclasses},\n                        therefore it cannot be instantiated by pulling with class {cls.__name__}.\n                        Please consider pulling the instance directly with one of the class in {deepest_subclasses}\n                        Alternatively, please check the inheritance tree is correctly defined in Python.\"\"\")\n                else:\n                    target_clz_rdf_type = next(iter(deepest_subclasses))\n        else:\n            # if there's any error, remove the iri from the loading status\n            # otherwise it will block any further pulling of the same object\n            KnowledgeGraph._remove_iri_from_loading(iri)\n            raise ValueError(\n                f\"\"\"The instance {iri} is of type {target_clz_rdf_types},\n                it doesn't match the rdf:type of class {cls.__name__} ({cls.rdf_type}),\n                nor any of its subclasses ({cls.construct_subclass_dictionary()}),\n                therefore it cannot be instantiated.\"\"\")\n        inst = KnowledgeGraph.get_object_from_lookup(iri)\n        # obtain the target class in case it is a subclass\n        target_clz = cls.retrieve_subclass(target_clz_rdf_type)\n        # rebuild the model in case there're any ForwardRef that were not resolved previously\n        target_clz.model_rebuild()\n\n        # instead of calling cls.get_object_properties() and cls.get_data_properties()\n        # calling methods of target_clz ensures that all properties are correctly inherited\n        ops = target_clz.get_object_properties()\n        dps = target_clz.get_data_properties()\n        # handle object properties (where the recursion happens)\n        # the situation where two instances pointing to each other (or if there's circular nodes)\n        #   is enabled by stopping pulling at KnowledgeGraph.iri_loading_in_progress\n        # here object_properties_dict is a fetch of the remote KG\n        object_properties_dict = {}\n        for op_iri, op_dct in ops.items():\n            _set = set()\n            if op_iri in props:\n                if flag_pull:\n                    c_tp: BaseClass = get_args(op_dct['type'])[0]\n                    _set = c_tp.pull_from_kg(props[op_iri], sparql_client, recursive_depth, force_overwrite_local)\n                else:\n                    _set = set(props[op_iri])\n            object_properties_dict[op_dct['field']] = _set\n        # here we handle data properties (data_properties_dict is a fetch of the remote KG)\n        data_properties_dict = {}\n        for dp_iri, dp_dct in dps.items():\n            if dp_iri in props:\n                # here we need to convert the data property to the correct type\n                _dp_tp = get_args(dp_dct['type'])[0]\n                data_properties_dict[dp_dct['field']] = set([_dp_tp(_) for _ in props[dp_iri]])\n            else:\n                data_properties_dict[dp_dct['field']] = set()\n        # handle rdfs:label and rdfs:comment (also fetch of the remote KG)\n        rdfs_properties_dict = {}\n        if RDFS.label.toPython() in props:\n            rdfs_properties_dict['rdfs_label'] = set(list(props[RDFS.label.toPython()]))\n        if RDFS.comment.toPython() in props:\n            rdfs_properties_dict['rdfs_comment'] = set(list(props[RDFS.comment.toPython()]))\n        # instantiate the object\n        if inst is not None and type(inst) is target_clz:\n            for op_iri, op_dct in ops.items():\n                if flag_pull:\n                    # below lines pull those object properties that are NOT connected in the remote KG,\n                    # but are connected in the local python memory\n                    # e.g. object `a` has a field `to_b` that points to object `b`\n                    # but triple &lt;a&gt; &lt;to_b&gt; &lt;b&gt; does not exist in the KG\n                    # this code then ensures the cache of object `b` is accurate\n                    # TODO [future] below query can be combined with those connected in the KG to save amount of queries\n                    c_tp: BaseClass = get_args(op_dct['type'])[0]\n                    _o = getattr(inst, op_dct['field']) if getattr(inst, op_dct['field']) is not None else set()\n                    c_tp.pull_from_kg(\n                        set([o.instance_iri if isinstance(o, BaseClass) else o for o in _o]) - set(props.get(op_iri, [])),\n                        sparql_client, recursive_depth, force_overwrite_local)\n            # now collect all featched values\n            fetched = {\n                k: set([o.instance_iri if isinstance(o, BaseClass) else o for o in v])\n                for k, v in object_properties_dict.items()\n            } # object properties\n            fetched.update({k: set(copy.deepcopy(v)) for k, v in data_properties_dict.items()}) # data properties\n            fetched.update(rdfs_properties_dict) # rdfs properties\n            # compare it with cached values and local values for all object/data/rdfs properties\n            # if the object is already in the lookup, then update the object for those fields that are not modified in the python\n            try:\n                inst._update_according_to_fetch(fetched, flag_pull, force_overwrite_local)\n            except Exception as e:\n                # if there's any error, remove the iri from the loading status\n                # otherwise it will block any further pulling of the same object\n                KnowledgeGraph._remove_iri_from_loading(inst.instance_iri)\n                raise e\n        else:\n            # if the object is not in the lookup, create a new object\n            inst = target_clz(\n                instance_iri=iri,\n                **rdfs_properties_dict,\n                **object_properties_dict,\n                **data_properties_dict,\n            )\n            inst._create_cache()\n\n        inst._exist_in_kg = True\n        # update cache here\n        instance_lst.append(inst)\n        # remote inst from the loading status\n        KnowledgeGraph._remove_iri_from_loading(inst.instance_iri)\n    return instance_lst\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.pull_all_instances_from_kg","title":"pull_all_instances_from_kg  <code>classmethod</code>","text":"<pre><code>pull_all_instances_from_kg(sparql_client: PySparqlClient, recursive_depth: int = 0, force_overwrite_local: bool = False) -&gt; Set[BaseClass]\n</code></pre> <p>This function pulls all instances of the calling class from the knowledge graph (triplestore). It calls the pull_from_kg function with the IRIs of all instances of the calling class. By default, it pulls the instances with no recursion.</p> <p>Parameters:</p> Name Type Description Default <code>sparql_client</code> <code>PySparqlClient</code> <p>The SPARQL client that is used to pull the data from the KG</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion</p> <code>0</code> <code>force_overwrite_local</code> <code>bool</code> <p>Whether to force overwrite the local values with the remote values</p> <code>False</code> <p>Returns:</p> Type Description <code>Set[BaseClass]</code> <p>Set[BaseClass]: A set of objects that are pulled from the KG</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef pull_all_instances_from_kg(\n    cls,\n    sparql_client: PySparqlClient,\n    recursive_depth: int = 0,\n    force_overwrite_local: bool = False,\n) -&gt; Set[BaseClass]:\n    \"\"\"\n    This function pulls all instances of the calling class from the knowledge graph (triplestore).\n    It calls the pull_from_kg function with the IRIs of all instances of the calling class.\n    By default, it pulls the instances with no recursion.\n\n    Args:\n        sparql_client (PySparqlClient): The SPARQL client that is used to pull the data from the KG\n        recursive_depth (int): The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion\n        force_overwrite_local (bool): Whether to force overwrite the local values with the remote values\n\n    Returns:\n        Set[BaseClass]: A set of objects that are pulled from the KG\n    \"\"\"\n    iris = sparql_client.get_all_instances_of_class(cls.rdf_type)\n    return cls.pull_from_kg(iris, sparql_client, recursive_depth, force_overwrite_local)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.get_object_and_data_properties","title":"get_object_and_data_properties  <code>classmethod</code>","text":"<pre><code>get_object_and_data_properties() -&gt; Dict[str, Dict[str, Union[str, Type[BaseProperty]]]]\n</code></pre> <p>This function returns the object and data properties of the calling class. This method calls the get_object_properties and get_data_properties functions and returns the combined dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Union[str, Type[BaseProperty]]]]</code> <p>Dict[str, Dict[str, Union[str, Type[BaseProperty]]]]: A dictionary containing the object and data properties of the calling class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef get_object_and_data_properties(cls) -&gt; Dict[str, Dict[str, Union[str, Type[BaseProperty]]]]:\n    \"\"\"\n    This function returns the object and data properties of the calling class.\n    This method calls the get_object_properties and get_data_properties functions and returns the combined dictionary.\n\n    Returns:\n        Dict[str, Dict[str, Union[str, Type[BaseProperty]]]]: A dictionary containing the object and data properties of the calling class\n    \"\"\"\n    return {**cls.get_object_properties(), **cls.get_data_properties()}\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.get_object_properties","title":"get_object_properties  <code>classmethod</code>","text":"<pre><code>get_object_properties() -&gt; Dict[str, Dict[str, Union[str, Type[ObjectProperty]]]]\n</code></pre> <p>This function returns the object properties of the calling class.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Union[str, Type[ObjectProperty]]]]</code> <p>Dict[str, Union[str, Type[ObjectProperty]]]]: A dictionary containing the object properties of the calling class in the format of {predicate_iri: {'field': field_name, 'type': field_clz}} e.g. {'https://twa.com/myObjectProperty': {'field': 'myObjectProperty', 'type': MyObjectProperty}}</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef get_object_properties(cls) -&gt; Dict[str, Dict[str, Union[str, Type[ObjectProperty]]]]:\n    \"\"\"\n    This function returns the object properties of the calling class.\n\n    Returns:\n        Dict[str, Union[str, Type[ObjectProperty]]]]: A dictionary containing the object properties of the calling class\n            in the format of {predicate_iri: {'field': field_name, 'type': field_clz}}\n            e.g. {'https://twa.com/myObjectProperty': {'field': 'myObjectProperty', 'type': MyObjectProperty}}\n    \"\"\"\n    dct_op = {}\n    for f, field_info in cls.model_fields.items():\n        op = get_args(field_info.annotation)[0] if type(field_info.annotation) == _UnionGenericAlias else field_info.annotation\n        if ObjectProperty._is_inherited(op):\n            dct_op[op.predicate_iri] = {'field': f, 'type': op}\n    return dct_op\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.get_data_properties","title":"get_data_properties  <code>classmethod</code>","text":"<pre><code>get_data_properties() -&gt; Dict[str, Dict[str, Union[str, Type[DatatypeProperty]]]]\n</code></pre> <p>This function returns the data properties of the calling class.</p> <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Union[str, Type[DatatypeProperty]]]]</code> <p>Dict[str, Dict[str, Union[str, Type[DatatypeProperty]]]]: A dictionary containing the data properties of the calling class in the format of {predicate_iri: {'field': field_name, 'type': field_clz}} e.g. {'https://twa.com/myDatatypeProperty': {'field': 'myDatatypeProperty', 'type': MyDatatypeProperty}}</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef get_data_properties(cls) -&gt; Dict[str, Dict[str, Union[str, Type[DatatypeProperty]]]]:\n    \"\"\"\n    This function returns the data properties of the calling class.\n\n    Returns:\n        Dict[str, Dict[str, Union[str, Type[DatatypeProperty]]]]: A dictionary containing the data properties of the calling class\n            in the format of {predicate_iri: {'field': field_name, 'type': field_clz}}\n            e.g. {'https://twa.com/myDatatypeProperty': {'field': 'myDatatypeProperty', 'type': MyDatatypeProperty}}\n    \"\"\"\n    dct_dp = {}\n    for f, field_info in cls.model_fields.items():\n        dp = get_args(field_info.annotation)[0] if type(field_info.annotation) == _UnionGenericAlias else field_info.annotation\n        if DatatypeProperty._is_inherited(dp):\n            dct_dp[dp.predicate_iri] = {'field': f, 'type': dp}\n    return dct_dp\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.revert_local_changes","title":"revert_local_changes","text":"<pre><code>revert_local_changes()\n</code></pre> <p>This function reverts the local changes made to the python object to cached values.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def revert_local_changes(self):\n    \"\"\" This function reverts the local changes made to the python object to cached values. \"\"\"\n    for f, field_info in self.model_fields.items():\n        if BaseProperty._is_inherited(field_info.annotation):\n            setattr(self, f, copy.deepcopy(self._latest_cache.get(f, field_info.annotation(set()))))\n        else:\n            setattr(self, f, copy.deepcopy(self._latest_cache.get(f, None)))\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.get_object_property_by_iri","title":"get_object_property_by_iri","text":"<pre><code>get_object_property_by_iri(iri: str) -&gt; ObjectProperty\n</code></pre> <p>This function returns the object property by the IRI of the property.</p> <p>Parameters:</p> Name Type Description Default <code>iri</code> <code>str</code> <p>IRI of the object property</p> required <p>Returns:</p> Name Type Description <code>ObjectProperty</code> <code>ObjectProperty</code> <p>The object property</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def get_object_property_by_iri(self, iri: str) -&gt; ObjectProperty:\n    \"\"\"\n    This function returns the object property by the IRI of the property.\n\n    Args:\n        iri (str): IRI of the object property\n\n    Returns:\n        ObjectProperty: The object property\n    \"\"\"\n    dct = self.__class__.get_object_properties()\n    field_name = dct.get(iri, {}).get('field', None)\n    if field_name is not None:\n        return getattr(self, field_name)\n    else:\n        return None\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.push_to_kg","title":"push_to_kg","text":"<pre><code>push_to_kg(sparql_client: PySparqlClient, recursive_depth: int = 0, pull_first: bool = False, maximum_retry: int = 0, force_overwrite_if_pull_first: bool = False) -&gt; Tuple[Graph, Graph]\n</code></pre> <p>This function pushes the triples of the calling object to the knowledge graph (triplestore).</p> <p>Parameters:</p> Name Type Description Default <code>sparql_client</code> <code>PySparqlClient</code> <p>The SPARQL client object to be used to push the triples</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion</p> <code>0</code> <code>pull_first</code> <code>bool</code> <p>Whether to pull the latest triples from the KG before pushing the triples</p> <code>False</code> <code>maximum_retry</code> <code>int</code> <p>The number of retries if any exception was raised during SPARQL update</p> <code>0</code> <code>force_overwrite_if_pull_first</code> <code>bool</code> <p>Whether to force overwrite the local values with the remote values if <code>pull_first</code> is <code>True</code></p> <code>False</code> <p>Returns:</p> Type Description <code>Tuple[Graph, Graph]</code> <p>Tuple[Graph, Graph]: A tuple of two rdflib.Graph objects containing the triples to be removed and added</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def push_to_kg(\n    self,\n    sparql_client: PySparqlClient,\n    recursive_depth: int = 0,\n    pull_first: bool = False,\n    maximum_retry: int = 0,\n    force_overwrite_if_pull_first: bool = False,\n) -&gt; Tuple[Graph, Graph]:\n    \"\"\"\n    This function pushes the triples of the calling object to the knowledge graph (triplestore).\n\n    Args:\n        sparql_client (PySparqlClient): The SPARQL client object to be used to push the triples\n        recursive_depth (int): The depth of the recursion, 0 means no recursion, -1 means infinite recursion, n means n-level recursion\n        pull_first (bool): Whether to pull the latest triples from the KG before pushing the triples\n        maximum_retry (int): The number of retries if any exception was raised during SPARQL update\n        force_overwrite_if_pull_first (bool): Whether to force overwrite the local values with the remote values if `pull_first` is `True`\n\n    Returns:\n        Tuple[Graph, Graph]: A tuple of two rdflib.Graph objects containing the triples to be removed and added\n    \"\"\"\n    # TODO [future] what happens when KG changed during processing in the python side? race conditions...\n    # NOTE when push, the objects in memory are loaded to collect diff and only stops when it's string (i.e. no object cached)\n    # this supports the situation where recursive_depth specified here is greater than the value used to pull the object\n\n    # pull the latest triples from the KG if needed\n    if pull_first:\n        self.__class__.pull_from_kg(self.instance_iri, sparql_client, recursive_depth, force_overwrite_if_pull_first)\n    # type of changes: remove old triples, add new triples\n    g_to_remove = Graph()\n    g_to_add = Graph()\n    g_to_remove, g_to_add = self._collect_diff_to_graph(g_to_remove, g_to_add, recursive_depth)\n\n    # retry push if any exception is raised\n    retry_delay = 2\n    for attempt in range(0, maximum_retry +1):\n        try:\n            sparql_client.delete_and_insert_graphs(g_to_remove, g_to_add)\n            # if no exception was thrown, update cache\n            self._create_cache(recursive_depth)\n            return g_to_remove, g_to_add\n        except Exception as e:\n            if attempt &lt; maximum_retry:\n                time.sleep(retry_delay)\n            else:\n                raise e\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.graph","title":"graph","text":"<pre><code>graph(g: Graph = None) -&gt; Graph\n</code></pre> <p>This method adds all the outgoing triples of the calling object.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The rdflib.Graph object to which the triples should be added</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Graph</code> <code>Graph</code> <p>The rdflib.Graph object containing the triples added</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def graph(self, g: Graph = None) -&gt; Graph:\n    \"\"\"\n    This method adds all the outgoing triples of the calling object.\n\n    Args:\n        g (Graph, optional): The rdflib.Graph object to which the triples should be added\n\n    Returns:\n        Graph: The rdflib.Graph object containing the triples added\n    \"\"\"\n    if g is None:\n        g = Graph()\n    g.add((URIRef(self.instance_iri), RDF.type, URIRef(self.rdf_type)))\n    for f, field_info in self.model_fields.items():\n        tp = get_args(field_info.annotation)[0] if type(field_info.annotation) == _UnionGenericAlias else field_info.annotation\n        if ObjectProperty._is_inherited(tp):\n            tp: ObjectProperty\n            prop = getattr(self, f) if getattr(self, f) is not None else set()\n            for o in prop:\n                g.add((URIRef(self.instance_iri), URIRef(tp.predicate_iri), URIRef(o.instance_iri if isinstance(o, BaseClass) else o)))\n        elif DatatypeProperty._is_inherited(tp):\n            tp: DatatypeProperty\n            prop = getattr(self, f) if getattr(self, f) is not None else set()\n            for o in prop:\n                g.add((URIRef(self.instance_iri), URIRef(tp.predicate_iri), Literal(o)))\n        elif f == 'rdfs_comment' and bool(self.rdfs_comment):\n            for comment in self.rdfs_comment:\n                g.add((URIRef(self.instance_iri), RDFS.comment, Literal(comment)))\n        elif f == 'rdfs_label' and bool(self.rdfs_label):\n            for label in self.rdfs_label:\n                g.add((URIRef(self.instance_iri), RDFS.label, Literal(label)))\n    return g\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.BaseClass.triples","title":"triples","text":"<pre><code>triples() -&gt; str\n</code></pre> <p>This method generates the turtle representation for all outgoing triples of the calling object.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The outgoing triples in turtle format</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def triples(self) -&gt; str:\n    \"\"\"\n    This method generates the turtle representation for all outgoing triples of the calling object.\n\n    Returns:\n        str: The outgoing triples in turtle format\n    \"\"\"\n    return self.graph().serialize(format='ttl')\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.ObjectProperty","title":"ObjectProperty","text":"<pre><code>ObjectProperty(*args, **kwargs)\n</code></pre> <p>               Bases: <code>BaseProperty</code></p> <p>Base class for object properties. It inherits the BaseProperty class.</p> <p>Attributes:</p> Name Type Description <code>rdfs_isDefinedBy</code> <p>The ontology that defines the property</p> <code>predicate_iri</code> <p>The predicate IRI of the property</p> <code>owl_minQualifiedCardinality</code> <p>The minimum qualified cardinality of the property (default is 0)</p> <code>owl_maxQualifiedCardinality</code> <p>The maximum qualified cardinality of the property (default is None, meaning infinite)</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.ObjectProperty.retrieve_cardinality","title":"retrieve_cardinality  <code>classmethod</code>","text":"<pre><code>retrieve_cardinality() -&gt; Tuple[int, int]\n</code></pre> <p>This method is used to retrieve the cardinality of the property.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: The minimum and maximum cardinality of the property</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef retrieve_cardinality(cls) -&gt; Tuple[int, int]:\n    \"\"\"\n    This method is used to retrieve the cardinality of the property.\n\n    Returns:\n        Tuple[int, int]: The minimum and maximum cardinality of the property\n    \"\"\"\n    return super().retrieve_cardinality()\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.ObjectProperty.create_from_base","title":"create_from_base  <code>classmethod</code>","text":"<pre><code>create_from_base(class_name: str, ontology: Type[BaseOntology], min_cardinality: Optional[int] = 0, max_cardinality: Optional[int] = None) -&gt; Type[ObjectProperty]\n</code></pre> <p>This method is used to create a new property class from the calling property class. The new property class will inherit the min and max cardinality from the calling class if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>class_name</code> <code>str</code> <p>The name of the new property class</p> required <code>ontology</code> <code>Type[BaseOntology]</code> <p>The ontology that defines the property</p> required <code>min_cardinality</code> <code>Optional[int]</code> <p>The minimum qualified cardinality of the property (defaults to 0)</p> <code>0</code> <code>max_cardinality</code> <code>Optional[int]</code> <p>The maximum qualified cardinality of the property (defaults to None meaning infinite)</p> <code>None</code> <p>Returns:</p> Type Description <code>Type[ObjectProperty]</code> <p>Type[ObjectProperty]: The new property class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef create_from_base(\n    cls,\n    class_name: str,\n    ontology: Type[BaseOntology],\n    min_cardinality: Optional[int] = 0,\n    max_cardinality: Optional[int] = None,\n) -&gt; Type[ObjectProperty]:\n    \"\"\"\n    This method is used to create a new property class from the calling property class.\n    The new property class will inherit the min and max cardinality from the calling class if not specified.\n\n    Args:\n        class_name (str): The name of the new property class\n        ontology (Type[BaseOntology]): The ontology that defines the property\n        min_cardinality (Optional[int], optional): The minimum qualified cardinality of the property (defaults to 0)\n        max_cardinality (Optional[int], optional): The maximum qualified cardinality of the property (defaults to None meaning infinite)\n\n    Returns:\n        Type[ObjectProperty]: The new property class\n    \"\"\"\n    # NOTE we inherit cardinality from the calling cls if not specified\n    return super().create_from_base(class_name, ontology, min_cardinality, max_cardinality)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.TransitiveProperty","title":"TransitiveProperty","text":"<pre><code>TransitiveProperty(*args, **kwargs)\n</code></pre> <p>               Bases: <code>ObjectProperty</code></p> <p>Base class for transitive object properties. It inherits the ObjectProperty class.</p> <p>Attributes:</p> Name Type Description <code>rdfs_isDefinedBy</code> <p>The ontology that defines the property</p> <code>predicate_iri</code> <p>The predicate IRI of the property</p> <code>owl_minQualifiedCardinality</code> <p>The minimum qualified cardinality of the property (default is 0)</p> <code>owl_maxQualifiedCardinality</code> <p>The maximum qualified cardinality of the property (default is None, meaning infinite)</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.TransitiveProperty.obtain_transitive_objects","title":"obtain_transitive_objects  <code>classmethod</code>","text":"<pre><code>obtain_transitive_objects(instance: Union[BaseClass, str]) -&gt; Set\n</code></pre> <p>This function obtains the transitive objects of the instance for the transitive object property.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>Union[BaseClass, str]</code> <p>The instance for which the transitive objects are to be obtained</p> required <p>Returns:</p> Name Type Description <code>Set</code> <code>Set</code> <p>The set that contains the transitive objects</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef obtain_transitive_objects(cls, instance: Union[BaseClass, str]) -&gt; Set:\n    \"\"\"\n    This function obtains the transitive objects of the instance for the transitive object property.\n\n    Args:\n        instance (Union[BaseClass, str]): The instance for which the transitive objects are to be obtained\n\n    Returns:\n        Set: The set that contains the transitive objects\n    \"\"\"\n    # check if instance is a string and look it up in the knowledge graph\n    if isinstance(instance, str):\n        _inst = KnowledgeGraph.get_object_from_lookup(instance)\n        if _inst is None:\n            # warn if the instance is not found\n            # there could be further transitive objects in the remote knowledge graph\n            # but they are not looked up here\n            warnings.warn(f\"Transitive objects for object property {cls.predicate_iri} not looked up beyond instance {instance} as it is not found in the Python memory.\")\n            return set()\n        else:\n            instance = _inst\n\n    # get the transitive objects from the instance using the predicate IRI\n    _transitive_objects = instance.get_object_property_by_iri(cls.predicate_iri)\n    # initialise the transitive objects set with a deep copy of _transitive_objects, or an empty set if it's None\n    transitive_objects = set(copy.deepcopy(_transitive_objects)) if _transitive_objects else set()\n\n    # if there are no transitive objects, return the initialised set (which is an empty set)\n    if not _transitive_objects:\n        return transitive_objects\n\n    # recursively find and accumulate transitive objects for each object in _transitive_objects\n    for o in _transitive_objects:\n        transitive_objects = transitive_objects.union(cls.obtain_transitive_objects(o))\n\n    return transitive_objects\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.DatatypeProperty","title":"DatatypeProperty","text":"<pre><code>DatatypeProperty(*args, **kwargs)\n</code></pre> <p>               Bases: <code>BaseProperty</code></p> <p>Base class for data properties. It inherits the BaseProperty class.</p> <p>Attributes:</p> Name Type Description <code>rdfs_isDefinedBy</code> <p>The ontology that defines the property</p> <code>predicate_iri</code> <p>The predicate IRI of the property</p> <code>owl_minQualifiedCardinality</code> <p>The minimum qualified cardinality of the property (default is 0)</p> <code>owl_maxQualifiedCardinality</code> <p>The maximum qualified cardinality of the property (default is None, meaning infinite)</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>def __init__(self, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.DatatypeProperty.retrieve_cardinality","title":"retrieve_cardinality  <code>classmethod</code>","text":"<pre><code>retrieve_cardinality() -&gt; Tuple[int, int]\n</code></pre> <p>This method is used to retrieve the cardinality of the property.</p> <p>Returns:</p> Type Description <code>Tuple[int, int]</code> <p>Tuple[int, int]: The minimum and maximum cardinality of the property</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef retrieve_cardinality(cls) -&gt; Tuple[int, int]:\n    \"\"\"\n    This method is used to retrieve the cardinality of the property.\n\n    Returns:\n        Tuple[int, int]: The minimum and maximum cardinality of the property\n    \"\"\"\n    return super().retrieve_cardinality()\n</code></pre>"},{"location":"api/base_ontology/#twa.data_model.base_ontology.DatatypeProperty.create_from_base","title":"create_from_base  <code>classmethod</code>","text":"<pre><code>create_from_base(class_name: str, ontology: Type[BaseOntology], min_cardinality: Optional[int] = 0, max_cardinality: Optional[int] = None) -&gt; Type[DatatypeProperty]\n</code></pre> <p>This method is used to create a new property class from the calling property class. The new property class will inherit the min and max cardinality from the calling class if not specified.</p> <p>Parameters:</p> Name Type Description Default <code>class_name</code> <code>str</code> <p>The name of the new property class</p> required <code>ontology</code> <code>Type[BaseOntology]</code> <p>The ontology that defines the property</p> required <code>min_cardinality</code> <code>Optional[int]</code> <p>The minimum qualified cardinality of the property (defaults to 0)</p> <code>0</code> <code>max_cardinality</code> <code>Optional[int]</code> <p>The maximum qualified cardinality of the property (defaults to None meaning infinite)</p> <code>None</code> <p>Returns:</p> Type Description <code>Type[DatatypeProperty]</code> <p>Type[DatatypeProperty]: The new property class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/base_ontology.py</code> <pre><code>@classmethod\ndef create_from_base(\n    cls,\n    class_name: str,\n    ontology: Type[BaseOntology],\n    min_cardinality: Optional[int] = 0,\n    max_cardinality: Optional[int] = None,\n) -&gt; Type[DatatypeProperty]:\n    \"\"\"\n    This method is used to create a new property class from the calling property class.\n    The new property class will inherit the min and max cardinality from the calling class if not specified.\n\n    Args:\n        class_name (str): The name of the new property class\n        ontology (Type[BaseOntology]): The ontology that defines the property\n        min_cardinality (Optional[int], optional): The minimum qualified cardinality of the property (defaults to 0)\n        max_cardinality (Optional[int], optional): The maximum qualified cardinality of the property (defaults to None meaning infinite)\n\n    Returns:\n        Type[DatatypeProperty]: The new property class\n    \"\"\"\n    # NOTE we inherit cardinality from the calling cls if not specified\n    return super().create_from_base(class_name, ontology, min_cardinality, max_cardinality)\n</code></pre>"},{"location":"api/conf/","title":"Configuration","text":""},{"location":"api/conf/#twa.conf.agent_conf.Config","title":"Config","text":"<pre><code>Config(env: Mapping[str, Any])\n</code></pre> <p>This is a generic config class that can be extended by other classes. Map environment variables to class fields according to these rules:</p> <pre><code>- Field won't be parsed unless it has a type annotation\n- Field will be skipped if not in all caps\n- Class field and environment variable name are the same\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Mapping[str, Any]</code> <p>A mapping of environment variables.</p> required <p>Raises:</p> Type Description <code>AppConfigError</code> <p>Required fields are not provided</p> <code>AppConfigError</code> <p>Provided value for field does not match with the specified data type</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/conf/agent_conf.py</code> <pre><code>def __init__(self, env: Mapping[str, Any]):\n    \"\"\"\n    The constructor for the Config class.\n\n    Args:\n        env (Mapping[str, Any]): A mapping of environment variables.\n\n    Raises:\n        AppConfigError: Required fields are not provided\n        AppConfigError: Provided value for field does not match with the specified data type\n    \"\"\"\n    for field in self.all_annotations(): # this ensures the annotations of all parent classes are included\n        if not field.isupper():\n            continue\n\n        # Raise AppConfigError if required field not supplied\n        default_value = getattr(self, field, None)\n        if default_value is None and env.get(field) is None:\n            raise AppConfigError('The {} field is required'.format(field))\n\n        # Cast env var value to expected type and raise AppConfigError on failure\n        try:\n            var_type = get_type_hints(self.__class__)[field]\n            if var_type == bool:\n                value = _parse_bool(env.get(field, default_value))\n            else:\n                value = var_type(env.get(field, default_value))\n\n            self.__setattr__(field, value)\n        except ValueError:\n            raise AppConfigError('Unable to cast value of \"{}\" to type \"{}\" for \"{}\" field'.format(\n                env[field],\n                var_type,\n                field\n            )\n        )\n</code></pre>"},{"location":"api/conf/#twa.conf.agent_conf.Config.all_annotations","title":"all_annotations  <code>classmethod</code>","text":"<pre><code>all_annotations() -&gt; ChainMap\n</code></pre> <p>Returns a dictionary-like ChainMap that includes annotations for all  attributes defined in cls or inherited from superclasses.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/conf/agent_conf.py</code> <pre><code>@classmethod\ndef all_annotations(cls) -&gt; ChainMap:\n    \"\"\"Returns a dictionary-like ChainMap that includes annotations for all \n    attributes defined in cls or inherited from superclasses.\"\"\"\n    return ChainMap(*(c.__annotations__ for c in cls.__mro__ if '__annotations__' in c.__dict__) )\n</code></pre>"},{"location":"api/conf/#twa.conf.agent_conf.AgentConfig","title":"AgentConfig","text":"<pre><code>AgentConfig(env: Mapping[str, Any])\n</code></pre> <p>               Bases: <code>Config</code></p> <p>Configuration class for the DerivationAgent. This class is a subclass of Config and provides custom configurations for developed agents. It includes various fields to configure the agent's behavior and connectivity.</p> <p>Attributes:</p> Name Type Description <code>DERIVATION_PERIODIC_TIMESCALE</code> <code>int</code> <p>The time scale of the periodic job that monitors asynchronous derivations.</p> <code>DERIVATION_INSTANCE_BASE_URL</code> <code>str</code> <p>The base URL of the derivation instances that to be created by this agent.</p> <code>SPARQL_QUERY_ENDPOINT</code> <code>str</code> <p>The SPARQL endpoint to be used for querying the knowledge graph.</p> <code>SPARQL_UPDATE_ENDPOINT</code> <code>str</code> <p>The SPARQL endpoint to be used for updating the knowledge graph.</p> <code>KG_USERNAME</code> <code>str</code> <p>The username to access the SPARQL endpoint.</p> <code>KG_PASSWORD</code> <code>str</code> <p>The password to access the SPARQL endpoint.</p> <code>FILE_SERVER_ENDPOINT</code> <code>str</code> <p>The endpoint of the file server.</p> <code>FILE_SERVER_USERNAME</code> <code>str</code> <p>The username to access the file server.</p> <code>FILE_SERVER_PASSWORD</code> <code>str</code> <p>The password to access the file server.</p> <code>ONTOAGENT_OPERATION_HTTP_BASE_URL</code> <code>str</code> <p>The URL of the OntoAgent:Operation HTTP endpoint.</p> <code>REGISTER_AGENT</code> <code>bool</code> <p>Whether to register the OntoAgent instance of the configured agent to knowledge graph.</p> <code>MAX_THREAD_MONITOR_ASYNC_DERIVATIONS</code> <code>int</code> <p>The maximum number of thread can be invoked to monitor async derivations at the same time, the default value is 1.</p> <code>EMAIL_RECIPIENT</code> <code>str</code> <p>The list of recipients of email notifications during agent operation, multiple email address should be seperated by semicolon, e.g. foo.1@bar.com;foo.2@bar.com.</p> <code>EMAIL_SUBJECT_PREFIX</code> <code>str</code> <p>The subject prefix for email notifications, \"[] \" is automatically added, e.g. the prefix will be \"[YourAgent] \" if \"YourAgent\" is specified.</p> <code>EMAIL_USERNAME</code> <code>str</code> <p>The username of the email sender, note that a gmail account is required.</p> <code>EMAIL_AUTH_JSON_PATH</code> <code>str</code> <p>The json file path to the OAuth2 file of the gmail account defined by EMAIL_USERNAME.</p> <code>EMAIL_START_END_ASYNC_DERIVATIONS</code> <code>bool</code> <p>The boolean flag to choose whether to send email notification at the start and end of process an async derivation, the default value is False.</p> <p>Parameters:</p> Name Type Description Default <code>env</code> <code>Mapping[str, Any]</code> <p>A mapping of environment variables.</p> required <p>Raises:</p> Type Description <code>AppConfigError</code> <p>Required fields are not provided</p> <code>AppConfigError</code> <p>Provided value for field does not match with the specified data type</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/conf/agent_conf.py</code> <pre><code>def __init__(self, env: Mapping[str, Any]):\n    \"\"\"\n    The constructor for the Config class.\n\n    Args:\n        env (Mapping[str, Any]): A mapping of environment variables.\n\n    Raises:\n        AppConfigError: Required fields are not provided\n        AppConfigError: Provided value for field does not match with the specified data type\n    \"\"\"\n    for field in self.all_annotations(): # this ensures the annotations of all parent classes are included\n        if not field.isupper():\n            continue\n\n        # Raise AppConfigError if required field not supplied\n        default_value = getattr(self, field, None)\n        if default_value is None and env.get(field) is None:\n            raise AppConfigError('The {} field is required'.format(field))\n\n        # Cast env var value to expected type and raise AppConfigError on failure\n        try:\n            var_type = get_type_hints(self.__class__)[field]\n            if var_type == bool:\n                value = _parse_bool(env.get(field, default_value))\n            else:\n                value = var_type(env.get(field, default_value))\n\n            self.__setattr__(field, value)\n        except ValueError:\n            raise AppConfigError('Unable to cast value of \"{}\" to type \"{}\" for \"{}\" field'.format(\n                env[field],\n                var_type,\n                field\n            )\n        )\n</code></pre>"},{"location":"api/conf/#twa.conf.agent_conf.config_generic","title":"config_generic","text":"<pre><code>config_generic(conf_cls: Type[Config], env_file: str = None) -&gt; Config\n</code></pre> <p>Load and return the configuration for the specified configuration class from either environment variables or a specified environment file.</p> <p>Parameters:</p> Name Type Description Default <code>conf_cls</code> <code>Type[Config]</code> <p>The configuration class to instantiate.</p> required <code>env_file</code> <code>str</code> <p>The path to a dotenv (.env) file containing environment variables. If not provided, environment variables will be loaded from the system environment.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Config</code> <code>Config</code> <p>An instance of the provided configuration class, populated with environment variables.</p> <p>Raises:</p> Type Description <code>AppConfigError</code> <p>If required configuration fields are missing or cannot be cast to the specified types.</p> <p>Examples:</p> <pre><code># Load configuration from a .env file\nconfig = config_generic(MyConfigClass, env_file=\".env\")\n\n# Load configuration from system environment variables\nconfig = config_generic(MyConfigClass)\n</code></pre> Note <p>The function prioritizes loading environment variables from the provided env_file if specified. Otherwise, it defaults to using the system environment variables.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/conf/agent_conf.py</code> <pre><code>def config_generic(conf_cls: Type[Config], env_file: str = None) -&gt; Config:\n    \"\"\"\n    Load and return the configuration for the specified configuration class from either environment variables or a specified environment file.\n\n    Args:\n        conf_cls (Type[Config]): The configuration class to instantiate.\n        env_file (str, optional): The path to a dotenv (.env) file containing environment variables. If not provided, environment variables will be loaded from the system environment.\n\n    Returns:\n        Config: An instance of the provided configuration class, populated with environment variables.\n\n    Raises:\n        AppConfigError: If required configuration fields are missing or cannot be cast to the specified types.\n\n    Examples:\n        ```\n        # Load configuration from a .env file\n        config = config_generic(MyConfigClass, env_file=\".env\")\n\n        # Load configuration from system environment variables\n        config = config_generic(MyConfigClass)\n        ```\n\n    Note:\n        The function prioritizes loading environment variables from the provided env_file if specified.\n        Otherwise, it defaults to using the system environment variables.\n    \"\"\"\n    if env_file is not None:\n        return conf_cls(dotenv_values(env_file))\n    else:\n        return conf_cls(os.environ)\n</code></pre>"},{"location":"api/conf/#twa.conf.agent_conf.config_derivation_agent","title":"config_derivation_agent","text":"<pre><code>config_derivation_agent(env_file: str = None) -&gt; AgentConfig\n</code></pre> <p>Load and return the configuration for the DerivationAgent from either environment variables or a specified environment file.</p> <p>Parameters:</p> Name Type Description Default <code>env_file</code> <code>str</code> <p>The path to a dotenv file containing environment variables. If not provided, environment variables will be loaded from the system environment.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>AgentConfig</code> <code>AgentConfig</code> <p>An instance of the AgentConfig class, populated with environment variables.</p> <p>Raises:</p> Type Description <code>AppConfigError</code> <p>If required configuration fields are missing or cannot be cast to the specified types.</p> <p>Examples:</p> <pre><code># Load configuration from a .env file\nconfig = config_derivation_agent(env_file=\".env\")\n\n# Load configuration from system environment variables\nconfig = config_derivation_agent()\n</code></pre> Note <p>The function prioritizes loading environment variables from the provided env_file if specified. Otherwise, it defaults to using the system environment variables.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/conf/agent_conf.py</code> <pre><code>def config_derivation_agent(env_file: str = None) -&gt; AgentConfig:\n    \"\"\"\n    Load and return the configuration for the DerivationAgent from either environment variables or a specified environment file.\n\n    Args:\n        env_file (str, optional): The path to a dotenv file containing environment variables. If not provided, environment variables will be loaded from the system environment.\n\n    Returns:\n        AgentConfig: An instance of the AgentConfig class, populated with environment variables.\n\n    Raises:\n        AppConfigError: If required configuration fields are missing or cannot be cast to the specified types.\n\n    Examples:\n        ```\n        # Load configuration from a .env file\n        config = config_derivation_agent(env_file=\".env\")\n\n        # Load configuration from system environment variables\n        config = config_derivation_agent()\n        ```\n\n    Note:\n        The function prioritizes loading environment variables from the provided env_file if specified.\n        Otherwise, it defaults to using the system environment variables.\n    \"\"\"\n    return config_generic(AgentConfig, env_file)\n</code></pre>"},{"location":"api/derivation/","title":"Derivation","text":""},{"location":"api/derivation/#twa.data_model.derivation.Derivation","title":"Derivation","text":"<pre><code>Derivation(derivation_java)\n</code></pre> <p>Wrapper class for <code>uk.ac.cam.cares.jps.base.derivation.Derivation.java</code>.</p> <p>This class provides a simplified interface for interacting with the Derivation object returned when creating synchronous derivations for new information.</p> <p>Only two methods are provided here, all other methods in Java can be accessed via <code>self.derivation.nameOfJavaMethod(args)</code>.</p> <p>Methods:</p> Name Description <code>getIri</code> <p>Returns the IRI of the Derivation instance</p> <code>getBelongsToIris</code> <p>Returns the IRIs of the entities that belong to the Derivation instance</p> <p>Parameters:</p> Name Type Description Default <code>derivation_java</code> <p>The Java derivation object</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def __init__(self, derivation_java):\n    \"\"\"\n    Initialises the Derivation instance.\n\n    Args:\n        derivation_java: The Java derivation object\n    \"\"\"\n    self.derivation = derivation_java\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.Derivation.getIri","title":"getIri","text":"<pre><code>getIri() -&gt; str\n</code></pre> <p>Returns the IRI of the Derivation instance.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the Derivation instance</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def getIri(self) -&gt; str:\n    \"\"\"\n    Returns the IRI of the Derivation instance.\n\n    Returns:\n        str: IRI of the Derivation instance\n    \"\"\"\n    return self.derivation.getIri()\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.Derivation.getBelongsToIris","title":"getBelongsToIris","text":"<pre><code>getBelongsToIris(outputRdfType: str) -&gt; List[str]\n</code></pre> <p>Returns the IRIs of the entities that belongsTo the Derivation instance.</p> <p>Parameters:</p> Name Type Description Default <code>outputRdfType</code> <code>str</code> <p>IRI of the rdf:type of the entities that belongsTo the Derivation instance</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of the entities that belongsTo the Derivation instance</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def getBelongsToIris(self, outputRdfType: str) -&gt; List[str]:\n    \"\"\"\n    Returns the IRIs of the entities that belongsTo the Derivation instance.\n\n    Args:\n        outputRdfType (str): IRI of the rdf:type of the entities that belongsTo the Derivation instance\n\n    Returns:\n        List[str]: List of IRIs of the entities that belongsTo the Derivation instance\n    \"\"\"\n    return self.derivation.getBelongsToIris(outputRdfType)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs","title":"DerivationInputs","text":"<pre><code>DerivationInputs(derivationInputs)\n</code></pre> <p>Wrapper class for <code>uk.ac.cam.cares.jps.base.derivation.DerivationInputs.java</code>.</p> <p>This class provides methods to handle derivations within Python derivation agents, referencing to the corresponding methods in the Java class. For implementation details, please refer to the Java code.</p> <p>Methods:</p> Name Description <code>getDerivationIRI</code> <p>Returns the IRI of the derivation.</p> <code>getInputs</code> <p>Returns the inputs of the derivation as a dictionary.</p> <code>getIris</code> <p>Returns the IRIs of the inputs of the specified rdf:type.</p> <code>get_inputs_ogm_by_rdf_type</code> <p>Returns the inputs as objects of the specified rdf:type.</p> <code>get_inputs_ogm</code> <p>Returns the inputs as objects of the specified class.</p> <code>get_inputs_ogm_assume_one</code> <p>Returns a single input object of the specified class.</p> <p>Parameters:</p> Name Type Description Default <code>derivationInputs</code> <p>The Java DerivationInputs object</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def __init__(self, derivationInputs) -&gt; None:\n    \"\"\"\n    Initialises the DerivationInputs instance.\n\n    Args:\n        derivationInputs: The Java DerivationInputs object\n    \"\"\"\n    self.derivation_inputs = derivationInputs\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.getDerivationIRI","title":"getDerivationIRI","text":"<pre><code>getDerivationIRI() -&gt; str\n</code></pre> <p>Returns the IRI of the derivation.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def getDerivationIRI(self) -&gt; str:\n    \"\"\"\n    Returns the IRI of the derivation.\n\n    Returns:\n        str: IRI of the derivation\n    \"\"\"\n    return self.derivation_inputs.getDerivationIRI()\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.getInputs","title":"getInputs","text":"<pre><code>getInputs() -&gt; Dict[str, List[str]]\n</code></pre> <p>Returns the inputs of the derivation as a dictionary.</p> <p>Returns:</p> Type Description <code>Dict[str, List[str]]</code> <p>Dict[str, List[str]]: Inputs of the derivation in the format of {rdf_type: [iris]}</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def getInputs(self) -&gt; Dict[str, List[str]]:\n    \"\"\"\n    Returns the inputs of the derivation as a dictionary.\n\n    Returns:\n        Dict[str, List[str]]: Inputs of the derivation in the format of {rdf_type: [iris]}\n    \"\"\"\n    return ast.literal_eval(str(self.derivation_inputs.getInputs()))\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.getIris","title":"getIris","text":"<pre><code>getIris(rdfType) -&gt; Union[List[str], None]\n</code></pre> <p>Returns the IRIs of the inputs of the specified rdf:type.</p> <p>Parameters:</p> Name Type Description Default <code>rdfType</code> <code>str</code> <p>IRI of the rdf:type of the inputs</p> required <p>Returns:</p> Type Description <code>Union[List[str], None]</code> <p>List[str]: List of IRIs of the inputs, or None if no inputs are found</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def getIris(self, rdfType) -&gt; Union[List[str], None]:\n    \"\"\"\n    Returns the IRIs of the inputs of the specified rdf:type.\n\n    Args:\n        rdfType (str): IRI of the rdf:type of the inputs\n\n    Returns:\n        List[str]: List of IRIs of the inputs, or None if no inputs are found\n    \"\"\"\n    iris = self.derivation_inputs.getIris(rdfType)\n    return list(iris) if iris is not None else None\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.get_inputs_ogm_by_rdf_type","title":"get_inputs_ogm_by_rdf_type","text":"<pre><code>get_inputs_ogm_by_rdf_type(rdf_type: str, sparql_client, recursive_depth: int = 0) -&gt; List[BaseClass]\n</code></pre> <p>Returns the inputs as objects of the specified rdf:type (when using object graph mapper).</p> <p>Parameters:</p> Name Type Description Default <code>rdf_type</code> <code>str</code> <p>IRI of the rdf:type</p> required <code>sparql_client</code> <p>The SPARQL client to query the knowledge graph</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of recursive queries (default is 0)</p> <code>0</code> <p>Returns:</p> Type Description <code>List[BaseClass]</code> <p>List[BaseClass]: List of objects of the specified rdf:type</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def get_inputs_ogm_by_rdf_type(\n    self,\n    rdf_type: str,\n    sparql_client,\n    recursive_depth: int = 0\n) -&gt; List[BaseClass]:\n    \"\"\"\n    Returns the inputs as objects of the specified rdf:type (when using object graph mapper).\n\n    Args:\n        rdf_type (str): IRI of the rdf:type\n        sparql_client: The SPARQL client to query the knowledge graph\n        recursive_depth (int): The depth of recursive queries (default is 0)\n\n    Returns:\n        List[BaseClass]: List of objects of the specified rdf:type\n    \"\"\"\n    return BaseClass.pull_from_kg(\n        iris=self.getIris(rdf_type),\n        sparql_client=sparql_client,\n        recursive_depth=recursive_depth\n    )\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.get_inputs_ogm","title":"get_inputs_ogm","text":"<pre><code>get_inputs_ogm(clz: Type[_T], sparql_client, recursive_depth: int = 0) -&gt; List[_T]\n</code></pre> <p>Returns the inputs as objects of the specified class.</p> <p>Parameters:</p> Name Type Description Default <code>clz</code> <code>Type[_T]</code> <p>The class of the objects to return</p> required <code>sparql_client</code> <p>The SPARQL client to query the knowledge graph</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of recursive queries (default is 0)</p> <code>0</code> <p>Returns:</p> Type Description <code>List[_T]</code> <p>List[_T]: List of objects of the specified class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def get_inputs_ogm(\n    self,\n    clz: Type[_T],\n    sparql_client,\n    recursive_depth: int = 0\n) -&gt; List[_T]:\n    \"\"\"\n    Returns the inputs as objects of the specified class.\n\n    Args:\n        clz (Type[_T]): The class of the objects to return\n        sparql_client: The SPARQL client to query the knowledge graph\n        recursive_depth (int): The depth of recursive queries (default is 0)\n\n    Returns:\n        List[_T]: List of objects of the specified class\n    \"\"\"\n    return clz.pull_from_kg(\n        iris=self.getIris(clz.rdf_type),\n        sparql_client=sparql_client,\n        recursive_depth=recursive_depth\n    )\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationInputs.get_inputs_ogm_assume_one","title":"get_inputs_ogm_assume_one","text":"<pre><code>get_inputs_ogm_assume_one(clz: Type[_T], sparql_client, recursive_depth: int = 0) -&gt; _T\n</code></pre> <p>Returns a single input object of the specified class.</p> <p>Parameters:</p> Name Type Description Default <code>clz</code> <code>Type[_T]</code> <p>The class of the object to return</p> required <code>sparql_client</code> <p>The SPARQL client to query the knowledge graph</p> required <code>recursive_depth</code> <code>int</code> <p>The depth of recursive queries (default is 0)</p> <code>0</code> <p>Raises:</p> Type Description <code>Exception</code> <p>If the number of objects found is not exactly one</p> <p>Returns:</p> Name Type Description <code>_T</code> <code>_T</code> <p>The single object of the specified class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def get_inputs_ogm_assume_one(\n    self,\n    clz: Type[_T],\n    sparql_client,\n    recursive_depth: int = 0\n) -&gt; _T:\n    \"\"\"\n    Returns a single input object of the specified class.\n\n    Args:\n        clz (Type[_T]): The class of the object to return\n        sparql_client: The SPARQL client to query the knowledge graph\n        recursive_depth (int): The depth of recursive queries (default is 0)\n\n    Raises:\n        Exception: If the number of objects found is not exactly one\n\n    Returns:\n        _T: The single object of the specified class\n    \"\"\"\n    objects = self.get_inputs_ogm(clz=clz, sparql_client=sparql_client, recursive_depth=recursive_depth)\n    if len(objects) != 1:\n        raise Exception(f\"\"\"Input type {clz.rdf_type} assumed one for derivation {self.getDerivationIRI()},\n            encounterred {len(objects)}: {' '.join([o.triples() for o in objects])}\"\"\")\n    return next(iter(objects))\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs","title":"DerivationOutputs","text":"<pre><code>DerivationOutputs(derivationOutputs)\n</code></pre> <p>Wrapper class for <code>uk.ac.cam.cares.jps.base.derivation.DerivationOutputs.java</code>.</p> <p>This class provides methods to handle derivations within Python derivation agents, referencing to the corresponding methods in the Java class. For implementation details, please refer to the Java code.</p> <p>Methods:</p> Name Description <code>createNewEntity</code> <p>Creates a new entity with the given IRI and rdf:type.</p> <code>createNewEntityWithBaseUrl</code> <p>Creates a new entity with a base URL and rdf:type.</p> <code>addTriple</code> <p>Adds a triple to the derivation outputs.</p> <code>addLiteral</code> <p>Adds a literal to the derivation outputs.</p> <code>addLiteralWithDataType</code> <p>Adds a literal with a specified data type to the derivation outputs.</p> <code>addGraph</code> <p>Adds a whole rdflib.Graph to the derivation outputs.</p> <code>add_outputs_ogm</code> <p>Adds objects of a specified class to the derivation outputs.</p> <p>Parameters:</p> Name Type Description Default <code>derivationOutputs</code> <p>The Java DerivationOutputs object</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def __init__(self, derivationOutputs) -&gt; None:\n    \"\"\"\n    Initialises the DerivationOutputs instance.\n\n    Args:\n        derivationOutputs: The Java DerivationOutputs object\n    \"\"\"\n    self.derivation_outputs = derivationOutputs\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.createNewEntity","title":"createNewEntity","text":"<pre><code>createNewEntity(iri, rdfType)\n</code></pre> <p>Creates a new entity with the given IRI and rdf:type.</p> <p>Parameters:</p> Name Type Description Default <code>iri</code> <code>str</code> <p>IRI of the new entity</p> required <code>rdfType</code> <code>str</code> <p>IRI of the rdf:type of the new entity</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def createNewEntity(self, iri, rdfType):\n    \"\"\"\n    Creates a new entity with the given IRI and rdf:type.\n\n    Args:\n        iri (str): IRI of the new entity\n        rdfType (str): IRI of the rdf:type of the new entity\n    \"\"\"\n    self.derivation_outputs.createNewEntity(iri, rdfType)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.createNewEntityWithBaseUrl","title":"createNewEntityWithBaseUrl","text":"<pre><code>createNewEntityWithBaseUrl(baseUrl, rdfType)\n</code></pre> <p>Creates a new entity with the given base URL and rdf:type, adds the new entity to derivation outputs, then returns the initialised IRI.</p> <p>Parameters:</p> Name Type Description Default <code>baseUrl</code> <code>str</code> <p>Base URL for the new entity</p> required <code>rdfType</code> <code>str</code> <p>IRI of the rdf:type of the new entity</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>IRI of the newly created entity.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def createNewEntityWithBaseUrl(self, baseUrl, rdfType):\n    \"\"\"\n    Creates a new entity with the given base URL and rdf:type, adds the new entity to derivation outputs, then returns the initialised IRI.\n\n    Args:\n        baseUrl (str): Base URL for the new entity\n        rdfType (str): IRI of the rdf:type of the new entity\n\n    Returns:\n        str: IRI of the newly created entity.\n    \"\"\"\n    return self.derivation_outputs.createNewEntityWithBaseUrl(baseUrl, rdfType)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.addTriple","title":"addTriple","text":"<pre><code>addTriple(s, p, o)\n</code></pre> <p>Adds a triple to the derivation outputs. Note that only one addTriple function is provided here, the two functions taking TriplePattern is NOT provided for simplicity of java-python data structure conversion.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Subject of the triple</p> required <code>p</code> <code>str</code> <p>Predicate of the triple</p> required <code>o</code> <code>str</code> <p>Object of the triple</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def addTriple(self, s, p, o):\n    \"\"\"\n    Adds a triple to the derivation outputs.\n    Note that only one addTriple function is provided here, the two functions taking TriplePattern is NOT provided for simplicity of java-python data structure conversion.\n\n    Args:\n        s (str): Subject of the triple\n        p (str): Predicate of the triple\n        o (str): Object of the triple\n    \"\"\"\n    self.derivation_outputs.addTriple(s, p, o)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.addLiteral","title":"addLiteral","text":"<pre><code>addLiteral(s, p, o)\n</code></pre> <p>Adds a literal to the derivation outputs. Note that only one addLiteral is provided here as the correct method to use will be decided by java automatically.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Subject of the triple</p> required <code>p</code> <code>str</code> <p>Predicate of the triple</p> required <code>o</code> <code>Union[str, Literal]</code> <p>Literal object of the triple</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def addLiteral(self, s, p, o):\n    \"\"\"\n    Adds a literal to the derivation outputs.\n    Note that only one addLiteral is provided here as the correct method to use will be decided by java automatically.\n\n    Args:\n        s (str): Subject of the triple\n        p (str): Predicate of the triple\n        o (Union[str, Literal]): Literal object of the triple\n    \"\"\"\n    self.derivation_outputs.addLiteral(s, p, o)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.addLiteralWithDataType","title":"addLiteralWithDataType","text":"<pre><code>addLiteralWithDataType(s, p, o, dataType)\n</code></pre> <p>Adds a literal with a specified data type to the derivation outputs. Note that this method corresponds to addLiteral(String, String, String, String) in <code>DerivationOutputs.java</code>, but renamed in python due to limitations of overloading in python.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Subject of the triple</p> required <code>p</code> <code>str</code> <p>Predicate of the triple</p> required <code>o</code> <code>str</code> <p>Literal object of the triple</p> required <code>dataType</code> <code>str</code> <p>Data type of the literal</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def addLiteralWithDataType(self, s, p, o, dataType):\n    \"\"\"\n    Adds a literal with a specified data type to the derivation outputs.\n    Note that this method corresponds to addLiteral(String, String, String, String) in `DerivationOutputs.java`,\n    but renamed in python due to limitations of overloading in python.\n\n    Args:\n        s (str): Subject of the triple\n        p (str): Predicate of the triple\n        o (str): Literal object of the triple\n        dataType (str): Data type of the literal\n    \"\"\"\n    self.derivation_outputs.addLiteral(s, p, o, dataType)\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.addGraph","title":"addGraph","text":"<pre><code>addGraph(g: Graph)\n</code></pre> <p>Adds a whole rdflib.Graph to the derivation outputs.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The graph to add to the derivation outputs</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def addGraph(self, g: Graph):\n    \"\"\"\n    Adds a whole rdflib.Graph to the derivation outputs.\n\n    Args:\n        g (Graph): The graph to add to the derivation outputs\n    \"\"\"\n    for s, p, o in g:\n        try:\n            if p.toPython() == RDF.type.toPython():\n                self.createNewEntity(s.toPython(), o.toPython())\n            else:\n                # add data properties\n                if isinstance(o, Literal):\n                    if isinstance(o.toPython(), Literal):\n                        # if o.toPython() is a Literal instance, then it's returning itself\n                        # this means the datatype provided to initialise o is NOT presented in rdflib.term.XSDToPython\n                        # therefore, it cannot be cast to native python type\n                        # but str(o) will return the lexical_or_value used\n                        self.addLiteralWithDataType(s.toPython(), p.toPython(), str(o), o._datatype.toPython())\n                    else:\n                        # .toPython() works out what's the most suitable python class and cast to it\n                        self.addLiteral(s.toPython(), p.toPython(), o.toPython())\n                # add object properties\n                else:\n                    self.addTriple(s.toPython(), p.toPython(), o.toPython())\n        except Exception as exc:\n            raise Exception(f\"Failed to add: {s.n3()} {p.n3()} {o.n3()}\") from exc\n</code></pre>"},{"location":"api/derivation/#twa.data_model.derivation.DerivationOutputs.add_outputs_ogm","title":"add_outputs_ogm","text":"<pre><code>add_outputs_ogm(objects: Union[BaseClass, List[BaseClass]])\n</code></pre> <p>Adds objects of a specified class to the derivation outputs.</p> <p>Parameters:</p> Name Type Description Default <code>objects</code> <code>Union[BaseClass, List[BaseClass]]</code> <p>The objects to add to the derivation outputs</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/derivation.py</code> <pre><code>def add_outputs_ogm(self, objects: Union[BaseClass, List[BaseClass]]):\n    \"\"\"\n    Adds objects of a specified class to the derivation outputs.\n\n    Args:\n        objects (Union[BaseClass, List[BaseClass]]): The objects to add to the derivation outputs\n    \"\"\"\n    if isinstance(objects, BaseClass):\n        objects = [objects]\n    iris = [o.instance_iri for o in objects]\n    self.addGraph(KnowledgeGraph.all_triples_of_nodes(iris))\n</code></pre>"},{"location":"api/derivation_agent/","title":"Derivation Agent","text":""},{"location":"api/derivation_agent/#twa.agent.derivation_agent.FlaskConfig","title":"FlaskConfig","text":"<p>               Bases: <code>object</code></p> <p>This class provides the configuration for flask app object. Each config should be provided as constant. For more information, visit https://flask.palletsprojects.com/en/3.0.x/config/.</p> <p>Attributes:</p> Name Type Description <code>SCHEDULER_API_ENABLED</code> <code>bool</code> <p>Enables the Flask Scheduler API (default is True)</p>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent","title":"DerivationAgent","text":"<pre><code>DerivationAgent(time_interval: int, kg_url: str, kg_update_url: str = None, kg_user: str = None, kg_password: str = None, fs_url: str = None, fs_user: str = None, fs_password: str = None, derivation_instance_base_url: str = TWA_BASE_URL, flask_config: FlaskConfig = FlaskConfig(), agent_endpoint_base_url: str = 'http://localhost:5000/', register_agent: bool = True, max_thread_monitor_async_derivations: int = 1, email_recipient: str = '', email_subject_prefix: str = '', email_username: str = '', email_auth_json_path: str = '', email_start_end_async_derivations: bool = False, logger_for_dev: bool = True)\n</code></pre> <p>               Bases: <code>ABC</code></p> <p>Abstract base class for a derivation agent.</p> <p>This class provides the foundational methods and configurations required for a derivation agent. It uses a Flask application and APScheduler to manage asynchronous derivations and periodic jobs.</p> <p>Attributes:</p> Name Type Description <code>app</code> <code>Flask</code> <p>The Flask application instance.</p> <code>scheduler</code> <code>APScheduler</code> <p>The APScheduler instance for managing periodic jobs.</p> <code>time_interval</code> <code>int</code> <p>The time interval between two runs of the derivation monitoring job (in seconds).</p> <code>max_thread_monitor_async_derivations</code> <code>int</code> <p>Maximum number of threads to be used for monitoring async derivations.</p> <code>syncDerivationEndpoint</code> <code>str</code> <p>HTTP endpoint for handling synchronous derivations.</p> <code>kgUrl</code> <code>str</code> <p>SPARQL query endpoint.</p> <code>kgUpdateUrl</code> <code>str</code> <p>SPARQL update endpoint.</p> <code>kgUser</code> <code>str</code> <p>Username for the SPARQL endpoints.</p> <code>kgPassword</code> <code>str</code> <p>Password for the SPARQL endpoints.</p> <code>fs_url</code> <code>str</code> <p>File server endpoint.</p> <code>fs_user</code> <code>str</code> <p>Username for the file server.</p> <code>fs_password</code> <code>str</code> <p>Password for the file server.</p> <code>derivation_client</code> <code>PyDerivationClient</code> <p>Client for managing derivations.</p> <code>sparql_client</code> <code>PySparqlClient</code> <p>SPARQL client instance.</p> <code>logger</code> <code>Logger</code> <p>Logger for the agent.</p> <code>yag</code> <code>SMTP</code> <p>Email client for sending notifications.</p> <code>email_recipient</code> <code>List[str]</code> <p>List of email recipients.</p> <code>email_subject_prefix</code> <code>str</code> <p>Prefix for email subjects.</p> <code>email_start_end_async_derivations</code> <code>bool</code> <p>Flag to send email notifications at the start and end of async derivations.</p> <code>register_agent</code> <code>bool</code> <p>Flag to register the agent to the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>time_interval</code> <code>int</code> <p>time interval between two runs of derivation monitoring job (in SECONDS)</p> required <code>kg_url</code> <code>str</code> <p>SPARQL query endpoint, an example: \"http://localhost:8080/blazegraph/namespace/triplestore/sparql\"</p> required <code>kg_update_url</code> <code>str</code> <p>SPARQL update endpoint, will be set to the same value as kg_url if not provided, an example: \"http://localhost:8080/blazegraph/namespace/triplestore/sparql\"</p> <code>None</code> <code>kg_user</code> <code>str</code> <p>username used to access the SPARQL query/update endpoint specified by kg_url/kg_update_url</p> <code>None</code> <code>kg_password</code> <code>str</code> <p>password that set for the kg_user used to access the SPARQL query/update endpoint specified by kg_url/kg_update_url</p> <code>None</code> <code>fs_url</code> <code>str</code> <p>file server endpoint, an example: \"http://localhost:8080/FileServer/\"</p> <code>None</code> <code>fs_user</code> <code>str</code> <p>username used to access the file server endpoint specified by fs_url</p> <code>None</code> <code>fs_password</code> <code>str</code> <p>password that set for the fs_user used to access the file server endpoint specified by fs_url</p> <code>None</code> <code>derivation_instance_base_url</code> <code>str</code> <p>namespace to be used when creating derivation instance, an example: \"http://example.com/kg/\"</p> <code>TWA_BASE_URL</code> <code>flask_config</code> <code>FlaskConfig</code> <p>configuration object for flask app, should be an instance of the class FlaskConfig provided as part of this package</p> <code>FlaskConfig()</code> <code>agent_endpoint_base_url</code> <code>str</code> <p>data property OntoAgent:hasHttpUrl of OntoAgent:Operation of the derivation agent, an example: \"http://localhost:5000/endpoint\"</p> <code>'http://localhost:5000/'</code> <code>register_agent</code> <code>bool</code> <p>boolean value, whether to register the agent to the knowledge graph</p> <code>True</code> <code>max_thread_monitor_async_derivations</code> <code>int</code> <p>maximum number of threads that to be used for monitoring async derivations</p> <code>1</code> <code>email_recipient</code> <code>str</code> <p>recipients of email notification seperated by semicolon, e.g. \"abc@email.com;def@email.com\"</p> <code>''</code> <code>email_subject_prefix</code> <code>str</code> <p>subject prefix of the email title to put in a square bracket, e.g. the email subject will start with \"[My Prefix]\" when provided \"My Prefix\"</p> <code>''</code> <code>email_username</code> <code>str</code> <p>the username to be used as the sender of the email</p> <code>''</code> <code>email_auth_json_path</code> <code>str</code> <p>file path to the auth json for the <code>email_username</code></p> <code>''</code> <code>email_start_end_async_derivations</code> <code>bool</code> <p>a boolean flag indicating whether to send email notification at the start and end of processing async derivations</p> <code>False</code> <code>logger_for_dev</code> <code>bool</code> <p>logger for agents in development or production</p> <code>True</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def __init__(\n    self,\n    time_interval: int,\n    kg_url: str,\n    kg_update_url: str = None,\n    kg_user: str = None,\n    kg_password: str = None,\n    fs_url: str = None,\n    fs_user: str = None,\n    fs_password: str = None,\n    derivation_instance_base_url: str = TWA_BASE_URL,\n    flask_config: FlaskConfig = FlaskConfig(),\n    agent_endpoint_base_url: str = \"http://localhost:5000/\",\n    register_agent: bool = True,\n    max_thread_monitor_async_derivations: int = 1,\n    email_recipient: str = '',\n    email_subject_prefix: str = '',\n    email_username: str = '',\n    email_auth_json_path: str = '',\n    email_start_end_async_derivations: bool = False,\n    logger_for_dev: bool = True,\n):\n    \"\"\"\n    Initialises the instance of DerivationAgent.\n\n    Args:\n        time_interval (int): time interval between two runs of derivation monitoring job (in SECONDS)\n        kg_url (str): SPARQL query endpoint, an example: \"http://localhost:8080/blazegraph/namespace/triplestore/sparql\"\n        kg_update_url (str): SPARQL update endpoint, will be set to the same value as kg_url if not provided, an example: \"http://localhost:8080/blazegraph/namespace/triplestore/sparql\"\n        kg_user (str): username used to access the SPARQL query/update endpoint specified by kg_url/kg_update_url\n        kg_password (str): password that set for the kg_user used to access the SPARQL query/update endpoint specified by kg_url/kg_update_url\n        fs_url (str): file server endpoint, an example: \"http://localhost:8080/FileServer/\"\n        fs_user (str): username used to access the file server endpoint specified by fs_url\n        fs_password (str): password that set for the fs_user used to access the file server endpoint specified by fs_url\n        derivation_instance_base_url (str): namespace to be used when creating derivation instance, an example: \"http://example.com/kg/\"\n        flask_config (FlaskConfig): configuration object for flask app, should be an instance of the class FlaskConfig provided as part of this package\n        agent_endpoint_base_url (str): data property OntoAgent:hasHttpUrl of OntoAgent:Operation of the derivation agent, an example: \"http://localhost:5000/endpoint\"\n        register_agent (bool): boolean value, whether to register the agent to the knowledge graph\n        max_thread_monitor_async_derivations (int): maximum number of threads that to be used for monitoring async derivations\n        email_recipient (str): recipients of email notification seperated by semicolon, e.g. \"abc@email.com;def@email.com\"\n        email_subject_prefix (str): subject prefix of the email title to put in a square bracket, e.g. the email subject will start with \"[My Prefix]\" when provided \"My Prefix\"\n        email_username (str): the username to be used as the sender of the email\n        email_auth_json_path (str): file path to the auth json for the `email_username`\n        email_start_end_async_derivations (bool): a boolean flag indicating whether to send email notification at the start and end of processing async derivations\n        logger_for_dev (bool): logger for agents in development or production\n    \"\"\"\n\n    # create a JVM module view and use it to import the required java classes\n    self.jpsBaseLib_view = jpsBaseLibGW.createModuleView()\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view, \"uk.ac.cam.cares.jps.base.agent.*\")\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view, \"uk.ac.cam.cares.jps.base.query.*\")\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view, \"uk.ac.cam.cares.jps.base.derivation.*\")\n\n    # initialise flask app with its configuration\n    self.app = Flask(self.__class__.__name__)\n    self.app.config.from_object(flask_config)\n\n    # initialise flask scheduler and assign time interval for monitor_async_derivations job\n    self.scheduler = APScheduler(app=self.app)\n    self.time_interval = time_interval\n    self.max_thread_monitor_async_derivations = max_thread_monitor_async_derivations\n\n    # assign IRI and HTTP URL of the agent\n    # self.agentIRI\n    self.syncDerivationEndpoint = agent_endpoint_base_url + 'derivation' if agent_endpoint_base_url.endswith('/') else agent_endpoint_base_url + '/derivation'\n\n    # assign KG related information\n    self.kgUrl = kg_url\n    self.kgUpdateUrl = kg_update_url if kg_update_url is not None else kg_url\n    # NOTE that we check first if below are empty string first\n    # as the config_derivation_agent will read as '' if the value is not provided in env file\n    self.kgUser = kg_user if kg_user != '' else None\n    self.kgPassword = kg_password if kg_password != '' else None\n\n    # assign file server related information\n    # NOTE that we check first if below are empty string first\n    # as the config_derivation_agent will read as '' if the value is not provided in env file\n    self.fs_url = fs_url if fs_url != '' else None\n    self.fs_user = fs_user if fs_user != '' else None\n    self.fs_password = fs_password if fs_password != '' else None\n\n    # initialise the derivation_client with SPARQL Query and Update endpoint\n    self.derivation_client = PyDerivationClient(\n        derivation_instance_base_url,\n        self.kgUrl,\n        self.kgUpdateUrl,\n        self.kgUser,\n        self.kgPassword,\n    )\n\n    # initialise the SPARQL client as None, this will be replaced when get_sparql_client() is first called\n    self.sparql_client = None\n\n    # initialise the logger\n    self.logger = agentlogging.get_logger('dev' if logger_for_dev else 'prod')\n\n    # initialise the email object and email_start_end_async_derivations flag\n    if all([bool(param) for param in [email_recipient, email_username, email_auth_json_path]]):\n        self.yag = yagmail.SMTP(email_username, oauth2_file=email_auth_json_path)\n        self.email_recipient = email_recipient.split(';')\n        self.email_subject_prefix = email_subject_prefix if bool(email_subject_prefix) else str(self.__class__.__name__)\n    else:\n        self.yag = None\n    self.email_start_end_async_derivations = email_start_end_async_derivations\n\n    # register the agent to the KG if required\n    self.register_agent = register_agent\n    try:\n        self.register_agent_in_kg()\n    except Exception as e:\n        self.logger.error(\n            \"Failed to register the agent &lt;{}&gt; to the KG &lt;{}&gt;. Error: {}\".format(self.__class__.agentIRI, self.kgUrl, e),\n            stack_info=True, exc_info=True)\n        raise e\n\n    self.logger.info(\n        \"DerivationAgent &lt;%s&gt; is initialised to monitor derivations in triple store &lt;%s&gt; with a time interval of %d seconds.\" % (\n            self.__class__.agentIRI, self.kgUrl, self.time_interval)\n    )\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.agent_input_concepts","title":"agent_input_concepts  <code>abstractmethod</code> <code>classmethod</code> <code>property</code>","text":"<pre><code>agent_input_concepts: List[Union[str, BaseClass]]\n</code></pre> <p>This method returns a list of input concepts of the agent. This should be overridden by the derived class.</p>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.agent_output_concepts","title":"agent_output_concepts  <code>abstractmethod</code> <code>classmethod</code> <code>property</code>","text":"<pre><code>agent_output_concepts: List[Union[str, BaseClass]]\n</code></pre> <p>This method returns a list of output concepts of the agent. This should be overridden by the derived class.</p>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.periodical_job","title":"periodical_job","text":"<pre><code>periodical_job(func)\n</code></pre> <p>This method is used to start a periodic job. This should be used as a decorator (@Derivation.periodical_job) for the method that needs to be executed periodically.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def periodical_job(func):\n    \"\"\"This method is used to start a periodic job. This should be used as a decorator (@Derivation.periodical_job) for the method that needs to be executed periodically.\"\"\"\n    def inner(self, *args, **kwargs):\n        func(self, *args, **kwargs)\n        if not self.scheduler.running:\n            self.scheduler.start()\n            self.logger.info(\"Scheduler is started.\")\n    inner.__is_periodical_job__ = True\n    return inner\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.send_email_when_exception","title":"send_email_when_exception","text":"<pre><code>send_email_when_exception(func_return_value=False)\n</code></pre> <p>Decorator to send an email when an exception occurs in the decorated method.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def send_email_when_exception(func_return_value=False):\n    \"\"\"Decorator to send an email when an exception occurs in the decorated method.\"\"\"\n    def decorator(func):\n        def inner(self, *args, **kwargs):\n            try:\n                if not func_return_value:\n                    func(self, *args, **kwargs)\n                else:\n                    return func(self, *args, **kwargs)\n            except Exception as e:\n                if self.yag is not None:\n                    self.send_email(\n                        f\"[{self.email_subject_prefix}] exception: {str(func.__name__)}\",\n                        [\n                            format_current_time(),\n                            # the \"&lt;\" and \"&gt;\" may exist in exception message if any IRI is presented, e.g. &lt;http://iri&gt;\n                            # here we replace them to HTML entities, so that the IRIs can be displayed correctly\n                            # for more information about HTML entities, visit https://www.w3schools.com/html/html_entities.asp\n                            str(e).replace(\"&lt;\", \"&amp;lt;\").replace(\"&gt;\", \"&amp;gt;\"),\n                            traceback.format_exc()\n                        ]\n                    )\n                # Log error regardless\n                self.logger.exception(e)\n        return inner\n    return decorator\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.send_email","title":"send_email","text":"<pre><code>send_email(subject: str, contents: list)\n</code></pre> <p>Sends an email notification with the given subject and contents.</p> <p>Parameters:</p> Name Type Description Default <code>subject</code> <code>str</code> <p>The subject of the email</p> required <code>contents</code> <code>list</code> <p>The contents of the email</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def send_email(self, subject: str, contents: list):\n    \"\"\"\n    Sends an email notification with the given subject and contents.\n\n    Args:\n        subject (str): The subject of the email\n        contents (list): The contents of the email\n    \"\"\"\n    timeout = 2\n    process_email = Process(target=self.yag.send, args=(self.email_recipient, subject, contents))\n    process_email.start()\n    process_email.join(timeout=timeout)\n    if process_email.is_alive():\n        process_email.kill()\n        process_email.join()\n    if process_email.exitcode != 0:\n        self.logger.error(f\"Timed out sending email notification after {timeout} seconds.\\n Recipient: {self.email_recipient}\\n Subject: {subject}\\n Contents: {contents}\")\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.send_email_when_async_derivation_up_to_date","title":"send_email_when_async_derivation_up_to_date","text":"<pre><code>send_email_when_async_derivation_up_to_date(derivation_iri: str)\n</code></pre> <p>Sends an email notification when an asynchronous derivation is up-to-date.</p> <p>Parameters:</p> Name Type Description Default <code>derivation_iri</code> <code>str</code> <p>The IRI of the derivation that was processed</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def send_email_when_async_derivation_up_to_date(self, derivation_iri: str):\n    \"\"\"\n    Sends an email notification when an asynchronous derivation is up-to-date.\n\n    Args:\n        derivation_iri (str): The IRI of the derivation that was processed\n    \"\"\"\n    if self.yag is not None and self.email_start_end_async_derivations:\n        self.send_email(\n            f\"[{self.email_subject_prefix}] async derivation up-to-date\",\n            [format_current_time(), f\"{derivation_iri}\"]\n        )\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.send_email_when_async_derivation_started","title":"send_email_when_async_derivation_started","text":"<pre><code>send_email_when_async_derivation_started(derivation_iri)\n</code></pre> <p>Sends an email notification when an asynchronous derivation starts.</p> <p>Parameters:</p> Name Type Description Default <code>derivation_iri</code> <code>str</code> <p>The IRI of the derivation that was processed</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def send_email_when_async_derivation_started(self, derivation_iri):\n    \"\"\"\n    Sends an email notification when an asynchronous derivation starts.\n\n    Args:\n        derivation_iri (str): The IRI of the derivation that was processed\n    \"\"\"\n    if self.yag is not None and self.email_start_end_async_derivations:\n        self.send_email(\n            f\"[{self.email_subject_prefix}] async derivation now-in-progress\",\n            [format_current_time(), f\"{derivation_iri}\"]\n        )\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.get_sparql_client","title":"get_sparql_client","text":"<pre><code>get_sparql_client(sparql_client_cls: Type[PY_SPARQL_CLIENT]) -&gt; PY_SPARQL_CLIENT\n</code></pre> <p>Returns a SPARQL client object that instantiated from sparql_client_cls, which should extend PySparqlClient class.</p> <p>Parameters:</p> Name Type Description Default <code>sparql_client_cls</code> <code>Type[PY_SPARQL_CLIENT]</code> <p>The SPARQL client class</p> required <p>Returns:</p> Name Type Description <code>PY_SPARQL_CLIENT</code> <code>PY_SPARQL_CLIENT</code> <p>An instance of the SPARQL client</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def get_sparql_client(self, sparql_client_cls: Type[PY_SPARQL_CLIENT]) -&gt; PY_SPARQL_CLIENT:\n    \"\"\"\n    Returns a SPARQL client object that instantiated from sparql_client_cls, which should extend PySparqlClient class.\n\n    Args:\n        sparql_client_cls (Type[PY_SPARQL_CLIENT]): The SPARQL client class\n\n    Returns:\n        PY_SPARQL_CLIENT: An instance of the SPARQL client\n    \"\"\"\n    if self.sparql_client is None or not isinstance(self.sparql_client, sparql_client_cls):\n        self.sparql_client = sparql_client_cls(\n            query_endpoint=self.kgUrl, update_endpoint=self.kgUpdateUrl,\n            kg_user=self.kgUser, kg_password=self.kgPassword,\n            fs_url=self.fs_url, fs_user=self.fs_user, fs_pwd=self.fs_password\n        )\n    return self.sparql_client\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.register_agent_in_kg","title":"register_agent_in_kg","text":"<pre><code>register_agent_in_kg()\n</code></pre> <p>This method registers the agent to the knowledge graph by uploading its OntoAgent triples generated on-the-fly.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def register_agent_in_kg(self):\n    \"\"\"This method registers the agent to the knowledge graph by uploading its OntoAgent triples generated on-the-fly.\"\"\"\n    if self.register_agent:\n        input_concepts = self.agent_input_concepts\n        output_concepts = self.agent_output_concepts\n        if not isinstance(input_concepts, list) or not isinstance(output_concepts, list):\n            raise Exception(\"Failed to proceed with registering the agent &lt;{}&gt; to the KG &lt;{}&gt;. Error: Input and output concepts must be lists. Received: {} (type: {}) and {} (type: {})\".format(\n                self.__class__.agentIRI, self.kgUrl, input_concepts, type(input_concepts), output_concepts, type(output_concepts)))\n        if len(input_concepts) == 0 or len(output_concepts) == 0:\n            raise Exception(\"Failed to proceed with registering the agent &lt;{}&gt; to the KG &lt;{}&gt;. Error: No input or output concepts specified.\".format(self.__class__.agentIRI, self.kgUrl))\n        input_concepts_iris = [o if isinstance(o, str) else o.rdf_type for o in input_concepts]\n        output_concepts_iris = [o if isinstance(o, str) else o.rdf_type for o in output_concepts]\n        self.derivation_client.createOntoAgentInstance(self.__class__.agentIRI, self.syncDerivationEndpoint, input_concepts_iris, output_concepts_iris)\n        self.logger.info(\"Agent &lt;%s&gt; is registered to the KG &lt;%s&gt; with input signature %s and output signature %s.\" % (\n            self.__class__.agentIRI, self.kgUrl, input_concepts, output_concepts))\n    else:\n        self.logger.info(\"Flag register_agent is False. Agent &lt;%s&gt; is NOT registered to the KG &lt;%s&gt;.\" % (self.__class__.agentIRI, self.kgUrl))\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.add_url_pattern","title":"add_url_pattern","text":"<pre><code>add_url_pattern(url_pattern: str = None, url_pattern_name: str = None, function: RouteCallable = None, methods: str = ['GET'], *args, **kwargs)\n</code></pre> <p>This method is a wrapper of add_url_rule method of Flask object that adds customised URL Pattern to derivation agent. For more information, visit https://flask.palletsprojects.com/en/3.0.x/api/#flask.Flask.add_url_rule WARNING: Use of this by developer is STRONGLY discouraged. The design intention of an derivation agent is to communicate via the KNOWLEDGE GRAPH, and NOT via HTTP requests.</p> <p>Parameters:</p> Name Type Description Default <code>url_pattern</code> <code>str</code> <p>the endpoint url to associate with the rule and view function</p> <code>None</code> <code>url_pattern_name</code> <code>str</code> <p>the name of the endpoint</p> <code>None</code> <code>function</code> <code>RouteCallable</code> <p>the view function to associate with the endpoint</p> <code>None</code> <code>methods</code> <code>str</code> <p>HTTP request methods, default to ['GET']</p> <code>['GET']</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def add_url_pattern(\n    self,\n    url_pattern: str = None,\n    url_pattern_name: str = None,\n    function: RouteCallable = None,\n    methods: str = ['GET'],\n    *args,\n    **kwargs\n):\n    \"\"\"\n    This method is a wrapper of add_url_rule method of Flask object that adds customised URL Pattern to derivation agent.\n    For more information, visit https://flask.palletsprojects.com/en/3.0.x/api/#flask.Flask.add_url_rule\n    WARNING: Use of this by developer is STRONGLY discouraged.\n    The design intention of an derivation agent is to communicate via the KNOWLEDGE GRAPH, and NOT via HTTP requests.\n\n    Args:\n        url_pattern (str): the endpoint url to associate with the rule and view function\n        url_pattern_name (str): the name of the endpoint\n        function (flask.typing.RouteCallable): the view function to associate with the endpoint\n        methods (str): HTTP request methods, default to ['GET']\n    \"\"\"\n    self.app.add_url_rule(url_pattern, url_pattern_name,\n                          function, methods=methods, *args, **kwargs)\n    self.logger.info(f\"A URL Pattern &lt;{url_pattern}&gt; is added.\")\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.monitor_async_derivations","title":"monitor_async_derivations","text":"<pre><code>monitor_async_derivations()\n</code></pre> <p>This method monitors the status of the asynchronous derivation that \"isDerivedUsing\" DerivationAgent.</p> <p>When it detects the status is \"Requested\", the agent will mark the status as \"InProgress\" and start the job. Once the job is finished, the agent marks the status as \"Finished\" and attaches the new derived IRI to it via \"hasNewDerivedIRI\". All new generated triples are also written to the knowledge graph at this point.</p> <p>When it detects the status is \"InProgress\", the currently implementation just passes.</p> <p>When it detects the status is \"Finished\", the agent deletes the old entities, reconnects the new instances (previously attached to the status via \"hasNewDerivedIRI\") with the original derivation, cleans up all the status, and finally updates the timestamp of the derivation. All these processing steps at the <code>Finished</code> status are taken care of by method <code>uk.ac.cam.cares.jps.base.derivation.DerivationClient.cleanUpFinishedDerivationUpdate(String)</code>.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>@send_email_when_exception(func_return_value=False)\ndef monitor_async_derivations(self):\n    \"\"\"\n    This method monitors the status of the asynchronous derivation that \"isDerivedUsing\" DerivationAgent.\n\n    When it detects the status is \"Requested\", the agent will mark the status as \"InProgress\" and start the job.\n    Once the job is finished, the agent marks the status as \"Finished\" and attaches the new derived IRI to it via \"hasNewDerivedIRI\".\n    All new generated triples are also written to the knowledge graph at this point.\n\n    When it detects the status is \"InProgress\", the currently implementation just passes.\n\n    When it detects the status is \"Finished\", the agent deletes the old entities,\n    reconnects the new instances (previously attached to the status via \"hasNewDerivedIRI\") with the original derivation,\n    cleans up all the status, and finally updates the timestamp of the derivation.\n    All these processing steps at the `Finished` status are taken care of by method\n    `uk.ac.cam.cares.jps.base.derivation.DerivationClient.cleanUpFinishedDerivationUpdate(String)`.\n    \"\"\"\n\n    # Below codes follow the logic as defined in DerivationAgent.java in JPS_BASE_LIB\n    # for more information, please visit https://github.com/cambridge-cares/TheWorldAvatar/blob/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/agent/DerivationAgent.java\n\n    # Initialise two conditions for the while loop\n    # 1. break_out_time is the timestamp when the next round of monitoring should be started\n    break_out_time = time.time() + self.time_interval\n    # 2. query_again is the flag to indicate whether the derivation status should be updated in memory\n    query_again = False\n\n    # There is no do-while loop in Python, so we use a while loop with a break statement\n    # \"while True\" makes sure the loop is executed at least once\n    while True:\n        # Retrieves a list of derivations and their status type that \"isDerivedUsing\" DerivationAgent\n        derivationAndStatusType = self.derivation_client.derivation_client.getDerivationsAndStatusType(\n            self.agentIRI)\n        if bool(derivationAndStatusType):\n            self.logger.info(\"A list of asynchronous derivations that &lt;isDerivedUsing&gt; &lt;%s&gt; are retrieved: %s.\" % (\n                self.agentIRI, {d: str(derivationAndStatusType[d]) for d in derivationAndStatusType}))\n\n            # Iterate over the list of derivation, and do different things depend on the derivation status\n            for derivation in derivationAndStatusType:\n                statusType = str(derivationAndStatusType[derivation])\n\n                try:\n                    # If \"Requested\", check the immediate upstream derivations if they are up-to-date\n                    # if any of the asynchronous derivations are still outdated, skip, otherwise, request update of all synchronous derivations\n                    # then retrieve inputs, marks as \"InProgress\", start job, update status at job completion\n                    if statusType == 'REQUESTED':\n                        immediateUpstreamDerivationToUpdate = self.derivation_client.derivation_client.checkImmediateUpstreamDerivation(derivation)\n                        if self.jpsBaseLib_view.DerivationSparql.ONTODERIVATION_DERIVATIONASYN in immediateUpstreamDerivationToUpdate:\n                            self.logger.info(\"Asynchronous derivation &lt;\" + derivation\n                                            + \"&gt; has a list of immediate upstream asynchronous derivations to be updated: \"\n                                            + str(immediateUpstreamDerivationToUpdate))\n                            # set flag to false to skips this \"Requested\" derivation until next time\n                            # this is to avoid the agent flooding the KG with queries of the status over a short period of time\n                            query_again = False\n                        else:\n                            syncDerivationsToUpdate = self.derivation_client.derivation_client.groupSyncDerivationsToUpdate(immediateUpstreamDerivationToUpdate)\n                            if bool(syncDerivationsToUpdate):\n                                self.logger.info(\"Asynchronous derivation &lt;\" + derivation\n                                                + \"&gt; has a list of immediate upstream synchronous derivations to be updated: \"\n                                                + str(syncDerivationsToUpdate))\n                                self.derivation_client.derivation_client.updatePureSyncDerivations(syncDerivationsToUpdate)\n                                self.logger.info(\"Update of synchronous derivation is done for: \" + str(syncDerivationsToUpdate))\n                            if not bool(self.derivation_client.derivation_client.checkImmediateUpstreamDerivation(derivation)):\n                                agentInputs = str(self.derivation_client.derivation_client.retrieveAgentInputIRIs(derivation, self.agentIRI))\n                                # Mark the status as \"InProgress\"\n                                # if another agent thread is updating the same derivation concurrently\n                                # and successed before this thread, then this method will return false\n                                progressToJob = self.derivation_client.derivation_client.updateStatusBeforeSetupJob(derivation)\n                                # only progress to job if the status is updated successfully\n                                # otherwise, the other thread will handle the job\n                                if not progressToJob:\n                                    self.logger.info(f\"Asynchronous derivation &lt;{derivation}&gt; is already in progress by another agent thread.\")\n                                else:\n                                    self.logger.info(\"Agent &lt;%s&gt; retrieved inputs of asynchronous derivation &lt;%s&gt;: %s.\" % (\n                                        self.agentIRI, derivation, agentInputs))\n                                    self.logger.info(\"Asynchronous derivation &lt;%s&gt; is in progress.\" % (derivation))\n                                    # send email to indicate the derivation is handled in this thread and started, i.e. now-in-progress\n                                    self.send_email_when_async_derivation_started(derivation)\n\n                                    # Preprocessing inputs to be sent to agent for setting up job, this is now in dict datatype\n                                    agent_input_json = json.loads(agentInputs) if not isinstance(agentInputs, dict) else agentInputs\n                                    agent_input_key = str(self.jpsBaseLib_view.DerivationClient.AGENT_INPUT_KEY)\n                                    if agent_input_key in agent_input_json:\n                                        inputs_to_send = agent_input_json[agent_input_key]\n                                    else:\n                                        self.logger.error(\"Agent input key (%s) might be missing. Received input: %s.\" % (\n                                            agent_input_key, agent_input_json.__dict__))\n                                    # The inputs_to_send should be a key-values pair format,\n                                    # for example: {'OntoXX:Concept_A': ['Instance_A'], 'OntoXX:Concept_B': ['Instance_B']}\n                                    derivationInputs = self.jpsBaseLib_view.DerivationInputs(inputs_to_send, derivation)\n                                    derivation_inputs = DerivationInputs(derivationInputs)\n                                    derivationOutputs = self.jpsBaseLib_view.DerivationOutputs()\n                                    derivation_outputs = DerivationOutputs(derivationOutputs)\n                                    self.process_request_parameters(derivation_inputs, derivation_outputs)\n\n                                    newDerivedIRI = derivationOutputs.getNewDerivedIRI()\n                                    newTriples = derivationOutputs.getOutputTriples()\n                                    self.derivation_client.derivation_client.updateStatusAtJobCompletion(derivation, newDerivedIRI, newTriples)\n                                    self.logger.info(\"Asynchronous derivation &lt;%s&gt; generated new derived IRI: &lt;%s&gt;.\" % (\n                                        derivation, \"&gt;, &lt;\".join(newDerivedIRI)))\n                                    self.logger.info(\"Asynchronous derivation &lt;\" + derivation +\n                                                    \"&gt; has all new generated triples: \" + str([t.getQueryString() for t in newTriples]))\n                                    self.logger.info(\"Asynchronous derivation &lt;\" + derivation + \"&gt; is now finished, to be cleaned up.\")\n\n                            # set flag to true as either (1) the agent has been process this derivation for some time\n                            # and status of other derivations in KG might have changed by other processes during this time\n                            # or (2) the derivation is processed by another agent therefore needs a record update\n                            query_again = True\n\n                    # If \"InProgress\", pass\n                    elif statusType == 'INPROGRESS':\n                        # the query_again flag is set as false to let agent carry on to next derivation in the list\n                        query_again = False\n\n                    # If \"Finished\", do all the clean-up steps\n                    elif statusType == 'FINISHED':\n                        self.derivation_client.derivation_client.cleanUpFinishedDerivationUpdate(derivation)\n                        # set flag to true as the cleaning up process can take some time when there are a lot of triples\n                        query_again = True\n                        # send email to indicate the derivation is now finished and cleaned up, i.e. up-to-date\n                        self.send_email_when_async_derivation_up_to_date(derivation)\n\n                    elif statusType == 'ERROR':\n                        # for now just passes\n                        query_again = False\n\n                    elif statusType == 'NOSTATUS':\n                        # no need to query_again as the derivation is considered as up-to-date\n                        query_again = False\n\n                    # If anything else, pass\n                    else:\n                        self.logger.info(\"Asynchronous derivation &lt;%s&gt; has unhandled status type: %s.\" % (\n                            derivation, statusType))\n                        query_again = False\n\n                except Exception as exc:\n                    trace_back = traceback.format_exc()\n                    jps_exc = PythonException(trace_back)\n                    self.derivation_client.derivation_client.markAsError(derivation, jps_exc.exception)\n                    query_again = True\n                    self.logger.error(f\"Error when handling derivation &lt;{derivation}&gt;\", stack_info=True, exc_info=True)\n                    # Raise exception so that this will be sent via email notification\n                    raise exc\n\n                # Break out the for loop and query again the list of derivations and their status\n                if query_again:\n                    break\n\n        else:\n            self.logger.info(\"Currently, no asynchronous derivation &lt;isDerivedUsing&gt; &lt;%s&gt;.\" % (self.agentIRI))\n\n        # Check if the two flags are still met, if not, break out the while loop\n        # i.e. process until the time is up and if have not gone through all derivations\n        if time.time() &gt; break_out_time or not query_again:\n            break\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.process_request_parameters","title":"process_request_parameters  <code>abstractmethod</code>","text":"<pre><code>process_request_parameters(derivation_inputs: DerivationInputs, derivation_outputs: DerivationOutputs)\n</code></pre> <p>This method perform the agent logic of converting derivation inputs to derivation outputs. Developer shall override this when writing new derivation agent based on DerivationAgent class.</p> <p>Parameters:</p> Name Type Description Default <code>derivation_inputs</code> <code>DerivationInputs</code> <p>instance of derivation inputs, essentially in the format of: {     \"https://example.com/kg/Concept_1\": [\"https://example.com/kg/Concept_1/Instance_1\"],     \"https://example.com/kg/Concept_2\": [\"https://example.com/kg/Concept_2/Instance_2\"],     \"https://example.com/kg/Concept_3\":     [\"https://example.com/kg/Concept_3/Instance_3_1\",         \"https://example.com/kg/Concept_3/Instance_3_2\"],     \"https://example.com/kg/Concept_4\": [\"https://example.com/kg/Concept_4/Instance_4\"] }</p> required <code>derivation_outputs</code> <code>DerivationOutputs</code> <p>instance of derivation outputs, developer should add new created entiteis and triples to this variable</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>@abstractmethod\ndef process_request_parameters(self, derivation_inputs: DerivationInputs, derivation_outputs: DerivationOutputs):\n    \"\"\"\n    This method perform the agent logic of converting derivation inputs to derivation outputs.\n    Developer shall override this when writing new derivation agent based on DerivationAgent class.\n\n    Args:\n        derivation_inputs (DerivationInputs): instance of derivation inputs, essentially in the format of:\n            {\n                \"https://example.com/kg/Concept_1\": [\"https://example.com/kg/Concept_1/Instance_1\"],\n                \"https://example.com/kg/Concept_2\": [\"https://example.com/kg/Concept_2/Instance_2\"],\n                \"https://example.com/kg/Concept_3\":\n                [\"https://example.com/kg/Concept_3/Instance_3_1\",\n                    \"https://example.com/kg/Concept_3/Instance_3_2\"],\n                \"https://example.com/kg/Concept_4\": [\"https://example.com/kg/Concept_4/Instance_4\"]\n            }\n        derivation_outputs (DerivationOutputs): instance of derivation outputs, developer should add new created entiteis and triples to this variable\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.start_all_periodical_job","title":"start_all_periodical_job","text":"<pre><code>start_all_periodical_job()\n</code></pre> <p>This method starts all scheduled periodical jobs.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def start_all_periodical_job(self):\n    \"\"\"This method starts all scheduled periodical jobs.\"\"\"\n    all_periodical_jobs = [getattr(self, name) for name in dir(self) if callable(getattr(self, name)) and not name.startswith('__') and hasattr(getattr(self, name), '__is_periodical_job__')]\n    for func in all_periodical_jobs:\n        func()\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.handle_sync_derivations","title":"handle_sync_derivations","text":"<pre><code>handle_sync_derivations()\n</code></pre> <p>This method handles synchronous derivation by using the Flask app object of the DerivationAgent to process the HTTP request, and then pass it to <code>process_request_parameters</code> function provided by the developers.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>@send_email_when_exception(func_return_value=True)\ndef handle_sync_derivations(self):\n    \"\"\"\n    This method handles synchronous derivation by using the Flask app object of the DerivationAgent to process the HTTP request,\n    and then pass it to `process_request_parameters` function provided by the developers.\n    \"\"\"\n    self.logger.info(\"Received synchronous derivation request: %s.\" % (request.url))\n    requestParams = request.json\n    res = {}\n    if self.validate_inputs(requestParams):\n        # retrieve necessary information\n        derivationIRI = requestParams[self.jpsBaseLib_view.DerivationClient.DERIVATION_KEY]\n        derivationType = requestParams[self.jpsBaseLib_view.DerivationClient.DERIVATION_TYPE_KEY]\n        syncNewInfoFlag = requestParams[self.jpsBaseLib_view.DerivationClient.SYNC_NEW_INFO_FLAG]\n\n        # serialises DerivationInputs objects from JSONObject\n        inputs = self.jpsBaseLib_view.DerivationInputs(requestParams[self.jpsBaseLib_view.DerivationClient.AGENT_INPUT_KEY], derivationIRI)\n        self.logger.info(\"Received derivation request parameters: \" + str(requestParams))\n\n        # initialise DerivationOutputs, also set up information\n        outputs = self.jpsBaseLib_view.DerivationOutputs()\n        outputs.setThisDerivation(derivationIRI)\n        outputs.setRetrievedInputsAt(int(time.time()))\n        if not syncNewInfoFlag:\n            outputs.setOldEntitiesMap(requestParams[self.jpsBaseLib_view.DerivationClient.BELONGSTO_KEY])\n            outputs.setOldEntitiesDownstreamDerivationMap(requestParams[self.jpsBaseLib_view.DerivationClient.DOWNSTREAMDERIVATION_KEY])\n\n        # apply agent logic to convert inputs to outputs\n        derivation_inputs = DerivationInputs(inputs)\n        derivation_outputs = DerivationOutputs(outputs)\n        self.process_request_parameters(derivation_inputs, derivation_outputs)\n\n        # return response if this sync derivation is generated for new info\n        if syncNewInfoFlag:\n            agentServiceIRI = requestParams[self.jpsBaseLib_view.DerivationClient.AGENT_IRI_KEY]\n            self.derivation_client.derivation_client.writeSyncDerivationNewInfo(\n                outputs.getOutputTriples(), outputs.getNewDerivedIRI(),\n                agentServiceIRI, inputs.getAllIris(),\n                derivationIRI, derivationType, outputs.getRetrievedInputsAt()\n            )\n            res[self.jpsBaseLib_view.DerivationOutputs.RETRIEVED_INPUTS_TIMESTAMP_KEY] = outputs.getRetrievedInputsAt()\n            res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_KEY] = json.loads(str(outputs.getNewEntitiesJsonMap()))\n            self.logger.info(\"Synchronous derivation for new information generated successfully, returned response: \" + str(res))\n            return json.dumps(res)\n\n        # only enters below if the computation was not for new information (new instances)\n        derivation = self.jpsBaseLib_view.Derivation(derivationIRI, derivationType)\n        if not derivation.isDerivationAsyn() and not derivation.isDerivationWithTimeSeries():\n            # Perform the mapping between the new outputs and the downstream derivations\n            connectionMap = self.derivation_client.derivation_client.mapSyncNewOutputsToDownstream(\n                outputs.getThisDerivation(), outputs.getNewOutputsAndRdfTypeMap())\n            # construct and fire SPARQL update given DerivationOutputs objects, if normal\n            # derivation NOTE this makes sure that the new generated instances/triples will\n            # ONLY be written to knowledge graph if the target derivation is till outdated\n            # at the point of executing SPARQL update, i.e. this solves concurrent request\n            # issue as detailed in\n            # https://github.com/cambridge-cares/TheWorldAvatar/issues/184\n            triplesChangedForSure = self.derivation_client.derivation_client.reconnectSyncDerivation(\n                outputs.getThisDerivation(), connectionMap,\n                outputs.getOutputTriples(), outputs.getRetrievedInputsAt()\n            )\n\n            # for normal Derivation, we need to return both timestamp and the new derived\n            if triplesChangedForSure:\n                # if we know the triples are changed for sure, we return the triples\n                # computed by this agent\n                res[self.jpsBaseLib_view.DerivationOutputs.RETRIEVED_INPUTS_TIMESTAMP_KEY] = outputs.getRetrievedInputsAt()\n                res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_KEY] = json.loads(str(outputs.getNewEntitiesJsonMap()))\n                res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_CONNECTION_KEY] = json.loads(str(self.jpsBaseLib_view.org.json.JSONObject(connectionMap)))\n                self.logger.info(\"Derivation update is done in the knowledge graph, returned response: \" + str(res))\n            else:\n                # if we are not certain, query the knowledge graph to get the accurate\n                # information\n                updated = self.derivation_client.derivation_client.getDerivation(derivationIRI)\n                res[self.jpsBaseLib_view.DerivationOutputs.RETRIEVED_INPUTS_TIMESTAMP_KEY] = updated.getTimestamp()\n                res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_KEY] = json.loads(str(updated.getBelongsToMap()))\n                res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_CONNECTION_KEY] = json.loads(str(updated.getDownstreamDerivationConnectionMap()))\n                self.logger.info(\"Unable to determine if the SPARQL update mutated triples, returned latest information in knowledge graph: \"\n                                 + str(res))\n        else:\n            # for DerivationWithTimeSeries, we just need to return retrievedInputsAt\n            res[self.jpsBaseLib_view.DerivationOutputs.RETRIEVED_INPUTS_TIMESTAMP_KEY] = outputs.getRetrievedInputsAt()\n            self.logger.info(\n                \"DerivationWithTimeSeries update is done, returned response: \" + str(res))\n    else:\n        res[self.jpsBaseLib_view.DerivationClient.AGENT_OUTPUT_KEY] = self.jpsBaseLib_view.DerivationAgent.EMPTY_REQUEST_MSG\n\n    return json.dumps(res)\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.validate_inputs","title":"validate_inputs  <code>abstractmethod</code>","text":"<pre><code>validate_inputs(http_request) -&gt; bool\n</code></pre> <p>Validates the HTTP request sent to the agent for processing synchronous derivations. Developer can overwrite this function for customised validation.</p> <p>Parameters:</p> Name Type Description Default <code>http_request</code> <p>The HTTP request received</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>HTTP request is empty</p> <code>Exception</code> <p>IRI for derivation is not provided in the HTTP request</p> <code>Exception</code> <p>IRI for agent is not provided in the HTTP request</p> <code>Exception</code> <p>IRI for old derivation outputs are not provided in the HTTP request</p> <code>Exception</code> <p>IRI for downstream derivations are not provided in the HTTP request</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the HTTP request is valid</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>@abstractmethod\ndef validate_inputs(self, http_request) -&gt; bool:\n    \"\"\"\n    Validates the HTTP request sent to the agent for processing synchronous derivations.\n    Developer can overwrite this function for customised validation.\n\n    Args:\n        http_request: The HTTP request received\n\n    Raises:\n        Exception: HTTP request is empty\n        Exception: IRI for derivation is not provided in the HTTP request\n        Exception: IRI for agent is not provided in the HTTP request\n        Exception: IRI for old derivation outputs are not provided in the HTTP request\n        Exception: IRI for downstream derivations are not provided in the HTTP request\n\n    Returns:\n        bool: Whether the HTTP request is valid\n    \"\"\"\n    self.logger.info(\"Validating inputs: \" + str(http_request))\n    if not bool(http_request):\n        self.logger.warn(\"RequestParams are empty, throwing BadRequestException...\")\n        raise Exception(\"RequestParams are empty\")\n\n    if self.jpsBaseLib_view.DerivationClient.AGENT_INPUT_KEY not in http_request:\n        self.logger.info(f\"Agent &lt;{self.agentIRI}&gt; received an empty request...\")\n        return False\n    else:\n        if self.jpsBaseLib_view.DerivationClient.DERIVATION_KEY not in http_request:\n            msg = f\"Agent &lt;{self.agentIRI}&gt; received a request that doesn't have derivationIRI...\"\n            self.logger.error(msg)\n            raise Exception(msg)\n        if http_request[self.jpsBaseLib_view.DerivationClient.SYNC_NEW_INFO_FLAG]:\n            if self.jpsBaseLib_view.DerivationClient.AGENT_IRI_KEY not in http_request:\n                msg = f\"Agent &lt;{self.agentIRI}&gt; received a request for sync new information that doesn't have information about agent IRI...\"\n                self.logger.error(msg)\n                raise Exception(msg)\n        else:\n            if self.jpsBaseLib_view.DerivationClient.BELONGSTO_KEY not in http_request:\n                msg = f\"Agent &lt;{self.agentIRI}&gt; received a request that doesn't have information about old outputs...\"\n                self.logger.error(msg)\n                raise Exception(msg)\n            if self.jpsBaseLib_view.DerivationClient.DOWNSTREAMDERIVATION_KEY not in http_request:\n                msg = f\"Agent &lt;{self.agentIRI}&gt; received a request that doesn't have information about downstream derivation...\"\n                self.logger.error(msg)\n                raise Exception(msg)\n\n    return True\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.DerivationAgent.run_flask_app","title":"run_flask_app","text":"<pre><code>run_flask_app(**kwargs)\n</code></pre> <p>This method runs the flask app as an HTTP servlet.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def run_flask_app(self, **kwargs):\n    \"\"\"This method runs the flask app as an HTTP servlet.\"\"\"\n    self.app.run(**kwargs)\n</code></pre>"},{"location":"api/derivation_agent/#twa.agent.derivation_agent.format_current_time","title":"format_current_time","text":"<pre><code>format_current_time() -&gt; str\n</code></pre> <p>Formats the current local time as a string.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The current local time in the format \"YYYY-MM-DD HH:MM:SS TIMEZONE\".</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agent/derivation_agent.py</code> <pre><code>def format_current_time() -&gt; str:\n    \"\"\"\n    Formats the current local time as a string.\n\n    Returns:\n        str: The current local time in the format \"YYYY-MM-DD HH:MM:SS TIMEZONE\".\n    \"\"\"\n    return str(time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())) + f\" {str(time.localtime().tm_zone)}\"\n</code></pre>"},{"location":"api/derivation_client/","title":"Derivation Client","text":""},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient","title":"PyDerivationClient","text":"<pre><code>PyDerivationClient(derivation_instance_base_url: str, query_endpoint: str, update_endpoint: str, kg_user: str = None, kg_password: str = None)\n</code></pre> <p>This is a wrapper class for the java class <code>uk.ac.cam.cares.jps.base.derivation.DerivationClient</code>. Only the methods that commonly used are wrapped here. For other methods, one may access them via <code>self.derivation_client.nameOfJavaMethod(args)</code>.</p> <p>Attributes:</p> Name Type Description <code>derivation_client</code> <p>The Java DerivationClient object</p> <code>jpsBaseLib_view</code> <p>The JVM module view for accessing Java classes</p> <p>Methods:</p> Name Description <code>createDerivation</code> <p>Create a normal derivation markup.</p> <code>createSyncDerivationForNewInfo</code> <p>Create a synchronous derivation for new info to be computed by the agent.</p> <code>createSyncDerivationForNewInfoWithHttpUrl</code> <p>Create a synchronous derivation for new info to be computed by the agent with the agent URL provided.</p> <code>bulkCreateDerivations</code> <p>Create multiple normal derivations in one go.</p> <code>createDerivationWithTimeSeries</code> <p>Create a time series derivation markup.</p> <code>bulkCreateDerivationsWithTimeSeries</code> <p>Create multiple time series derivations in one go.</p> <code>createAsyncDerivation</code> <p>Create an asynchronous derivation markup.</p> <code>createAsyncDerivationFromDerivation</code> <p>Create an asynchronous derivation markup from an existing derivation.</p> <code>bulkCreateAsyncDerivations</code> <p>Create multiple asynchronous derivations in one go.</p> <code>createAsyncDerivationForNewInfo</code> <p>Create an asynchronous derivation markup for new information.</p> <code>bulkCreateAsyncDerivationsForNewInfo</code> <p>Create multiple asynchronous derivations for new information in one go.</p> <code>validateDerivations</code> <p>Validate all derivations and their inputs are attached with timestamps, also no circular dependencies.</p> <code>createOntoAgentInstance</code> <p>Register an OntoAgent instance in the triple store.</p> <code>addTimeInstance</code> <p>Add a time instance to each entity in the list of entities.</p> <code>addTimeInstanceCurrentTimestamp</code> <p>Add time instance with current timestamp to the given entities.</p> <code>updateTimestamp</code> <p>Update the timestamp of the entity to the current time.</p> <code>updateTimestamps</code> <p>Update the timestamp of all entities in the list.</p> <code>dropTimestampsOf</code> <p>Drop the timestamp of the given entities.</p> <code>getDerivations</code> <p>Get the derivations of the given agent.</p> <code>getDerivationsOf</code> <p>Get the derivations of the given entities.</p> <code>unifiedUpdateDerivation</code> <p>Unified update derivation method.</p> <code>updatePureSyncDerivation</code> <p>Update a single synchronous derivation.</p> <code>updatePureSyncDerivations</code> <p>Update a list of synchronous derivations.</p> <code>updatePureSyncDerivationsInParallel</code> <p>Update a list of synchronous derivations in parallel.</p> <code>updateAllSyncDerivations</code> <p>Update all synchronous derivations within the knowledge graph.</p> <code>updateMixedAsyncDerivation</code> <p>Update a directed acyclic graph of a-/sync derivations.</p> <p>Parameters:</p> Name Type Description Default <code>derivation_instance_base_url</code> <code>str</code> <p>base url of the derivation instance to be created by the client</p> required <code>query_endpoint</code> <code>str</code> <p>query endpoint of the knowledge graph</p> required <code>update_endpoint</code> <code>str</code> <p>update endpoint of the knowledge graph</p> required <code>kg_user</code> <code>str</code> <p>username for the knowledge graph endpoint. Defaults to None.</p> <code>None</code> <code>kg_password</code> <code>str</code> <p>password for the knowledge graph endpoint. Defaults to None.</p> <code>None</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def __init__(\n    self,\n    derivation_instance_base_url: str,\n    query_endpoint: str,\n    update_endpoint: str,\n    kg_user:str=None,\n    kg_password:str=None\n) -&gt; None:\n    \"\"\"\n    Initialise the derivation client\n\n    Args:\n        derivation_instance_base_url (str): base url of the derivation instance to be created by the client\n        query_endpoint (str): query endpoint of the knowledge graph\n        update_endpoint (str): update endpoint of the knowledge graph\n        kg_user (str, optional): username for the knowledge graph endpoint. Defaults to None.\n        kg_password (str, optional): password for the knowledge graph endpoint. Defaults to None.\n    \"\"\"\n\n    # create a JVM module view and use it to import the required java classes\n    self.jpsBaseLib_view = jpsBaseLibGW.createModuleView()\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view,\"uk.ac.cam.cares.jps.base.query.*\")\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view,\"uk.ac.cam.cares.jps.base.derivation.*\")\n\n    # create store_client\n    if kg_user is None:\n        store_client = self.jpsBaseLib_view.RemoteStoreClient(query_endpoint, update_endpoint)\n    else:\n        store_client = self.jpsBaseLib_view.RemoteStoreClient(\n            query_endpoint, update_endpoint, kg_user, kg_password)\n\n    # create derivation_client\n    self.derivation_client = self.jpsBaseLib_view.DerivationClient(store_client, derivation_instance_base_url)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createDerivation","title":"createDerivation","text":"<pre><code>createDerivation(entities: List[str], agentIRI: str, inputs: List[str]) -&gt; str\n</code></pre> <p>Create a normal derivation markup.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of entities that belongsTo the derivation</p> required <code>agentIRI</code> <code>str</code> <p>List of agents that the derivation isDerivedUsing</p> required <code>inputs</code> <code>List[str]</code> <p>List of inputs that the derivation isDerivedFrom</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the created derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createDerivation(\n    self,\n    entities: List[str],\n    agentIRI: str,\n    inputs: List[str]\n) -&gt; str:\n    \"\"\"\n    Create a normal derivation markup.\n\n    Args:\n        entities (List[str]): List of entities that belongsTo the derivation\n        agentIRI (str): List of agents that the derivation isDerivedUsing\n        inputs (List[str]): List of inputs that the derivation isDerivedFrom\n\n    Returns:\n        str: IRI of the created derivation\n    \"\"\"\n    return self.derivation_client.createDerivation(entities, agentIRI, inputs)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createSyncDerivationForNewInfo","title":"createSyncDerivationForNewInfo","text":"<pre><code>createSyncDerivationForNewInfo(agentIRI: str, inputsIRI: List[str], derivationType: str) -&gt; Derivation\n</code></pre> <p>Create a sync derivation for new info to be computed by the agent.</p> <p>Parameters:</p> Name Type Description Default <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>inputsIRI</code> <code>List[str]</code> <p>List of inputs that the derivation isDerivedFrom</p> required <code>derivationType</code> <code>str</code> <p>IRI of the synchronous derivation type to be created</p> required <p>Returns:</p> Name Type Description <code>Derivation</code> <code>Derivation</code> <p>Object of the created derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createSyncDerivationForNewInfo(\n    self,\n    agentIRI: str,\n    inputsIRI: List[str],\n    derivationType: str\n) -&gt; Derivation:\n    \"\"\"\n    Create a sync derivation for new info to be computed by the agent.\n\n    Args:\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        inputsIRI (List[str]): List of inputs that the derivation isDerivedFrom\n        derivationType (str): IRI of the synchronous derivation type to be created\n\n    Returns:\n        Derivation: Object of the created derivation\n    \"\"\"\n    derivation_java = self.derivation_client.createSyncDerivationForNewInfo(agentIRI, inputsIRI, derivationType)\n    return Derivation(derivation_java=derivation_java)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createSyncDerivationForNewInfoWithHttpUrl","title":"createSyncDerivationForNewInfoWithHttpUrl","text":"<pre><code>createSyncDerivationForNewInfoWithHttpUrl(agentIRI: str, agentURL: str, inputsIRI: List[str], derivationType: str) -&gt; Derivation\n</code></pre> <p>Create a sync derivation for new info to be computed by the agent with the agent url provided.</p> <p>Parameters:</p> Name Type Description Default <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>agentURL</code> <code>str</code> <p>HTTP URL of the agent that the derivation isDerivedUsing</p> required <code>inputsIRI</code> <code>List[str]</code> <p>List of inputs that the derivation isDerivedFrom</p> required <code>derivationType</code> <code>str</code> <p>IRI of the synchronous derivation type to be created</p> required <p>Returns:</p> Name Type Description <code>Derivation</code> <code>Derivation</code> <p>Object of the created derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createSyncDerivationForNewInfoWithHttpUrl(\n    self,\n    agentIRI: str,\n    agentURL: str,\n    inputsIRI: List[str],\n    derivationType: str\n) -&gt; Derivation:\n    \"\"\"\n    Create a sync derivation for new info to be computed by the agent with the agent url provided.\n\n    Args:\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        agentURL (str): HTTP URL of the agent that the derivation isDerivedUsing\n        inputsIRI (List[str]): List of inputs that the derivation isDerivedFrom\n        derivationType (str): IRI of the synchronous derivation type to be created\n\n    Returns:\n        Derivation: Object of the created derivation\n    \"\"\"\n    derivation_java = self.derivation_client.createSyncDerivationForNewInfo(agentIRI, agentURL, inputsIRI, derivationType)\n    return Derivation(derivation_java=derivation_java)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.bulkCreateDerivations","title":"bulkCreateDerivations","text":"<pre><code>bulkCreateDerivations(entitiesList: List[List[str]], agentIRIList: List[str], inputsList: List[List[str]]) -&gt; List[str]\n</code></pre> <p>Create multiple normal derivations in one go.</p> <p>Parameters:</p> Name Type Description Default <code>entitiesList</code> <code>List[List[str]]</code> <p>List of list of entities that belongsTo the derivations</p> required <code>agentIRIList</code> <code>List[str]</code> <p>List of agents that the derivations isDerivedUsing</p> required <code>inputsList</code> <code>List[List[str]]</code> <p>List of list of inputs that the derivations isDerivedFrom</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of the created derivations</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def bulkCreateDerivations(\n    self,\n    entitiesList: List[List[str]],\n    agentIRIList: List[str],\n    inputsList: List[List[str]]\n) -&gt; List[str]:\n    \"\"\"\n    Create multiple normal derivations in one go.\n\n    Args:\n        entitiesList (List[List[str]]): List of list of entities that belongsTo the derivations\n        agentIRIList (List[str]): List of agents that the derivations isDerivedUsing\n        inputsList (List[List[str]]): List of list of inputs that the derivations isDerivedFrom\n\n    Returns:\n        List[str]: List of IRIs of the created derivations\n    \"\"\"\n    return self.derivation_client.bulkCreateDerivations(entitiesList, agentIRIList, inputsList)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createDerivationWithTimeSeries","title":"createDerivationWithTimeSeries","text":"<pre><code>createDerivationWithTimeSeries(entities: List[str], agentIRI: str, inputs: List[str]) -&gt; str\n</code></pre> <p>Create a time series derivation markup.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of entities that belongsTo the derivation</p> required <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>inputs</code> <code>List[str]</code> <p>List of inputs that the derivation isDerivedFrom</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the created time series derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createDerivationWithTimeSeries(\n    self,\n    entities: List[str],\n    agentIRI: str,\n    inputs: List[str]\n) -&gt; str:\n    \"\"\"\n    Create a time series derivation markup.\n\n    Args:\n        entities (List[str]): List of entities that belongsTo the derivation\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        inputs (List[str]): List of inputs that the derivation isDerivedFrom\n\n    Returns:\n        str: IRI of the created time series derivation\n    \"\"\"\n    return self.derivation_client.createDerivationWithTimeSeries(entities, agentIRI, inputs)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.bulkCreateDerivationsWithTimeSeries","title":"bulkCreateDerivationsWithTimeSeries","text":"<pre><code>bulkCreateDerivationsWithTimeSeries(entitiesList: List[List[str]], agentIRIList: List[str], inputsList: List[List[str]]) -&gt; List[str]\n</code></pre> <p>Create multiple time series derivations in one go.</p> <p>Parameters:</p> Name Type Description Default <code>entitiesList</code> <code>List[List[str]]</code> <p>List of list of entities that belongsTo the derivations</p> required <code>agentIRIList</code> <code>List[str]</code> <p>List of agents that the derivations isDerivedUsing</p> required <code>inputsList</code> <code>List[List[str]]</code> <p>List of list of inputs that the derivations isDerivedFrom</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of the created time series derivations</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def bulkCreateDerivationsWithTimeSeries(\n    self,\n    entitiesList: List[List[str]],\n    agentIRIList: List[str],\n    inputsList: List[List[str]]\n) -&gt; List[str]:\n    \"\"\"\n    Create multiple time series derivations in one go.\n\n    Args:\n        entitiesList (List[List[str]]): List of list of entities that belongsTo the derivations\n        agentIRIList (List[str]): List of agents that the derivations isDerivedUsing\n        inputsList (List[List[str]]): List of list of inputs that the derivations isDerivedFrom\n\n    Returns:\n        List[str]: List of IRIs of the created time series derivations\n    \"\"\"\n    return self.derivation_client.bulkCreateDerivationsWithTimeSeries(entitiesList, agentIRIList, inputsList)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createAsyncDerivation","title":"createAsyncDerivation","text":"<pre><code>createAsyncDerivation(entities: List[str], agentIRI: str, inputs: List[str], forUpdate: bool) -&gt; str\n</code></pre> <p>Create an asynchronous derivation markup. If <code>forUpdate</code> is True, the derivation will be marked as \"Requested\" with a timestamp of 0. Otherwise, the derivation will be marked without status but with a current timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of entities that belongsTo the derivation</p> required <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>inputs</code> <code>List[str]</code> <p>List of inputs that the derivation isDerivedFrom</p> required <code>forUpdate</code> <code>bool</code> <p>Boolean flag to indicate if the derivation markup is for update</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the created asynchronous derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createAsyncDerivation(\n    self,\n    entities: List[str],\n    agentIRI: str,\n    inputs: List[str],\n    forUpdate: bool\n) -&gt; str:\n    \"\"\"\n    Create an asynchronous derivation markup. If `forUpdate` is True, the derivation will be marked as \"Requested\"\n    with a timestamp of 0. Otherwise, the derivation will be marked without status but with a current timestamp.\n\n    Args:\n        entities (List[str]): List of entities that belongsTo the derivation\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        inputs (List[str]): List of inputs that the derivation isDerivedFrom\n        forUpdate (bool): Boolean flag to indicate if the derivation markup is for update\n\n    Returns:\n        str: IRI of the created asynchronous derivation\n    \"\"\"\n    return self.derivation_client.createAsyncDerivation(entities, agentIRI, inputs, forUpdate)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createAsyncDerivationFromDerivation","title":"createAsyncDerivationFromDerivation","text":"<pre><code>createAsyncDerivationFromDerivation(entities: List[str], agentIRI: str, derivation: str, forUpdate: bool) -&gt; str\n</code></pre> <p>Create an asynchronous derivation markup from an existing derivation. If <code>forUpdate</code> is True, the derivation will be marked as \"Requested\" with a timestamp of 0. Otherwise, the derivation will be marked without status but with a current timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of entities that belongsTo the derivation</p> required <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>derivation</code> <code>str</code> <p>IRI of an existing derivation whose outputs the new derivation isDerivedFrom</p> required <code>forUpdate</code> <code>bool</code> <p>Boolean flag to indicate if the derivation markup is for update</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the created asynchronous derivation</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createAsyncDerivationFromDerivation(\n    self,\n    entities: List[str],\n    agentIRI: str,\n    derivation: str,\n    forUpdate: bool\n) -&gt; str:\n    \"\"\"\n    Create an asynchronous derivation markup from an existing derivation. If `forUpdate` is True, the derivation\n    will be marked as \"Requested\" with a timestamp of 0. Otherwise, the derivation will be marked without status but\n    with a current timestamp.\n\n    Args:\n        entities (List[str]): List of entities that belongsTo the derivation\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        derivation (str): IRI of an existing derivation whose outputs the new derivation isDerivedFrom\n        forUpdate (bool): Boolean flag to indicate if the derivation markup is for update\n\n    Returns:\n        str: IRI of the created asynchronous derivation\n    \"\"\"\n    return self.derivation_client.createAsyncDerivation(entities, agentIRI, derivation, forUpdate)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.bulkCreateAsyncDerivations","title":"bulkCreateAsyncDerivations","text":"<pre><code>bulkCreateAsyncDerivations(entitiesList: List[List[str]], agentIRIList: List[str], inputsList: List[List[str]], forUpdateFlagList: List[bool]) -&gt; List[str]\n</code></pre> <p>Create multiple asynchronous derivations in one go. If the flag in <code>forUpdateFlagList</code> is True, the corresponding derivation will be marked as \"Requested\" with a timestamp of 0. Otherwise, the derivation will be marked without status but with a current timestamp.</p> <p>Parameters:</p> Name Type Description Default <code>entitiesList</code> <code>List[List[str]]</code> <p>List of list of entities that belongsTo the derivations</p> required <code>agentIRIList</code> <code>List[str]</code> <p>List of agents that the derivations isDerivedUsing</p> required <code>inputsList</code> <code>List[List[str]]</code> <p>List of list of inputs that the derivations isDerivedFrom</p> required <code>forUpdateFlagList</code> <code>List[bool]</code> <p>List of boolean flags to indicate if the derivation markup is for update</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of the created asynchronous derivations</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def bulkCreateAsyncDerivations(\n    self,\n    entitiesList: List[List[str]],\n    agentIRIList: List[str],\n    inputsList: List[List[str]],\n    forUpdateFlagList: List[bool]\n) -&gt; List[str]:\n    \"\"\"\n    Create multiple asynchronous derivations in one go. If the flag in `forUpdateFlagList` is True, the corresponding\n    derivation will be marked as \"Requested\" with a timestamp of 0. Otherwise, the derivation will be marked without\n    status but with a current timestamp.\n\n    Args:\n        entitiesList (List[List[str]]): List of list of entities that belongsTo the derivations\n        agentIRIList (List[str]): List of agents that the derivations isDerivedUsing\n        inputsList (List[List[str]]): List of list of inputs that the derivations isDerivedFrom\n        forUpdateFlagList (List[bool]): List of boolean flags to indicate if the derivation markup is for update\n\n    Returns:\n        List[str]: List of IRIs of the created asynchronous derivations\n    \"\"\"\n    return self.derivation_client.bulkCreateAsyncDerivations(entitiesList, agentIRIList, inputsList, forUpdateFlagList)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createAsyncDerivationForNewInfo","title":"createAsyncDerivationForNewInfo","text":"<pre><code>createAsyncDerivationForNewInfo(agentIRI: str, inputsAndDerivations: List[str]) -&gt; str\n</code></pre> <p>Create an asynchronous derivation markup for new information. The derivation will be marked as \"Requested\" with a timestamp of 0. The outputs of the derivation will be computed by the agent in due course. Note that all IRIs in the <code>inputsAndDerivations</code> list will be directly connected to the derivation as its inputs. Therefore, existing IRIs of the derivation outputs should be provided if applicable, instead of the IRI of that derivation.</p> <p>Parameters:</p> Name Type Description Default <code>agentIRI</code> <code>str</code> <p>IRI of the agent that the derivation isDerivedUsing</p> required <code>inputsAndDerivations</code> <code>List[str]</code> <p>List of inputs and derivations that the derivation isDerivedFrom</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>IRI of the created asynchronous derivation for new information</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createAsyncDerivationForNewInfo(\n    self,\n    agentIRI: str,\n    inputsAndDerivations: List[str]\n) -&gt; str:\n    \"\"\"\n    Create an asynchronous derivation markup for new information. The derivation will be marked as \"Requested\" with\n    a timestamp of 0. The outputs of the derivation will be computed by the agent in due course. Note that all IRIs in\n    the `inputsAndDerivations` list will be directly connected to the derivation as its inputs. Therefore, existing IRIs\n    of the derivation outputs should be provided if applicable, instead of the IRI of that derivation.\n\n    Args:\n        agentIRI (str): IRI of the agent that the derivation isDerivedUsing\n        inputsAndDerivations (List[str]): List of inputs and derivations that the derivation isDerivedFrom\n\n    Returns:\n        str: IRI of the created asynchronous derivation for new information\n    \"\"\"\n    return self.derivation_client.createAsyncDerivationForNewInfo(agentIRI, inputsAndDerivations)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.bulkCreateAsyncDerivationsForNewInfo","title":"bulkCreateAsyncDerivationsForNewInfo","text":"<pre><code>bulkCreateAsyncDerivationsForNewInfo(agentIRIList: List[str], inputsAndDerivationsList: List[List[str]]) -&gt; List[str]\n</code></pre> <p>Create multiple asynchronous derivations for new information in one go. The derivations will be marked as \"Requested\" with a timestamp of 0. The outputs of the derivations will be computed by the agents in due course. Note that all IRIs in the <code>inputsAndDerivationsList</code> list will be directly connected to the derivations as their inputs. Therefore, existing IRIs of the derivation outputs should be provided if applicable, instead of the IRI of that derivation.</p> <p>Parameters:</p> Name Type Description Default <code>agentIRIList</code> <code>List[str]</code> <p>List of agents that the derivations isDerivedUsing</p> required <code>inputsAndDerivationsList</code> <code>List[List[str]]</code> <p>List of list of inputs and derivations that the derivations isDerivedFrom</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of the created asynchronous derivations for new information</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def bulkCreateAsyncDerivationsForNewInfo(\n    self,\n    agentIRIList: List[str],\n    inputsAndDerivationsList: List[List[str]]\n) -&gt; List[str]:\n    \"\"\"\n    Create multiple asynchronous derivations for new information in one go. The derivations will be marked as\n    \"Requested\" with a timestamp of 0. The outputs of the derivations will be computed by the agents in due course.\n    Note that all IRIs in the `inputsAndDerivationsList` list will be directly connected to the derivations as their\n    inputs. Therefore, existing IRIs of the derivation outputs should be provided if applicable, instead of the IRI\n    of that derivation.\n\n    Args:\n        agentIRIList (List[str]): List of agents that the derivations isDerivedUsing\n        inputsAndDerivationsList (List[List[str]]): List of list of inputs and derivations that the derivations isDerivedFrom\n\n    Returns:\n        List[str]: List of IRIs of the created asynchronous derivations for new information\n    \"\"\"\n    return self.derivation_client.bulkCreateAsyncDerivationsForNewInfo(agentIRIList, inputsAndDerivationsList)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.validateDerivations","title":"validateDerivations","text":"<pre><code>validateDerivations() -&gt; bool\n</code></pre> <p>This checks for any circular dependency and ensures that all the linked inputs have a suitable timestamp attached. NOTE however, this method does not check for everything, e.g. instances having appropriate rdf:types, and the agent design.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>Whether the created derivations are valid, i.e. no circular dependency, timestamps correctly attached</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def validateDerivations(self) -&gt; bool:\n    \"\"\"\n    This checks for any circular dependency and ensures that all the linked inputs have a suitable timestamp attached.\n    NOTE however, this method does not check for everything, e.g. instances having appropriate rdf:types, and the agent design.\n\n    Returns:\n        bool: Whether the created derivations are valid, i.e. no circular dependency, timestamps correctly attached\n    \"\"\"\n    return self.derivation_client.validateDerivations()\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.createOntoAgentInstance","title":"createOntoAgentInstance","text":"<pre><code>createOntoAgentInstance(ontoAgentServiceIRI: str, ontoAgentOperationHttpUrl: str, inputTypes: List[str], outputTypes: List[str])\n</code></pre> <p>Register an OntoAgent instance in the triple store.</p> <p>Parameters:</p> Name Type Description Default <code>ontoAgentServiceIRI</code> <code>str</code> <p>IRI of the agent's OntoAgent:Service</p> required <code>ontoAgentOperationHttpUrl</code> <code>str</code> <p>IRI of the agent's operation HTTP URL</p> required <code>inputTypes</code> <code>List[str]</code> <p>List of IRI of the agent's input types</p> required <code>outputTypes</code> <code>List[str]</code> <p>List of IRI of the agent's output types</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def createOntoAgentInstance(\n    self,\n    ontoAgentServiceIRI: str,\n    ontoAgentOperationHttpUrl: str,\n    inputTypes: List[str],\n    outputTypes: List[str]\n):\n    \"\"\"\n    Register an OntoAgent instance in the triple store.\n\n    Args:\n        ontoAgentServiceIRI (str): IRI of the agent's OntoAgent:Service\n        ontoAgentOperationHttpUrl (str): IRI of the agent's operation HTTP URL\n        inputTypes (List[str]): List of IRI of the agent's input types\n        outputTypes (List[str]): List of IRI of the agent's output types\n    \"\"\"\n    self.derivation_client.createOntoAgentInstance(\n        ontoAgentServiceIRI, ontoAgentOperationHttpUrl, inputTypes, outputTypes)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.addTimeInstance","title":"addTimeInstance","text":"<pre><code>addTimeInstance(entities: List[str])\n</code></pre> <p>Add a time instance to each entity in the list of entities.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of IRIs of entities to add time instance to</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def addTimeInstance(self, entities: List[str]):\n    \"\"\"\n    Add a time instance to each entity in the list of entities.\n\n    Args:\n        entities (List[str]): List of IRIs of entities to add time instance to\n    \"\"\"\n    self.derivation_client.addTimeInstance(entities)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.addTimeInstanceCurrentTimestamp","title":"addTimeInstanceCurrentTimestamp","text":"<pre><code>addTimeInstanceCurrentTimestamp(entities: List[str])\n</code></pre> <p>Add time instance with current timestamp to the given entities</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of IRIs of entities to add time instance to</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def addTimeInstanceCurrentTimestamp(self, entities: List[str]):\n    \"\"\"\n    Add time instance with current timestamp to the given entities\n\n    Args:\n        entities (List[str]): List of IRIs of entities to add time instance to\n    \"\"\"\n    self.derivation_client.addTimeInstanceCurrentTimestamp(entities)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updateTimestamp","title":"updateTimestamp","text":"<pre><code>updateTimestamp(entity: str)\n</code></pre> <p>Update the timestamp of the entity to the current time.</p> <p>Parameters:</p> Name Type Description Default <code>entity</code> <code>str</code> <p>IRI of the entity to update the timestamp of</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updateTimestamp(self, entity: str):\n    \"\"\"\n    Update the timestamp of the entity to the current time.\n\n    Args:\n        entity (str): IRI of the entity to update the timestamp of\n    \"\"\"\n    self.derivation_client.updateTimestamp(entity)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updateTimestamps","title":"updateTimestamps","text":"<pre><code>updateTimestamps(entities: List[str])\n</code></pre> <p>Update the timestamp of all entities in the list.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of IRIs of entities to update the timestamp for</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updateTimestamps(self, entities: List[str]):\n    \"\"\"\n    Update the timestamp of all entities in the list.\n\n    Args:\n        entities (List[str]): List of IRIs of entities to update the timestamp for\n    \"\"\"\n    self.derivation_client.updateTimestamps(entities)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.dropTimestampsOf","title":"dropTimestampsOf","text":"<pre><code>dropTimestampsOf(entities: List[str])\n</code></pre> <p>Drop the timestamp of the given entities.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of IRIs of entities to drop the timestamp of</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def dropTimestampsOf(self, entities: List[str]):\n    \"\"\"\n    Drop the timestamp of the given entities.\n\n    Args:\n        entities (List[str]): List of IRIs of entities to drop the timestamp of\n    \"\"\"\n    self.derivation_client.dropTimestampsOf(entities)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.getDerivations","title":"getDerivations","text":"<pre><code>getDerivations(agentIRI: str) -&gt; List[str]\n</code></pre> <p>Get the derivations of the given agent.</p> <p>Parameters:</p> Name Type Description Default <code>agentIRI</code> <code>str</code> <p>IRI of the agent</p> required <p>Returns:</p> Name Type Description <code>list</code> <code>List[str]</code> <p>List of IRIs of the derivations that isDerivedUsing the given agent</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def getDerivations(self, agentIRI: str) -&gt; List[str]:\n    \"\"\"\n    Get the derivations of the given agent.\n\n    Args:\n        agentIRI (str): IRI of the agent\n\n    Returns:\n        list: List of IRIs of the derivations that isDerivedUsing the given agent\n    \"\"\"\n    return list(self.derivation_client.getDerivations(agentIRI))\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.getDerivationsOf","title":"getDerivationsOf","text":"<pre><code>getDerivationsOf(entities: List[str]) -&gt; Dict[str, str]\n</code></pre> <p>Get the derivations of the given entities.</p> <p>Parameters:</p> Name Type Description Default <code>entities</code> <code>List[str]</code> <p>List of entities</p> required <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>Dict[str, str]: The dictionary with the entity IRIs as keys and the derivation IRIs as values</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def getDerivationsOf(self, entities: List[str]) -&gt; Dict[str, str]:\n    \"\"\"\n    Get the derivations of the given entities.\n\n    Args:\n        entities (List[str]): List of entities\n\n    Returns:\n        Dict[str, str]: The dictionary with the entity IRIs as keys and the derivation IRIs as values\n    \"\"\"\n    return self.derivation_client.getDerivationsOf(entities)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.unifiedUpdateDerivation","title":"unifiedUpdateDerivation","text":"<pre><code>unifiedUpdateDerivation(derivationIRI: str)\n</code></pre> <p>Unified update derivation method. This methods updates the specified derivation and all its upstream derivations.</p> <p>Parameters:</p> Name Type Description Default <code>derivationIRI</code> <code>str</code> <p>IRI of the derivation to be updated</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def unifiedUpdateDerivation(self, derivationIRI: str):\n    \"\"\"\n    Unified update derivation method.\n    This methods updates the specified derivation and all its upstream derivations.\n\n    Args:\n        derivationIRI (str): IRI of the derivation to be updated\n    \"\"\"\n    self.derivation_client.unifiedUpdateDerivation(derivationIRI)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updatePureSyncDerivation","title":"updatePureSyncDerivation","text":"<pre><code>updatePureSyncDerivation(derivationIRI: str)\n</code></pre> <p>Update the specified synchronous derivation and all its upstream derivations.</p> <p>Parameters:</p> Name Type Description Default <code>derivationIRI</code> <code>str</code> <p>IRI of the derivation to be updated</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updatePureSyncDerivation(self, derivationIRI: str):\n    \"\"\"\n    Update the specified *synchronous* derivation and all its upstream derivations.\n\n    Args:\n        derivationIRI (str): IRI of the derivation to be updated\n    \"\"\"\n    self.derivation_client.updatePureSyncDerivation(derivationIRI)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updatePureSyncDerivations","title":"updatePureSyncDerivations","text":"<pre><code>updatePureSyncDerivations(derivationIRIs: List[str])\n</code></pre> <p>Update the specified list of synchronous derivations and all their upstream derivations.</p> <p>Parameters:</p> Name Type Description Default <code>derivationIRIs</code> <code>List[str]</code> <p>List of IRIs of the derivations to be updated</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updatePureSyncDerivations(self, derivationIRIs: List[str]):\n    \"\"\"\n    Update the specified list of *synchronous* derivations and all their upstream derivations.\n\n    Args:\n        derivationIRIs (List[str]): List of IRIs of the derivations to be updated\n    \"\"\"\n    self.derivation_client.updatePureSyncDerivations(derivationIRIs)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updatePureSyncDerivationsInParallel","title":"updatePureSyncDerivationsInParallel","text":"<pre><code>updatePureSyncDerivationsInParallel(derivationIRIs: List[str])\n</code></pre> <p>Update the specified list of synchronous derivations and all their upstream derivations in parallel.</p> <p>Parameters:</p> Name Type Description Default <code>derivationIRIs</code> <code>List[str]</code> <p>List of IRIs of the derivations to be updated</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updatePureSyncDerivationsInParallel(self, derivationIRIs: List[str]):\n    \"\"\"\n    Update the specified list of *synchronous* derivations and all their upstream derivations in parallel.\n\n    Args:\n        derivationIRIs (List[str]): List of IRIs of the derivations to be updated\n    \"\"\"\n    self.derivation_client.updatePureSyncDerivationsInParallel(derivationIRIs)\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updateAllSyncDerivations","title":"updateAllSyncDerivations","text":"<pre><code>updateAllSyncDerivations()\n</code></pre> <p>Update all synchronous derivations in the knowledge graph.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updateAllSyncDerivations(self):\n    \"\"\"\n    Update all *synchronous* derivations in the knowledge graph.\n    \"\"\"\n    self.derivation_client.updateAllSyncDerivations()\n</code></pre>"},{"location":"api/derivation_client/#twa.kg_operations.derivation_client.PyDerivationClient.updateMixedAsyncDerivation","title":"updateMixedAsyncDerivation","text":"<pre><code>updateMixedAsyncDerivation(derivationIRI: str)\n</code></pre> <p>Update a directed acyclic graph (DAG) of pure asynchronous derivations or asynchronous derivations depending on synchronous derivations.</p> <p>Parameters:</p> Name Type Description Default <code>derivationIRI</code> <code>str</code> <p>IRI of the derivation to be updated</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/derivation_client.py</code> <pre><code>def updateMixedAsyncDerivation(self, derivationIRI: str):\n    \"\"\"\n    Update a directed acyclic graph (DAG) of pure asynchronous derivations or asynchronous derivations depending on synchronous derivations.\n\n    Args:\n        derivationIRI (str): IRI of the derivation to be updated\n    \"\"\"\n    self.derivation_client.updateMixedAsyncDerivation(derivationIRI)\n</code></pre>"},{"location":"api/gateway/","title":"Gateway","text":"<p>The purpose of this module is to create and start Java resource gateway objects to be used in other modules and scripts.</p>"},{"location":"api/gateway/#instantiation-of-gateway-object","title":"Instantiation of gateway object","text":"<p>To begin with, the resource gateway object for <code>JpsBaseLib</code>, which allows access to <code>JPS_BASE_LIB</code>, needs to be instantiated:</p> <pre><code># To avoid unnecessary logging information from py4j package, set logger level before\n# first creation of JPS_BASE_LIB module view (i.e. jpsBaseLibView = jpsBaseLibGW.createModuleView())\nimport logging\nlogging.getLogger(\"py4j\").setLevel(logging.INFO)\n\nfrom twa.resources import JpsBaseLib\njpsBaseLibGW = JpsBaseLib()\n</code></pre>"},{"location":"api/gateway/#start-the-gateway-object","title":"Start the gateway object","text":"<p>Below method starts the communication with the Java side:</p> <pre><code>jpsBaseLibGW.launchGateway()\n\n# Alternatively, one can supply args to the launchGateway() method:\n# jpsBaseLibGW.launchGateway(**LGkwargs)\n</code></pre> <p>where the <code>**LGkwargs</code> argument represents a dictionary of any optional <code>argument: value</code> pairs one wishes to pass to the py4j launch_gateway method. Please refer to the method documentation for the description of all the possible arguments. The most important and useful settings are set by default in the <code>twa.JPSGateway.launchGateway</code> method so a user hardly ever need to pass any arguments in that call. If required, however, the <code>twa.JPSGateway.launchGateway</code> method defaults can be overwritten by simply passing their new values.</p> <p>NOTE that compared to the <code>twa.JPSGateway</code> class, the <code>JpsBaseLib</code> constructor call neither accepts the resource name nor the resource jar path as arguments. This ensures that the resource is properly encapsulated.</p>"},{"location":"api/jps_gateway/","title":"JPS Gateway","text":"<p><code>JPSGateway</code> is the parent class which should be instantiated by every resource gateway class.</p> <p>The resource gateway class is automatically created upon the resource installation, whose class name is the same as the name of the resource given during the installation.</p> <p>Therefore, one should ideally only work with the resource classes, e.g. <code>JpsBaseLib</code>, rather than with the parent <code>JPSGateway</code> class.</p> <p>The documentation here is provided for developers' information.</p>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGatewaySingletonMeta","title":"JPSGatewaySingletonMeta","text":"<p>               Bases: <code>type</code></p> <p>A Singleton metaclass that ensures only one instance of the class is created.</p>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGateway","title":"JPSGateway","text":"<pre><code>JPSGateway(resName: str = None, jarPath: str = None, **JGkwargs)\n</code></pre> <p>Wrapper class of the py4j JavaGateway class for managing Python-Java communication.</p> <p>The class can be used in the following way:</p> <pre><code>from twa import JPSGateway\n\nyourGateway = JPSGateway(resName=yourResName, jarPath=yourResJarPath, **JGkwargs)\n</code></pre> <p>Note that if you wish to access an already installed resource through the <code>JPSGateway</code> (not recommended), then the <code>jarPath</code> argument can be omitted as it can be looked up by the resource name in the resource registry. Also, note that some of the <code>py4j.java_gateway.JavaGateway</code> constructor arguments are not allowed or should be passed to the <code>py4j.java_gateway.launch_gateway</code> method instead. If that is the case, the code will print a warning message which shows how to set the desired argument correctly. Please also note that according to the <code>py4j</code> documentation, the <code>gateway_parameters</code> argument to the <code>py4j.java_gateway.JavaGateway</code> constructor must have the type of the py4j GatewayParameters object. However, to make it easy for the <code>twa</code> users, this argument can be passed as a dictionary which then is automatically converted into the <code>py4j GatewayParameters</code> object.</p> <p>Attributes:</p> Name Type Description <code>resName</code> <code>str</code> <p>name of the Java resource</p> <code>jarPath</code> <code>str</code> <p>absolute path to the main jar file of the java resource</p> <code>gateway</code> <code>JavaGateway</code> <p>the gateway object handling Python-Java communication</p> <code>_isStarted</code> <code>bool</code> <p>flag indicating if the gateway was launched</p> <code>_gatewayUserParams</code> <code>dict</code> <p>dictionary storing user provided JavaGateway parameters</p> <code>_launchGatewayUserParams</code> <code>dict</code> <p>dictionary storing user provided launch_gateway parameters</p> <code>_initialised</code> <code>bool</code> <p>flag inticating if the instance is already initialised</p> <p>Parameters:</p> Name Type Description Default <code>resName</code> <code>str</code> <p>name of the Java resource</p> <code>None</code> <code>jarPath</code> <code>str</code> <p>absolute path to the main jar file of the java resource</p> <code>None</code> <code>JGkwargs</code> <code>dict</code> <p>dictionary storing user provided JavaGateway parameters <code>argument: value</code> pairs one wishes to pass to the py4j JavaGateway constructor</p> <code>{}</code> <p>Note that the JGkwargs related to the 'gateway_parameters' argument should be passed as a dictionary which is then automatically converted into the 'GatewayParameters' object. Please refer to the py4j documentation for the description of all the possible arguments.</p> <p>As an example, the following arguments:</p> <pre><code>JGkwargs = {'gateway_parameters':{'auto_convert':True}}\n</code></pre> <p>will be automatically converted to:</p> <pre><code>JGkwargs = {'gateway_parameters': GatewayParameters(auto_convert=True)}}\n</code></pre> <p>Note that the 'java_process' and 'auth_token' arguments will be skipped if present and they are automatically set by the py4j.java_gateway.launch_gateway method</p> <p>Note that the 'port' argument will skipped if present as it can only be passed to the py4j.java_gateway.launch_gateway call</p> <p>Note that setting the JavaGateway 'eager_load' and the py4j.java_gateway.launch_gateway 'enable_auth' arguments to True at the same time does NOT work. The arguments are mutually exclusive</p> <p>Note that the most important and useful settings are set by default in this constructor so a user hardly ever need to pass any arguments in that call. If required, however, the defaults of this constructor can be overwritten by simply passing their new values. Please also note that this constructor only instantiates the <code>JPSGateway</code> object, and it DOES NOT instantiate the <code>py4j.java_gateway.JavaGateway</code>, whose instantiation only happens in the <code>twa.JPSGateway.launchGateway</code> method explained in more details below.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/JPSGateway.py</code> <pre><code>def __init__(self, resName:str=None, jarPath:str=None, **JGkwargs):\n    \"\"\"\n    JPSGateway constructor class\n\n    Args:\n        resName (str): name of the Java resource\n        jarPath (str): absolute path to the main jar file of the java resource\n        JGkwargs (dict): dictionary storing user provided JavaGateway parameters\n            `argument: value` pairs one wishes to pass to the\n            [py4j JavaGateway](https://www.py4j.org/py4j_java_gateway.html#py4j.java_gateway.JavaGateway) constructor\n\n    &gt; Note that the JGkwargs related to the 'gateway_parameters'\n    argument should be passed as a dictionary which is then\n    automatically converted into the 'GatewayParameters' object.\n    Please refer to the\n    [py4j documentation](https://www.py4j.org/py4j_java_gateway.html)\n    for the description of all the possible arguments.\n\n    &gt; As an example, the following arguments:\n\n    &gt; ```python\n    &gt; JGkwargs = {'gateway_parameters':{'auto_convert':True}}\n    &gt; ```\n\n    &gt; will be automatically converted to:\n\n    &gt; ```python\n    &gt; JGkwargs = {'gateway_parameters': GatewayParameters(auto_convert=True)}}\n    &gt; ```\n\n    &gt; Note that the 'java_process' and 'auth_token' arguments\n    will be skipped if present and they are automatically\n    set by the py4j.java_gateway.launch_gateway method\n\n    &gt; Note that the 'port' argument will skipped if present\n    as it can only be passed to the py4j.java_gateway.launch_gateway call\n\n    &gt; Note that setting the JavaGateway 'eager_load' and the\n    py4j.java_gateway.launch_gateway 'enable_auth' arguments to\n    True at the same time does NOT work. The arguments are mutually\n    exclusive\n\n    &gt; Note that the most important and useful settings are set by default\n    in this constructor so a user hardly ever need to pass any arguments\n    in that call. If required, however, the defaults of this constructor\n    can be overwritten by simply passing their new values. Please also\n    note that this constructor only instantiates the `JPSGateway` object,\n    and it DOES NOT instantiate the `py4j.java_gateway.JavaGateway`, whose\n    instantiation only happens in the `twa.JPSGateway.launchGateway` method\n    explained in more details below.\n    \"\"\"\n    if not hasattr(self, '_initialised'):\n        # ensures __init__ runs only once\n        self._initialised = True\n        self.resName = resName\n        self.jarPath = jarPath\n        if self.jarPath is None:\n            self.jarPath = resReg.getResMainFilePath(resName)\n\n        try:\n            if not path.isfile(self.jarPath):\n                print('Error: Resource jarpath is invalid.')\n                raise FileNotFoundError\n        except TypeError:\n            print('Error: Resource jarpath is invalid.')\n            raise FileNotFoundError\n        self.gateway = None\n        self._gatewayUserParams = _processJGkwargs(**JGkwargs)\n        self._launchGatewayUserParams = None\n        self._isStarted = False\n        print(f'Info: Initializing JPSGateway with resName={resName}, jarPath={jarPath}')\n    else:\n        print(f'Info: Gateway already initialised. Any JavaGateway created ({self.gateway}) will be reused.')\n</code></pre>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGateway.launchGateway","title":"launchGateway","text":"<pre><code>launchGateway(**LGkwargs)\n</code></pre> <p>Wrapper method for the py4j.java_gateway.launch_gateway method which launches the Gateway in a new Java process and creates a default JavaGateway to connect to it.</p> <p>Parameters:</p> Name Type Description Default <code>LGkwargs</code> <code>dict</code> <p>a dictionary containing the py4j.java_gateway.launch_gateway method arguments</p> <code>{}</code> <p>Note that the 'jarpath' and 'return_proc' arguments cannot be changed and will be skipped if provided</p> <p>Note that this calls an internal py4j.java_gateway.launch_gateway function which is different from the launch_gateway function described in py4j web documentation. The py4j function described in py4j web documentation is a JavaGateway classmethod which in turn calls the function below. It is a bit confusing as the two functions have the same name. The difference between the two is that the launch_gateway classmethod launches the java process and then creates a JavaGateway object connected to it, the problem is that this function call does not accept any user JavaGateway constructor arguments. The non classmethod call on the other hand only launches the java process without creating the JavaGateway instance. The JavaGateway instance can be then created at a later stage with user defined parameters plus the parameters returned from the launch_gateway method call that connect the running java process and the JavaGateway. Therefore, the non classmethod py4j.java_gateway.launch_gateway is called herein and its outputs are passed to the JavaGateway constructor.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/JPSGateway.py</code> <pre><code>def launchGateway(self, **LGkwargs):\n    \"\"\"\n    Wrapper method for the py4j.java_gateway.launch_gateway\n    method which launches the Gateway in a new Java process\n    and creates a default JavaGateway to connect to it.\n\n    Args:\n        LGkwargs (dict): a dictionary containing the py4j.java_gateway.launch_gateway method arguments\n\n    &gt; Note that the 'jarpath' and 'return_proc' arguments cannot\n    be changed and will be skipped if provided\n\n    &gt; Note that **this calls an internal py4j.java_gateway.launch_gateway function which is\n    different from the launch_gateway function described in py4j web documentation.**\n    The py4j function described in py4j web documentation is a JavaGateway classmethod\n    which in turn calls the function below. It is a bit confusing as the two functions have\n    the same name. The difference between the two is that the launch_gateway classmethod\n    launches the java process and then creates a JavaGateway object connected to it, the\n    problem is that this function call does not accept any user JavaGateway constructor\n    arguments. The non classmethod call on the other hand only launches the java process\n    without creating the JavaGateway instance. The JavaGateway instance can be then created\n    at a later stage with user defined parameters plus the parameters returned from the\n    launch_gateway method call that connect the running java process and the JavaGateway.\n    Therefore, the non classmethod py4j.java_gateway.launch_gateway is called herein and its\n    outputs are passed to the JavaGateway constructor.\n\n    \"\"\"\n\n    with self._launch_lock:\n        if not self._isStarted:\n            LGkwargs = _processLGkwargs(self.__class__.__name__, **LGkwargs)\n            self._launchGatewayUserParams = LGkwargs\n\n            # this launches the java process\n            try:\n                _ret = launch_gateway(jarpath=self.jarPath, **LGkwargs)\n            except TypeError as e:\n                print(textwrap.dedent(\"\"\"\n                    Error: The launch_gateway method called with invalid argument(s).\n                        Please see the py4j documentation at:\n                            https://www.py4j.org/py4j_java_gateway.html#py4j.java_gateway.launch_gateway\n                        to see the list of supported arguments.\"\"\"))\n                raise e\n            except FileNotFoundError as e:\n                print(textwrap.dedent(\"\"\"\n                    Error: Could not launch the resource gateway. Make sure that:\n                            1 - the resource jarPath is correct\n                            2 - java runtime environment 7+ is installed\n                            3 - java runtime environment 7+ is correctly added to the system path\"\"\"))\n                raise e\n\n            if LGkwargs['enable_auth']:\n                _port, _auth_token, proc = _ret\n            else:\n                _port, proc, _auth_token = _ret + (None, )\n\n            self._gatewayUserParams = _addConJGParams(_port, proc, _auth_token, self._gatewayUserParams)\n            # this creates the JavaGateway object connected to the launched java process above\n            try:\n                self.gateway = JavaGateway(**self._gatewayUserParams)\n            except TypeError as e:\n                print(textwrap.dedent(\"\"\"\n                    Error: The JavaGateway constructor method called with invalid argument(s).\n                        Please see the py4j documentation at:\n                            https://www.py4j.org/py4j_java_gateway.html#py4j.java_gateway.JavaGateway\n                        to see the list of supported arguments.\"\"\"))\n\n            self._isStarted = True\n        else:\n            print(\"Info: JavaGateway already started.\")\n</code></pre>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGateway.shutdown","title":"shutdown","text":"<pre><code>shutdown()\n</code></pre> <p>Wrapper method for the py4j shutdown method to stop the JavaGateway client.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/JPSGateway.py</code> <pre><code>def shutdown(self):\n    \"\"\"\n    Wrapper method for the py4j shutdown method\n    to stop the JavaGateway client.\n    \"\"\"\n    if self._isStarted:\n        self.gateway.shutdown()\n</code></pre>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGateway.createModuleView","title":"createModuleView","text":"<pre><code>createModuleView()\n</code></pre> <p>Wrapper method for the py4j new_jvm_view method. Creates a new JVM view with its own imports.</p> <p>Returns:</p> Name Type Description <code>new_jvm_view</code> <code>JVM</code> <p>A new JVM view object</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/JPSGateway.py</code> <pre><code>def createModuleView(self):\n    \"\"\"\n    Wrapper method for the py4j new_jvm_view method.\n    Creates a new JVM view with its own imports.\n\n    Returns:\n        new_jvm_view (JavaGateway.JVM): A new JVM view object\n    \"\"\"\n    if self._isStarted:\n        return self.gateway.new_jvm_view()\n    else:\n        print(\"Error: Cannot create the module view. The JavaGateway is not started. Call the gateway start() method first.\")\n</code></pre>"},{"location":"api/jps_gateway/#twa.JPSGateway.JPSGateway.importPackages","title":"importPackages","text":"<pre><code>importPackages(moduleView, importStatement)\n</code></pre> <p>Wrapper method for the py4j java_import method. Imports a class / package into the specified JVM view</p> <p>Parameters:</p> Name Type Description Default <code>moduleView</code> <code>JVM</code> <p>A new JVM view object</p> required <code>importStatement</code> <code>str</code> <p>The class / package name to import</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/JPSGateway.py</code> <pre><code>def importPackages(self, moduleView, importStatement):\n    \"\"\"\n    Wrapper method for the py4j java_import method.\n    Imports a class / package into the specified JVM view\n\n    Args:\n        moduleView (JavaGateway.JVM): A new JVM view object\n        importStatement (str): The class / package name to import\n    \"\"\"\n    if self._isStarted:\n        java_import(moduleView, importStatement)\n    else:\n        print(\"Error: Cannot import packages. The JavaGateway is not started. Call the gateway start() method first.\")\n</code></pre>"},{"location":"api/logging/","title":"Logging","text":""},{"location":"api/logging/#twa.agentlogging.logging.StreamToLogger","title":"StreamToLogger","text":"<pre><code>StreamToLogger(logger, log_level=DEBUG)\n</code></pre> <p>               Bases: <code>TextIOBase</code></p> <p>Fake file-like stream object that redirects writes to a logger instance.</p> <p>StreamToLogger is made to extend TextIOBase to prevent error like below when running pytest with docker-compose as part of dockerised test in developing pyderivationagent package:     AttributeError: 'StreamToLogger' object has no attribute 'isatty'</p> <p>To reproduce the error, one may checkout to this commit and run <code>pytest -s --docker-compose=./docker-compose.test.yml</code> in the folder</p> <p>This error was due to this line in pytest checking if <code>sys.stdout.isatty()</code> is True/False</p> <p>Another fix is to provide \"def isatty(self) -&gt; bool:\"\" but extending TextIOBase seems to be a \"safer\"/\"cleaner\" fix, according to this comment</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agentlogging/logging.py</code> <pre><code>def __init__(self, logger, log_level=logging.DEBUG):\n    self.logger = logger\n    self.log_level = log_level\n    self.linebuf = ''\n</code></pre>"},{"location":"api/logging/#twa.agentlogging.logging.get_logger","title":"get_logger","text":"<pre><code>get_logger(logger_name: str)\n</code></pre> <p>Get the dev or prod logger (avoids having to import 'logging' in calling code).</p> <p>Parameters:</p> Name Type Description Default <code>logger_name</code> <code>str</code> <p>name of the logger to be used, available options include 'dev' and 'prod'</p> required <p>Returns:</p> Type Description <p>Logger to use for logging statements.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agentlogging/logging.py</code> <pre><code>def get_logger(logger_name: str):\n    \"\"\"\n    Get the dev or prod logger (avoids having to import 'logging' in calling code).\n\n    Args:\n        logger_name: name of the logger to be used, available options include 'dev' and 'prod'\n\n    Returns:\n        Logger to use for logging statements.\n    \"\"\"\n    valid_logger_names = ['dev','prod']\n\n    if logger_name in valid_logger_names:\n        return logging.getLogger(logger_name)\n    else:\n        raise ValueError(\"Invalid logger name: allowed values are \"+\",\".join(valid_logger_names))\n</code></pre>"},{"location":"api/logging/#twa.agentlogging.logging.shutdown","title":"shutdown","text":"<pre><code>shutdown()\n</code></pre> <p>Shutdown the logging system, should be called before application exit after all logging calls.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agentlogging/logging.py</code> <pre><code>def shutdown():\n    \"\"\"\n    Shutdown the logging system, should be called\n    before application exit after all logging calls.\n    \"\"\"\n    logging.shutdown()\n</code></pre>"},{"location":"api/logging/#twa.agentlogging.logging.clear_loggers","title":"clear_loggers","text":"<pre><code>clear_loggers()\n</code></pre> <p>Remove handlers from all loggers. Method adopted from this comment.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/agentlogging/logging.py</code> <pre><code>def clear_loggers():\n    \"\"\"\n    Remove handlers from all loggers. Method adopted from\n    [this comment](https://github.com/pytest-dev/pytest/issues/5502#issuecomment-647157873).\n    \"\"\"\n    import logging\n    loggers = [logging.getLogger()] + list(logging.Logger.manager.loggerDict.values())\n    for logger in loggers:\n        handlers = getattr(logger, 'handlers', [])\n        for handler in handlers:\n            logger.removeHandler(handler)\n</code></pre>"},{"location":"api/res_manager/","title":"Resource Manager","text":""},{"location":"api/res_manager/#twa.resRegistry.resManager.start","title":"start","text":"<pre><code>start()\n</code></pre> <p>The entry point of the helper function, which allows <code>jpsrm</code> to be called from the command line.</p> Usage <p>jpsrm install   [--jar JARFILE] <p>jpsrm uninstall  <p>jpsrm list</p> <p>jpsrm clean</p> Options <p>-j, --jar: Name of the main jar file. If not provided, the first     found jar file in the resource directory will be used.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resManager.py</code> <pre><code>def start():\n    \"\"\" The entry point of the helper function, which allows `jpsrm` to be called from the command line.\n\n    Usage:\n        jpsrm install &lt;resource&gt; &lt;from&gt; [--jar JARFILE]\n\n        jpsrm uninstall &lt;resource&gt;\n\n        jpsrm list\n\n        jpsrm clean\n\n    Options:\n        -j, --jar: Name of the main jar file. If not provided, the first\n            found jar file in the resource directory will be used.\n    \"\"\"\n    devinstall = False\n    try:\n        args = docopt(doc)\n    except DocoptExit:\n        if len(sys.argv)==2:\n            if sys.argv[1]=='devinstall':\n                devinstall = True\n        if not devinstall:\n            raise DocoptExit('Error: jpsrm called with wrong arguments.')\n\n    if devinstall:\n        _doDevinstall()\n    else:\n        if args['install']:\n            resReg.addResToReg(resName=args['&lt;resource&gt;'], resLoc=args['&lt;from&gt;'], resMainJarFile=args['JARFILE'])\n        elif args['uninstall']:\n            resReg.removeResFromReg(resName=args['&lt;resource&gt;'])\n        elif args['list']:\n            resReg.listRes()\n        elif args['clean']:\n            resReg.cleanReg()\n</code></pre>"},{"location":"api/res_registry/","title":"Resource Registry","text":""},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry","title":"resRegistry","text":"<pre><code>resRegistry()\n</code></pre> <p>Registry class for managing jps resources.</p> <p>Attributes:</p> Name Type Description <code>resReg</code> <code>dict</code> <p>resource registry dictionary</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def __init__(self):\n    \"\"\"\n    Constructs the registry object. If regsitry file does not exists, it creates one on the fly.\n    \"\"\"\n    try:\n        self.resReg = json.load(pkg_resources.resource_stream(__name__, os.path.join('..','resources',_RES_REG_FILE)))\n    except FileNotFoundError:\n        self.resReg = {'resources':{}}\n        self._updateRegFile()\n</code></pre>"},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry.addResToReg","title":"addResToReg","text":"<pre><code>addResToReg(resName, resLoc, resMainJarFile=None)\n</code></pre> <p>Adds a resource to the registry.</p> <p>Parameters:</p> Name Type Description Default <code>resName</code> <code>str</code> <p>resource name</p> required <code>resLoc</code> <code>str</code> <p>path to the resource directory</p> required <code>resMainJarFile</code> <code>str</code> <p>name of the main jar file, if not provided the first jar found in the resource dir will be selected, if no jars are present it is set to None</p> <code>None</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def addResToReg(self, resName, resLoc, resMainJarFile=None):\n    \"\"\"\n    Adds a resource to the registry.\n\n    Args:\n        resName (str): resource name\n        resLoc (str): path to the resource directory\n        resMainJarFile (str): name of the main jar file, if not provided the first jar found\n            in the resource dir will be selected, if no jars are present it is set to None\n    \"\"\"\n    if not self._isResInReg(resName):\n        print(\"Info: Adding the {0} resource...\".format(resName))\n        self._checkResName(resName)\n\n        # TODO default resources\n        #======================\n        #if self._isResInDefReg(resName):\n        #    print(\"Info: {0} is a default resource. Retrieving the resource metadata...\".format(resName))\n        #    resMeta = self._getResDefMeta(resName)\n        #    resLoc = resMeta['getFrom']\n        #    resMainJarFile = resMeta['mainFile']\n        ##======================\n        self._addResRegEntry(resName)\n        if resMainJarFile is None:\n            resMainJarFile = self._checkForMainJar(resLoc)\n        self._updateResRegEntry(resName, {'mainJarFile':resMainJarFile})\n        self._addResFiles(resName, resLoc)\n        self._addResMetaFile(resName)\n        self._updateRegFile()\n    else:\n        print('Info: Resource already exist.')\n</code></pre>"},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry.removeResFromReg","title":"removeResFromReg","text":"<pre><code>removeResFromReg(resName)\n</code></pre> <p>Removes a resource from the registry.</p> <p>Note, it removes all the resource files as well.</p> <p>Parameters:</p> Name Type Description Default <code>resName</code> <code>str</code> <p>resource name</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def removeResFromReg(self, resName):\n    \"\"\"\n    Removes a resource from the registry.\n    &gt; Note, it removes all the resource files as well.\n\n    Args:\n        resName (str): resource name\n    \"\"\"\n    if self._isResInReg(resName):\n        print(\"Info: Removing {0} resource...\".format(resName))\n        self._removeResRegEntry(resName)\n        self._removeResFiles(resName)\n        self._updateRegFile()\n    else:\n        print(\"Info: {0} resource is not on the registry!\".format(resName))\n</code></pre>"},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry.listRes","title":"listRes","text":"<pre><code>listRes()\n</code></pre> <p>Lists all currently installed resources.</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def listRes(self):\n    \"\"\"\n    Lists all currently installed resources.\n    \"\"\"\n    print('\\n'.join(list(self.resReg['resources'].keys())))\n</code></pre>"},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry.cleanReg","title":"cleanReg","text":"<pre><code>cleanReg()\n</code></pre> <p>Cleans the registry.</p> <p>Use with caution. The command removes:</p> <ul> <li> <p>all registry entries with no corresponding resource files</p> </li> <li> <p>all resource files with no corresponding registry entries</p> </li> </ul> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def cleanReg(self):\n    \"\"\"\n    Cleans the registry.\n\n    &gt; Use with caution. The command removes:\n\n    &gt; - all registry entries with no corresponding resource files\n\n    &gt; - all resource files with no corresponding registry entries\n    \"\"\"\n\n    print(\"Info: Removing resources that do not exist on the registry...\")\n    for f in os.scandir(_RES_DIR):\n        if f.is_dir():\n            if not self._isResInReg(f.name):\n                print(\"Info: Found {} directory that is not on the registry. Removing...\".format(f.name))\n                shutil.rmtree(f.path)\n    print(\"Info: Removing resources complete.\")\n    print(\"Info: Removing registry entries that have no corresponding resource files...\")\n    if not self._isEmpty():\n        for resName in self.resReg['resources']:\n            if not os.path.exists(self._getResPath(resName)):\n                print(\"Info: Found {} registry entry with no resource files.\".format(resName))\n                self._removeResRegEntry(resName)\n    print(\"Info: Removing registry entries complete.\")\n</code></pre>"},{"location":"api/res_registry/#twa.resRegistry.resRegistry.resRegistry.getResMainFilePath","title":"getResMainFilePath","text":"<pre><code>getResMainFilePath(resName)\n</code></pre> <p>Returns an absolute path to the resource main jar file.</p> <p>Parameters:</p> Name Type Description Default <code>resName</code> <code>str</code> <p>resource name</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/resRegistry/resRegistry.py</code> <pre><code>def getResMainFilePath(self, resName):\n    \"\"\"\n    Returns an absolute path to the resource main jar file.\n\n    Args:\n        resName (str): resource name\n    \"\"\"\n    if resName in self.resReg['resources']:\n        mainFile = self.resReg['resources'][resName]['mainJarFile']\n        return os.path.join(self._getResPath(resName), mainFile)\n    else:\n        return None\n</code></pre>"},{"location":"api/sparql_client/","title":"SparqlClient","text":""},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient","title":"PySparqlClient","text":"<pre><code>PySparqlClient(query_endpoint: str, update_endpoint: str, kg_user: str = None, kg_password: str = None, fs_url: str = None, fs_user: str = None, fs_pwd: str = None)\n</code></pre> <p>The purpose of this class is to provide a Python interface to the Java-based RemoteStoreClient for querying and updating the knowledge graph (triplestore).</p> <p>Attributes:</p> Name Type Description <code>jpsBaseLib_view</code> <code>JVM</code> <p>The module view for the JpsBaseLib</p> <code>kg_client</code> <code>RemoteStoreClient</code> <p>The Java-based uk.ac.cam.cares.jps.base.query.RemoteStoreClient object</p> <code>query_endpoint</code> <code>str</code> <p>The SPARQL query endpoint of the knowledge graph</p> <code>update_endpoint</code> <code>str</code> <p>The SPARQL update endpoint of the knowledge graph</p> <code>fs_url</code> <code>str</code> <p>The URL of the fileserver</p> <code>fs_auth</code> <code>str</code> <p>The authentication information for the fileserver</p> <p>Parameters:</p> Name Type Description Default <code>query_endpoint</code> <code>str</code> <p>The SPARQL query endpoint of the knowledge graph</p> required <code>update_endpoint</code> <code>str</code> <p>The SPARQL update endpoint of the knowledge graph</p> required <code>kg_user</code> <code>str</code> <p>The username for the knowledge graph</p> <code>None</code> <code>kg_password</code> <code>str</code> <p>The password for the knowledge graph</p> <code>None</code> <code>fs_url</code> <code>str</code> <p>The URL of the fileserver</p> <code>None</code> <code>fs_user</code> <code>str</code> <p>The username for the fileserver</p> <code>None</code> <code>fs_pwd</code> <code>str</code> <p>The password for the fileserver</p> <code>None</code> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def __init__(\n    self,\n    query_endpoint: str,\n    update_endpoint: str,\n    kg_user: str = None,\n    kg_password: str = None,\n    fs_url: str = None,\n    fs_user: str = None,\n    fs_pwd: str = None\n):\n    \"\"\"\n    The constructor for the PySparqlClient class.\n\n    Args:\n        query_endpoint (str): The SPARQL query endpoint of the knowledge graph\n        update_endpoint (str): The SPARQL update endpoint of the knowledge graph\n        kg_user (str): The username for the knowledge graph\n        kg_password (str): The password for the knowledge graph\n        fs_url (str): The URL of the fileserver\n        fs_user (str): The username for the fileserver\n        fs_pwd (str): The password for the fileserver\n    \"\"\"\n    # create a JVM module view and use it to import the required java classes\n    self.jpsBaseLib_view = jpsBaseLibGW.createModuleView()\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view,\"uk.ac.cam.cares.jps.base.query.*\")\n    jpsBaseLibGW.importPackages(self.jpsBaseLib_view,\"uk.ac.cam.cares.jps.base.derivation.*\")\n\n    if kg_user is not None:\n        self.kg_client = self.jpsBaseLib_view.RemoteStoreClient(query_endpoint, update_endpoint, kg_user, kg_password)\n    else:\n        self.kg_client = self.jpsBaseLib_view.RemoteStoreClient(query_endpoint, update_endpoint)\n\n    # Expose query and update endpoint\n    self.query_endpoint = query_endpoint\n    self.update_endpoint = update_endpoint\n\n    # Also initialise the fileserver URL and auth info\n    # TODO in the future development, make use of pyuploader\n    self.fs_url = fs_url\n    self.fs_auth = (fs_user, fs_pwd)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.check_instance_class","title":"check_instance_class","text":"<pre><code>check_instance_class(instance: str, instance_class: str) -&gt; bool\n</code></pre> <p>This method checks if the given instance is instantiated from the given instance class.</p> <p>Parameters:</p> Name Type Description Default <code>instance</code> <code>str</code> <p>IRI of an instance</p> required <code>instance_class</code> <code>str</code> <p>IRI of the instance class to be checked against</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the instance is instantiated from the given instance class, False otherwise</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def check_instance_class(self, instance: str, instance_class: str) -&gt; bool:\n    \"\"\"\n    This method checks if the given instance is instantiated from the given instance class.\n\n    Args:\n        instance (str): IRI of an instance\n        instance_class (str): IRI of the instance class to be checked against\n\n    Returns:\n        bool: True if the instance is instantiated from the given instance class, False otherwise\n    \"\"\"\n    # Delete \"&lt;\" and \"&gt;\" around the IRI\n    instance = utils.trim_iri(instance)\n    instance_class = utils.trim_iri(instance_class)\n\n    # Prepare query string, ignore owl:Thing and owl:NamedIndividual\n    query = f\"\"\"{PREFIX_RDFS} {PREFIX_RDF} {PREFIX_XSD} {PREFIX_OWL}\n            SELECT ?result\n            WHERE {{ &lt;{instance}&gt; rdf:type ?type .\n                FILTER(?type != owl:Thing &amp;&amp; ?type != owl:NamedIndividual) .\n                BIND(xsd:boolean(if(?type = &lt;{instance_class}&gt;, \"true\", \"false\")) as ?result)\n            }}\"\"\"\n\n    # Perform query\n    response = self.perform_query(query)\n\n    res = [list(r.values())[0] for r in response]\n    if res[0] == 'true':\n        return True\n    else:\n        return False\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.get_amount_of_triples","title":"get_amount_of_triples","text":"<pre><code>get_amount_of_triples() -&gt; int\n</code></pre> <p>This method returns the total number of triples in the knowledge graph.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The total number of triples in the knowledge graph</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def get_amount_of_triples(self) -&gt; int:\n    \"\"\"\n    This method returns the total number of triples in the knowledge graph.\n\n    Returns:\n        int: The total number of triples in the knowledge graph\n    \"\"\"\n    # return an integer of total number of triples\n    return self.kg_client.getTotalNumberOfTriples()\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.perform_query","title":"perform_query","text":"<pre><code>perform_query(query: str) -&gt; Dict[str, Any]\n</code></pre> <p>This function performs query to knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>SPARQL Query string</p> required <p>Returns:</p> Type Description <code>Dict[str, Any]</code> <p>Dict[str, Any]: The response of the query</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def perform_query(self, query: str) -&gt; Dict[str, Any]:\n    \"\"\"\n    This function performs query to knowledge graph.\n\n    Args:\n        query (str): SPARQL Query string\n\n    Returns:\n        Dict[str, Any]: The response of the query\n    \"\"\"\n    response = str(self.kg_client.executeQuery(query))\n    return json.loads(response)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.perform_update","title":"perform_update","text":"<pre><code>perform_update(update: str) -&gt; None\n</code></pre> <p>This function performs SPARQL Update to knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>update</code> <code>str</code> <p>SPARQL Update string</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def perform_update(self, update: str) -&gt; None:\n    \"\"\"\n    This function performs SPARQL Update to knowledge graph.\n\n    Args:\n        update (str): SPARQL Update string\n    \"\"\"\n    self.kg_client.executeUpdate(update)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.get_all_instances_of_class","title":"get_all_instances_of_class","text":"<pre><code>get_all_instances_of_class(class_iri: str) -&gt; List[str]\n</code></pre> <p>This function returns all instances of the given class.</p> <p>Parameters:</p> Name Type Description Default <code>class_iri</code> <code>str</code> <p>IRI of the class</p> required <p>Returns:</p> Type Description <code>List[str]</code> <p>List[str]: List of IRIs of all instances of the given class</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def get_all_instances_of_class(self, class_iri: str) -&gt; List[str]:\n    \"\"\"\n    This function returns all instances of the given class.\n\n    Args:\n        class_iri (str): IRI of the class\n\n    Returns:\n        List[str]: List of IRIs of all instances of the given class\n    \"\"\"\n    # Prepare query string\n    query = f\"\"\"SELECT ?iri WHERE {{ ?iri a &lt;{class_iri}&gt; }}\"\"\"\n\n    # Perform query\n    response = self.perform_query(query)\n\n    return [list(r.values())[0] for r in response]\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.upload_ontology","title":"upload_ontology","text":"<pre><code>upload_ontology(file_path: str) -&gt; None\n</code></pre> <p>This function uploads ontology to knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str</code> <p>The file path of ontology to be uploaded</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def upload_ontology(self, file_path: str) -&gt; None:\n    \"\"\"\n    This function uploads ontology to knowledge graph.\n\n    Args:\n        file_path (str): The file path of ontology to be uploaded\n    \"\"\"\n    javaFile = self.jpsBaseLib_view.java.io.File(file_path)\n    self.kg_client.uploadFile(javaFile)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.upload_file","title":"upload_file","text":"<pre><code>upload_file(local_file_path: str, filename_with_subdir: str = None) -&gt; Tuple[str, float]\n</code></pre> <p>This function uploads the file at the given local file path to file server.</p> <p>Parameters:</p> Name Type Description Default <code>local_file_path</code> <code>str</code> <p>The local file path of the file to be uploaded</p> required <code>filename_with_subdir</code> <code>str</code> <p>The filename with subdirectory in the file server</p> <code>None</code> <p>Returns:</p> Type Description <code>Tuple[str, float]</code> <p>Tuple[str, float]: The remote file path and the timestamp when the file was uploaded</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def upload_file(self, local_file_path: str, filename_with_subdir: str = None) -&gt; Tuple[str, float]:\n    \"\"\"\n    This function uploads the file at the given local file path to file server.\n\n    Args:\n        local_file_path (str): The local file path of the file to be uploaded\n        filename_with_subdir (str): The filename with subdirectory in the file server\n\n    Returns:\n        Tuple[str, float]: The remote file path and the timestamp when the file was uploaded\n    \"\"\"\n    if self.fs_url is None or self.fs_auth is None:\n        raise Exception(\"ERROR: Fileserver URL and auth are not provided correctly.\")\n    with open(local_file_path, 'rb') as file_obj:\n        files = {'file': file_obj}\n        timestamp_upload, response = datetime.now().timestamp(), requests.post(\n            self.fs_url+filename_with_subdir if filename_with_subdir is not None else self.fs_url,\n            auth=self.fs_auth, files=files\n        )\n\n        # If the upload succeeded, return the remote file path and the timestamp when the file was uploaded\n        if (response.status_code == requests.status_codes.codes.OK):\n            remote_file_path = response.headers['file']\n\n            return remote_file_path, timestamp_upload\n        else:\n            raise Exception(f\"ERROR: Local file ({local_file_path}) upload to file server &lt;{self.fs_url}&gt; failed with code {response.status_code} and response body: {str(response.content)}\")\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.download_file","title":"download_file","text":"<pre><code>download_file(remote_file_path: str, downloaded_file_path: str) -&gt; None\n</code></pre> <p>This function downloads a file given the remote file path and the local file path to store the downloaded file.</p> <p>Parameters:</p> Name Type Description Default <code>remote_file_path</code> <code>str</code> <p>The remote file path of the file to be downloaded</p> required <code>downloaded_file_path</code> <code>str</code> <p>The local file path to store the downloaded file</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def download_file(self, remote_file_path: str, downloaded_file_path: str) -&gt; None:\n    \"\"\"\n    This function downloads a file given the remote file path and the local file path to store the downloaded file.\n\n    Args:\n        remote_file_path (str): The remote file path of the file to be downloaded\n        downloaded_file_path (str): The local file path to store the downloaded file\n    \"\"\"\n    response = requests.get(remote_file_path, auth=self.fs_auth)\n    if (response.status_code == requests.status_codes.codes.OK):\n        with open(downloaded_file_path, 'wb') as file_obj:\n            for chunk in response.iter_content(chunk_size=128):\n                file_obj.write(chunk)\n    else:\n        raise Exception(f\"ERROR: File &lt;{remote_file_path}&gt; download failed with code {response.status_code} and response body: {str(response.content)}\")\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.upload_graph","title":"upload_graph","text":"<pre><code>upload_graph(g: Graph) -&gt; None\n</code></pre> <p>This function uploads the given graph to the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The rdflib.Graph object to be uploaded</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def upload_graph(self, g: Graph) -&gt; None:\n    \"\"\"\n    This function uploads the given graph to the knowledge graph.\n\n    Args:\n        g (Graph): The rdflib.Graph object to be uploaded\n    \"\"\"\n    update = f\"\"\"INSERT DATA {{ {g.serialize(format='nt')} }}\"\"\"\n    self.perform_update(update)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.delete_graph","title":"delete_graph","text":"<pre><code>delete_graph(g: Graph) -&gt; None\n</code></pre> <p>This function deletes the triples in the graph provided.</p> <p>Parameters:</p> Name Type Description Default <code>g</code> <code>Graph</code> <p>The rdflib.Graph object to be deleted</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def delete_graph(self, g: Graph) -&gt; None:\n    \"\"\"\n    This function deletes the triples in the graph provided.\n\n    Args:\n        g (Graph): The rdflib.Graph object to be deleted\n    \"\"\"\n    update = f\"\"\"DELETE DATA {{ {g.serialize(format='nt')} }}\"\"\"\n    self.perform_update(update)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.delete_and_insert_graphs","title":"delete_and_insert_graphs","text":"<pre><code>delete_and_insert_graphs(g_to_delete: Graph, g_to_insert: Graph) -&gt; None\n</code></pre> <p>This function deletes the triples in the first graph and inserts the triples in the second graph.</p> <p>Parameters:</p> Name Type Description Default <code>g_to_delete</code> <code>Graph</code> <p>The rdflib.Graph object to be deleted</p> required <code>g_to_insert</code> <code>Graph</code> <p>The rdflib.Graph object to be inserted</p> required Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def delete_and_insert_graphs(self, g_to_delete: Graph, g_to_insert: Graph) -&gt; None:\n    \"\"\"\n    This function deletes the triples in the first graph and inserts the triples in the second graph.\n\n    Args:\n        g_to_delete (Graph): The rdflib.Graph object to be deleted\n        g_to_insert (Graph): The rdflib.Graph object to be inserted\n    \"\"\"\n    update = f\"\"\"DELETE {{ {g_to_delete.serialize(format='nt')} }}\n                 INSERT {{ {g_to_insert.serialize(format='nt')} }}\n                 WHERE {{}}\"\"\"\n    self.perform_update(update)\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.check_if_triple_exist","title":"check_if_triple_exist","text":"<pre><code>check_if_triple_exist(s: str, p: str, o: Any, data_type: str = None) -&gt; bool\n</code></pre> <p>This function checks if the given triple exists in the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>s</code> <code>str</code> <p>Subject IRI</p> required <code>p</code> <code>str</code> <p>Predicate IRI</p> required <code>o</code> <code>Any</code> <p>Object IRI or literal value</p> required <code>data_type</code> <code>str</code> <p>Data type of the object literal</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the triple exists, False otherwise</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def check_if_triple_exist(self, s: str, p: str, o: Any, data_type: str = None) -&gt; bool:\n    \"\"\"\n    This function checks if the given triple exists in the knowledge graph.\n\n    Args:\n        s (str): Subject IRI\n        p (str): Predicate IRI\n        o (Any): Object IRI or literal value\n        data_type (str): Data type of the object literal\n\n    Returns:\n        bool: True if the triple exists, False otherwise\n    \"\"\"\n    s = \"?s\" if s is None else f\"&lt;{utils.trim_iri(s)}&gt;\"\n    p = \"?p\" if p is None else f\"&lt;{utils.trim_iri(p)}&gt;\"\n    o = \"?o\" if o is None else f\"&lt;{utils.trim_iri(o)}&gt;\" if data_type is None else Literal(o, datatype=utils.trim_iri(data_type))._literal_n3()\n    query = f\"\"\"ASK {{{s} {p} {o}.}}\"\"\"\n    response = self.perform_query(query)\n    return response[0]['ASK']\n</code></pre>"},{"location":"api/sparql_client/#twa.kg_operations.sparql_client.PySparqlClient.get_outgoing_and_attributes","title":"get_outgoing_and_attributes","text":"<pre><code>get_outgoing_and_attributes(node_iris: Set[str]) -&gt; Dict[str, Dict[str, Set[Any]]]\n</code></pre> <p>This function returns the outgoing edges and attributes of the given nodes in the knowledge graph.</p> <p>Parameters:</p> Name Type Description Default <code>node_iris</code> <code>Set[str]</code> <p>The set of IRIs of the nodes</p> required <p>Returns:</p> Type Description <code>Dict[str, Dict[str, Set[Any]]]</code> <p>Dict[str, Dict[str, Set[Any]]]: The dictionary of the outgoing edges and attributes of the given nodes, where the key is the node IRI</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/kg_operations/sparql_client.py</code> <pre><code>def get_outgoing_and_attributes(self, node_iris: Set[str]) -&gt; Dict[str, Dict[str, Set[Any]]]:\n    \"\"\"\n    This function returns the outgoing edges and attributes of the given nodes in the knowledge graph.\n\n    Args:\n        node_iris (Set[str]): The set of IRIs of the nodes\n\n    Returns:\n        Dict[str, Dict[str, Set[Any]]]: The dictionary of the outgoing edges and attributes of the given nodes, where the key is the node IRI\n    \"\"\"\n    result = {}\n    if isinstance(node_iris, str):\n        node_iris = [node_iris]\n    if isinstance(node_iris, list):\n        node_iris = set(node_iris)\n    if not node_iris:\n        return result\n    query = f\"\"\"SELECT ?s ?p ?o WHERE {{VALUES ?s {{ {' '.join([f'&lt;{utils.trim_iri(iri)}&gt;' for iri in node_iris])} }} ?s ?p ?o.}}\"\"\"\n    response = self.perform_query(query)\n    for r in response:\n        if r['s'] not in result:\n            result[r['s']] = {}\n        if r['p'] not in result[r['s']]:\n            result[r['s']][r['p']] = set()\n        result[r['s']][r['p']].add(r['o'])\n    return result\n</code></pre>"},{"location":"api/utilities/","title":"Utilities","text":""},{"location":"api/utilities/#twa.data_model.iris.TWA_BASE_URL","title":"TWA_BASE_URL  <code>module-attribute</code>","text":"<pre><code>TWA_BASE_URL = 'https://www.theworldavatar.com/kg/'\n</code></pre> <p>To be used by attaching specific namespace and class name to it e.g. https://www.theworldavatar.com/kg/ontolab/LabEquipment</p>"},{"location":"api/utilities/#twa.data_model.utils.check_valid_url","title":"check_valid_url","text":"<pre><code>check_valid_url(url: str) -&gt; str\n</code></pre> <p>This function checks if the provided URL for namespace starts with \"http://\" or \"https://\". If so, it returns the URL and add \"/\" if it's not already ending with a \"/\" or \"#\".</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to be checked</p> required <p>Raises:</p> Type Description <code>Exception</code> <p>The URL is not provided with either \"http://\" or \"https://\" as its start</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The original URL or the processed URL with a \"/\" added at its end</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/utils.py</code> <pre><code>def check_valid_url(url: str) -&gt; str:\n    \"\"\"\n    This function checks if the provided URL for namespace starts with \"http://\" or \"https://\".\n    If so, it returns the URL and add \"/\" if it's not already ending with a \"/\" or \"#\".\n\n    Args:\n        url (str): The URL to be checked\n\n    Raises:\n        Exception: The URL is not provided with either \"http://\" or \"https://\" as its start\n\n    Returns:\n        str: The original URL or the processed URL with a \"/\" added at its end\n    \"\"\"\n    if url.startswith('http://') or url.startswith('https://'):\n        return url if url[-1] in ['/', '#'] else url + '/'\n    else:\n        raise Exception(\"The provide url for namespace should start with either 'http://' or 'https://'.\")\n</code></pre>"},{"location":"api/utilities/#twa.data_model.utils.construct_namespace_iri","title":"construct_namespace_iri","text":"<pre><code>construct_namespace_iri(base_url: str, namespace: str) -&gt; str\n</code></pre> <p>This function constructs the namespace IRI from the base URL and namespace. For example, if the base URL is \"https://www.theworldavatar.com/kg\" and the namespace is \"ontolab\", The function will return \"https://www.theworldavatar.com/kg/ontolab\".</p> <p>Parameters:</p> Name Type Description Default <code>base_url</code> <code>str</code> <p>The base URL of the namespace IRI, e.g. \"https://www.theworldavatar.com/kg\"</p> required <code>namespace</code> <code>str</code> <p>The namespace, e.g. \"ontolab\", will be ignored if None</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/utils.py</code> <pre><code>def construct_namespace_iri(base_url: str, namespace: str) -&gt; str:\n    \"\"\"\n    This function constructs the namespace IRI from the base URL and namespace.\n    For example, if the base URL is \"https://www.theworldavatar.com/kg\" and the namespace is \"ontolab\",\n    The function will return \"https://www.theworldavatar.com/kg/ontolab\".\n\n    Args:\n        base_url (str): The base URL of the namespace IRI, e.g. \"https://www.theworldavatar.com/kg\"\n        namespace (str): The namespace, e.g. \"ontolab\", will be ignored if None\n\n    Returns:\n        str: The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"\n    \"\"\"\n    return f'{check_valid_url(base_url)}{namespace}' if namespace is not None else base_url\n</code></pre>"},{"location":"api/utilities/#twa.data_model.utils.construct_rdf_type","title":"construct_rdf_type","text":"<pre><code>construct_rdf_type(namespace_iri: str, class_name: str) -&gt; str\n</code></pre> <p>This function constructs the RDF type IRI from the namespace IRI and class name.</p> <p>Parameters:</p> Name Type Description Default <code>namespace_iri</code> <code>str</code> <p>The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"</p> required <code>class_name</code> <code>str</code> <p>The class name, e.g. \"LabEquipment\"</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The RDF type IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab/LabEquipment\"</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/utils.py</code> <pre><code>def construct_rdf_type(namespace_iri: str, class_name: str) -&gt; str:\n    \"\"\"\n    This function constructs the RDF type IRI from the namespace IRI and class name.\n\n    Args:\n        namespace_iri (str): The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"\n        class_name (str): The class name, e.g. \"LabEquipment\"\n\n    Returns:\n        str: The RDF type IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab/LabEquipment\"\n    \"\"\"\n    return f'{check_valid_url(namespace_iri)}{class_name}'\n</code></pre>"},{"location":"api/utilities/#twa.data_model.utils.init_instance_iri","title":"init_instance_iri","text":"<pre><code>init_instance_iri(namespace_iri: str, class_name: str) -&gt; str\n</code></pre> <p>The function constructs a unique IRI for an instance of a class in a namespace.</p> <p>Parameters:</p> Name Type Description Default <code>namespace_iri</code> <code>str</code> <p>The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"</p> required <code>class_name</code> <code>str</code> <p>The class name, e.g. \"LabEquipment\"</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The unique IRI for the instance, e.g. \"https://www.theworldavatar.com/kg/ontolab/LabEquipment_12345678\"</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/utils.py</code> <pre><code>def init_instance_iri(namespace_iri: str, class_name: str) -&gt; str:\n    \"\"\"\n    The function constructs a unique IRI for an instance of a class in a namespace.\n\n    Args:\n        namespace_iri (str): The namespace IRI, e.g. \"https://www.theworldavatar.com/kg/ontolab\"\n        class_name (str): The class name, e.g. \"LabEquipment\"\n\n    Returns:\n        str: The unique IRI for the instance, e.g. \"https://www.theworldavatar.com/kg/ontolab/LabEquipment_12345678\"\n    \"\"\"\n    return f'{construct_rdf_type(namespace_iri, class_name)}_{str(uuid4())}'\n</code></pre>"},{"location":"api/utilities/#twa.data_model.utils.trim_iri","title":"trim_iri","text":"<pre><code>trim_iri(iri: Union[str, List[str]]) -&gt; Union[str, List[str]]\n</code></pre> <p>This function trims the \"&lt;\" and \"&gt;\" characters from the left and right side of the given IRI (or lists of IRIs).</p> <p>Parameters:</p> Name Type Description Default <code>iri</code> <code>str or list</code> <p>The IRI(s) to be trimmed</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>Union[str, List[str]]</code> <p>The trimmed IRI</p> Source code in <code>JPS_BASE_LIB/python_wrapper/twa/data_model/utils.py</code> <pre><code>def trim_iri(iri: Union[str, List[str]]) -&gt; Union[str, List[str]]:\n    \"\"\"\n    This function trims the \"&lt;\" and \"&gt;\" characters from the left and right side of the given IRI (or lists of IRIs).\n\n    Args:\n        iri (str or list): The IRI(s) to be trimmed\n\n    Returns:\n        str: The trimmed IRI\n    \"\"\"\n    if isinstance(iri, list):\n        for i in range(len(iri)):\n            iri[i] = trim_iri(iri[i])\n    else:\n        iri = iri.strip().lstrip(\"&lt;\").rstrip(\"&gt;\")\n    return iri\n</code></pre>"},{"location":"examples/additional_java_lib/","title":"Use additional Java library","text":"<p><code>stack-clients</code> is another commonly used Java library within <code>TheWorldAvatar</code>. It is therefore chosen as an example to demonstrate how to use additional Java library. The same principle can be applied to any other Java packages.</p>"},{"location":"examples/additional_java_lib/#build-and-package-the-jar-files","title":"Build and package the jar files","text":"<p>All commands tested in WSL2.</p> <p>The first step is to build the <code>stack-clients</code> package: <pre><code>cd TheWorldAvatar/Deploy/stacks/dynamic/stack-clients\nmvn clean install -DskipTests\n</code></pre></p> <p>Then copy the <code>stack-clients.jar</code> file and the <code>lib</code> folder into a temporary folder, say name <code>tmp_stack</code>: <pre><code>mkdir tmp_stack\ncp target/stack-clients-*.jar tmp_stack/\ncp -r target/lib tmp_stack/lib\n</code></pre></p> <p>Finally install the stack-clients library into the <code>twa</code>: <pre><code>jpsrm install StackClients tmp_stack\n</code></pre></p> <p>Note that here we are not providing the <code>--jar</code> option so that <code>jpsrm</code> will use the first jar file it finds in the <code>tmp_stack</code> folder. Given that there is only one jar file in this folder, this will work just fine.</p> <p>Upon successful installation, you will see below messages in the concole: <pre><code>Info: Adding the StackClients resource...\nInfo: Adding StackClients resource to the registry.\nInfo: Fetching StackClients resource files.\nInfo: Installing StackClients files...\nInfo: Installing StackClients files complete.\nInfo: Saving the registry.\n</code></pre></p> <p>The temporary folder can now be safely removed:</p> <p><code>rm -rf</code> should be used with caution!!!</p> <pre><code>rm -rf tmp_stack\n</code></pre>"},{"location":"examples/additional_java_lib/#instantiate-and-launch-gateway","title":"Instantiate and launch gateway","text":"<p>Note that it is recommended to have ONLY ONE gateway object in your Python application per java resource you wish to access. This can be easily achieved by instantiating and starting the resource gateway objects in a single module and then to import these objects instances to any other module that requires it.</p> <p>Therefore, one can instantiate the gateway for <code>StackClients</code> in the following way:</p> <p><code>File: stack_clients_gateway.py</code></p> <pre><code>from twa.resources import StackClients\n\n\nstackClientsGw = StackClients()\nstackClientsGw.launchGateway()\n</code></pre> <p>and importing it in any other Python modules:</p> <p><code>File: my_python_script.py</code></p> <pre><code>from stack_clients_gateway import stackClientsGw\n\n# Create module views to relevant Stack clients\nstackClientsView = stackClientsGw.createModuleView()\nstackClientsGw.importPackages(stackClientsView, \"com.cmclinnovations.stack.clients.docker.ContainerClient\")\n\n# Retrieve endpoint configurations from Stack clients\ncontainerClient = stackClientsView.ContainerClient()\n\n# other custom codes...\n</code></pre>"},{"location":"examples/dif/","title":"Derived Information Framework (DIF)","text":"<p>The derived information framework (DIF) packaged in <code>twa</code> is a Python equivalent of <code>uk.ac.cam.cares.jps.base.agent.DerivationAgent.java</code> but based on Flask application behind a gunicorn server. This is inspired by the Example: Python agent.</p> <p>To read more about the Java-native implementation of <code>DerivationAgent</code> and derivation operations provided in <code>uk.ac.cam.cares.jps.base.derivation.DerivationClient.java</code>, please refer to below links:</p> <ul> <li><code>DerivationClient</code> - derivation client Java classes that process the derivations</li> <li><code>DerivationAgent.java</code> - derivation agent Java class that uses methods provided in <code>DerivationClient</code></li> <li><code>DerivationAsynExample</code> - example on directed acyclic graph (DAG) of derivations operated by derivation agents in Java</li> </ul> <p>To read the academic paper describing the DIF:</p> <ul> <li>Jiaru Bai, Kok Foong Lee, Markus Hofmeister, Sebastian Mosbach, Jethro Akroyd, and Markus Kraft. (2024). A derived information framework for a dynamic knowledge graph and its application to smart cities. Future Generation Computer Systems 152, 112\u2013126. doi:10.1016/j.future.2023.10.008</li> </ul> <p>To read the academic papers using the DIF:</p> <ul> <li>Jiaru Bai, Sebastian Mosbach, Connor J. Taylor, Dogancan Karan, Kok Foong Lee, Simon D. Rihm, Jethro Akroyd, Alexei A. Lapkin, and Markus Kraft. (2024). A dynamic knowledge graph approach to distributed self-driving laboratories. Nature Communications 15, 462. doi:10.1038/s41467-023-44599-9</li> <li>Wanni Xie, Feroz Farazi, John Atherton, Jiaru Bai, Sebastian Mosbach, Jethro Akroyd, and Markus Kraft. (2024). Dynamic knowledge graph approach for modelling the decarbonisation of power systems. Energy and AI 17, 100359. doi:10.1016/j.egyai.2024.10035</li> <li>Markus Hofmeister, Jiaru Bai, George Brownbridge, Sebastian Mosbach, Kok Foong Lee, Feroz Farazi, Michael Hillman, Mehal Agarwal, Srishti Ganguly, Jethro Akroyd, and Markus Kraft. (2024). Semantic agent framework for automated flood assessment using dynamic knowledge graphs. Data-Centric Engineering 5, 14. doi:10.1017/dce.2024.11</li> <li>Markus Hofmeister, George Brownbridge, Michael Hillman, Sebastian Mosbach, Jethro Akroyd, Kok Foong Lee, and Markus Kraft. (2024). Cross-domain flood risk assessment for smart cities using dynamic knowledge graphs. Sustainable Cities and Society 101, 105113. doi:10.1016/j.scs.2023.105113</li> <li>Markus Hofmeister, Kok Foong Lee, Yi-Kai Tsai, Magnus M\u00fcller, Karthik Nagarajan, Sebastian Mosbach, Jethro Akroyd, and Markus Kraft. (2024). Dynamic control of district heating networks with integrated emission modelling: A dynamic knowledge graph approach. Energy and AI 17, 100376. doi:10.1016/j.egyai.2024.100376</li> </ul> <p>A basic working example of using the DIF alone and in conjunction with the object graph mapper (OGM) is given below. Please refer to Object Graph Mapper (OGM) for examples on OGM itself.</p>"},{"location":"examples/dif/#develop-derivation-agent-server-side","title":"Develop derivation agent (server side)","text":"<p>An example agent that can be deployed using docker is provided here, it's strongly advised to stick to the folder structure below:</p> <p>Recommended Python agent folder layout</p> <pre><code>.\n\u251c\u2500\u2500 ...                         # other project files (README, LICENSE, etc..)\n\u251c\u2500\u2500 youragent                   # project source files for your agent\n\u2502   \u251c\u2500\u2500 agent                   # module that contains the agent logic\n\u2502   \u2502   \u251c\u2500\u2500 your_agent.py       # your derivation agent\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 conf                    # module that contains the agent config\n\u2502   \u2502   \u251c\u2500\u2500 your_conf.py        # specific configuration for your agent\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 data_model              # module that contains the dataclasses for concepts\n\u2502   \u2502   \u251c\u2500\u2500 your_onto.py        # dataclasses (OGM) for your ontology concepts\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 kg_operations           # module that handles knowledge graph operations\n\u2502   \u2502   \u251c\u2500\u2500 your_sparql.py      # sparql query and update strings for your agent\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 other_modules           # other necessary modules for your agent\n\u2502   \u2502   \u251c\u2500\u2500 module1.py\n\u2502   \u2502   \u251c\u2500\u2500 module2.py\n\u2502   \u2502   \u2514\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 entry_point.py          # agent entry point\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 youragent.env.example       # example environment variables for configuration\n\u251c\u2500\u2500 docker-compose.yml          # docker compose file\n\u251c\u2500\u2500 Dockerfile                  # Dockerfile\n\u2514\u2500\u2500 tests                       # tests files\n</code></pre> <p>Core script examples are shown below. Kindly see the inline documentation for clarifications.</p>"},{"location":"examples/dif/#agent-class","title":"Agent class","text":"<p><code>your_agent.py</code></p> <pre><code>from twa.agent import DerivationAgent\nfrom twa.data_model.derivation import DerivationInputs\nfrom twa.data_model.derivation import DerivationOutputs\nfrom youragent.kg_operations import YourSparqlClient\nfrom youragent.data_model import YourConcept\nfrom youragent.data_model import AnotherConcept\nfrom youragent.data_model import OutputConcept\n\n# NOTE For any developer to extend the DerivationAgent class, four @abstractmethod MUST be implemented\n# - agent_input_concepts = []\n# - agent_output_concepts = []\n# - validate_inputs(self, http_request) -&gt; bool\n# - process_request_parameters(self, derivation_inputs: DerivationInputs, derivation_outputs: DerivationOutputs)\nclass YourAgent(DerivationAgent):\n    ##########################################################\n    ## I. __init__ for custom configuration (if applicable) ##\n    ##########################################################\n    def __init__(self,\n        your_str_conf: str,\n        your_int_conf: int,\n        your_bool_conf: bool,\n        **kwargs\n    ):\n        super().__init__(**kwargs) # pass all other parameters to DerivationAgent.__init__, will throw error if unexpected input received\n        # Below you may want to assign your custom configuration\n        # How to provide them when instantiating agent will be detailed in your_conf.py, entry_point.py, and youragent.env.example\n        self.your_str_conf = your_str_conf\n        self.your_int_conf = your_int_conf\n        self.your_bool_conf = your_bool_conf\n\n    ###############################\n    ## II. Derivation agent part ##\n    ###############################\n    # Firstly, as the agent is designed to register itself in the knowledge graph when it is initialised\n    # One need to define the agent inputs/outputs by providing the concept IRIs as return values\n    # The registration is by default, which can be altered to False when instantiating agent\n    # One way of doing it is setting flag REGISTER_AGENT=false in the env file\n\n    # The agent inputs need to be provided in a list (even only one concept it involved)\n    agent_input_concepts = [YourConcept, AnotherConcept]\n\n    # The agent inputs need to be provided in a list (even only one concept it involved)\n    agent_output_concepts = [OutputConcept]\n\n    def validate_inputs(self, http_request) -&gt; bool:\n        # You may want to add some specific validation after the generic checks\n        if super().validate_inputs(http_request):\n            # do some specific checking\n            pass\n\n    def process_request_parameters(self, derivation_inputs: DerivationInputs, derivation_outputs: DerivationOutputs):\n        # Provide your agent logic that converts the agent inputs to triples of new created instances\n        # The derivation_inputs will be in the format of key-value pairs with the concept as key and instance iri as value\n        # For example:\n        # {\n        #     \"https://example/kg/onto/YourConcept\": [\"https://example/kg/onto/YourConcept_1\"],\n        #     \"https://example/kg/onto/AnotherConcept\": [\"https://example/kg/onto/AnotherConcept_1_1\",\n        #         \"https://example/kg/onto/AnotherConcept_1_2\"],\n        # }\n\n        # It is recommended to retrieve the agent inputs as OGM objects\n        your_concept = derivation_inputs.get_inputs_ogm_assume_one(\n            YourConcept, # the class you are interested in getting\n            sparql_client, # sparql_client that is connected to the knowledge graph endpoint\n            -1 # recursive_depth to control recursive queries\n        )\n\n        # The instance IRIs of the interested class (rdf:type) can be accessed via derivation_inputs.getIris(clz)\n        # e.g. assume we will take the first iri that has rdf:type YOUR_CONCEPT\n        instance_iri = derivation_inputs.getIris(YourConcept.rdf_type)[0]\n\n        # You may want to create instance of YourSparqlClient for specific queries/updates not covered by OGM\n        # YourSparqlClient should be defined in your_sparql.py that will be introduced later in this documentation page\n        # This client can be initialised with the configuration you already initialised in YourAgent.__init__ method\n        # A convenient method get_sparql_client is provided to get sparql_client if provided YourSparqlClient as arg\n        sparql_client = self.get_sparql_client(YourSparqlClient)\n\n        # Please note here we are using instance_iri of the YourConcept object within the provided derivation_inputs\n        response = sparql_client.your_sparql_query(your_concept.instance_iri)\n\n        # You may want to log something during agent execution\n        self.logger.info(\"YourAgent has done something.\")\n        self.logger.debug(\"And here are some details...\")\n\n        # The new output can be created using OGM\n        output_concept = OutputConcept(hasValue=5)\n        # Which is essentially triples below:\n        #   &lt;https://example/kg/onto/OutputConcept_UUID&gt; &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#type&gt; &lt;http://example/kg/onto/OutputConcept&gt;.\n        #   &lt;https://example/kg/onto/OutputConcept_UUID&gt; &lt;https://example/kg/onto/hasValue&gt; 5.\n\n        # The new created instances should be added to the derivation_outputs\n        # The easiest way to do it is by adding OGM objects\n        derivation_outputs.add_outputs_ogm(output_concept)\n\n    ################################################################\n    ## III. Any other periodical job the necessary for your agent ##\n    ################################################################\n    # Additionally, if you would like to define your own periodical job to be executed, you may do it like blow:\n    def your_periodical_job(self):\n        # Here provide the job logic to be executed periodically\n        pass\n\n    @DerivationAgent.periodical_job # This decorator enables the _start_your_periodical_job() to be called when calling start_all_periodical_job()\n    def _start_your_periodical_job(self):\n        # You also need to provide a function so that your periodical job can be started on its own\n        # self.scheduler is an object of APScheduler class\n        self.scheduler.add_job(\n            id='your_periodical_job', # the name for the periodical job\n            func=self.your_periodical_job, # the function for the periodical job\n            trigger='interval', # trigger type\n            seconds=10 # specify this value to the time interval you prefer for the job execution\n        )\n    # The start of your periodical job can be done in two ways once instantiated YourAgent (assume an object named \"your_agent\"):\n    # Option 1:\n    # your_agent._start_your_periodical_job() # start your periodical job independently\n    # Option 2:\n    # your_agent.start_all_periodical_job() # start your periodical job together with all other periodical jobs (e.g. _start_monitoring_derivations)\n    # An example is also provided in entry_point.py later in this documentation page\n</code></pre>"},{"location":"examples/dif/#agent-configuration","title":"Agent configuration","text":"<p><code>your_conf.py</code></p> <pre><code>from twa.conf import AgentConfig\nfrom twa.conf import config_generic\n\n# Similar to AgentConfig, here you may provide the configurations specific to your agent\nclass YourConfig(AgentConfig):\n    YOUR_STR_CONF: str\n    YOUR_INT_CONF: int\n    YOUR_BOOL_CONF: bool\n\ndef config_your_agent(env_file: str = None) -&gt; YourConfig:\n    \"\"\"Return configurations from either environment variables or env_file.\"\"\"\n    # Remember to put YourConfig as the first input argument to config_generic\n    return config_generic(YourConfig, env_file)\n</code></pre>"},{"location":"examples/dif/#ogm-data-models","title":"OGM data models","text":"<p><code>your_onto.py</code></p> <p>Please refer to Object Graph Mapper (OGM) for examples on OGM in more details.</p> <pre><code>from __future__ import annotations # imported to enable pydantic postponed annotations\n# The update_forward_refs() required in pydantic (1.x.x) to enable forward reference is no longer required for pydantic (2.x.x)\n# Instead, `from __future__ import annotations` at the beginning of the script should already enable this\n# For more details, please see https://pydantic-docs.helpmanual.io/usage/postponed_annotations/\nfrom twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty\n\nclass YourOntology(BaseOntology):\n    base_url = 'https://example/kg/'\n    namespace = 'onto'\n    owl_versionInfo = '0.0.1'\n    rdfs_comment = 'ontology'\n\nHasValue = DatatypeProperty.create_from_base(\n    'HasValue', YourOntology, 1, 1\n)\n\nclass YourConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    hasValue: HasValue[int]\n\nclass AnotherConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    hasValue: HasValue[int]\n\nclass OutputConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    hasValue: HasValue[int]\n</code></pre>"},{"location":"examples/dif/#custom-sparql-client","title":"Custom SPARQL client","text":"<p><code>your_sparql.py</code></p> <p>Please refer to Create custom sparql client for more details.</p> <pre><code>from twa.kg_operations import PySparqlClient\n\nclass YourSparqlClient(PySparqlClient):\n    # PySparqlClient class provides a few utility functions that developer can call within their own functions:\n    #  - checkInstanceClass(self, instance, instance_class)\n    #  - getAmountOfTriples(self)\n    #  - performQuery(self, query)\n    #  - performUpdate(self, update)\n    #  - uploadOntology(self, filePath)\n    #  - uploadFile(self, local_file_path)\n    #  - downloadFile(self, remote_file_path, downloaded_file_path)\n    #  more to come...\n\n    def your_sparql_query(self, your_instance_iri: str):\n        pass\n</code></pre>"},{"location":"examples/dif/#entry-point-for-docker","title":"Entry point for docker","text":"<p><code>entry_point.py</code></p> <pre><code>from twa.conf import config_derivation_agent\nfrom youragent.conf import config_your_agent\nfrom youragent.agent import YourAgent\n\ndef create_app():\n    # If you would like to deploy your agent within a docker container\n    # (using docker-compose.yml and youragent.env which will be introduced later in this documentation page)\n    # then you may use:\n    agent_config = config_your_agent() # here we assume custom config are required, for normal config, you may use:\n    # agent_config = config_derivation_agent()\n\n    # Else, if you would like to create agent to run in your memory\n    # then you may want to provide the path to youragent.env file as argument to function config_your_agent()\n    # i.e.,\n    # agent_config = config_your_agent(\"/path/to/youragent.env\")\n    # Again, for normal config, you may use:\n    # agent_config = config_derivation_agent(\"/path/to/youragent.env\")\n\n    # Create agent instance\n    agent = YourAgent(\n        your_str_conf = agent_config.YOUR_STR_CONF, # remember to populate custom config if applicable\n        your_int_conf = agent_config.YOUR_INT_CONF, # remember to populate custom config if applicable\n        your_bool_conf = agent_config.YOUR_BOOL_CONF, # remember to populate custom config if applicable\n        time_interval = agent_config.DERIVATION_PERIODIC_TIMESCALE,\n        kg_url = agent_config.SPARQL_QUERY_ENDPOINT,\n        kg_update_url = agent_config.SPARQL_UPDATE_ENDPOINT,\n        kg_user = agent_config.KG_USERNAME,\n        kg_password = agent_config.KG_PASSWORD,\n        fs_url = agent_config.FILE_SERVER_ENDPOINT,\n        fs_user = agent_config.FILE_SERVER_USERNAME,\n        fs_password = agent_config.FILE_SERVER_PASSWORD,\n        derivation_instance_base_url = agent_config.DERIVATION_INSTANCE_BASE_URL,\n        flask_config = FlaskConfig(),\n        agent_endpoint_base_url = agent_config.ONTOAGENT_OPERATION_HTTP_BASE_URL,\n        register_agent = agent_config.REGISTER_AGENT,\n        logger_for_dev = True,\n        # note that you can set the maximum number of threads to monitor async derivations at the same time\n        max_thread_monitor_async_derivations = agent_config.MAX_THREAD_MONITOR_ASYNC_DERIVATIONS,\n        # note that you may choose NOT to supply below parameters if you DO NOT want email notifications\n        email_recipient = agent_config.EMAIL_RECIPIENT,\n        email_subject_prefix = agent_config.EMAIL_SUBJECT_PREFIX,\n        email_username = agent_config.EMAIL_USERNAME,\n        email_auth_json_path = agent_config.EMAIL_AUTH_JSON_PATH,\n        email_start_end_async_derivations = agent_config.EMAIL_START_END_ASYNC_DERIVATIONS,\n    )\n\n    # Start listening sync/monitoring async derivations\n    # There are two ways of doing this, the first way it to start the monitoring process independently by:\n    # Option 1:\n    agent._start_monitoring_derivations()\n    # Option 2:\n    # Or, you can execute below line, which will start all periodical jobs that decorated with @DerivationAgent.periodical_job\n    # where _start_monitoring_derivations() will be called as well\n    # agent.start_all_periodical_job() # particularly useful when custom periodical job is defined\n\n    # Expose flask app of agent to be picked by gunicorn\n    app = agent.app\n\n    return app\n</code></pre>"},{"location":"examples/dif/#env-file","title":".env file","text":"<p><code>youragent.env.example</code></p> <pre><code>DERIVATION_PERIODIC_TIMESCALE=60\nDERIVATION_INSTANCE_BASE_URL=http://www.example.com/triplestore/repository/\nSPARQL_QUERY_ENDPOINT=http://www.example.com/blazegraph/namespace/kb/sparql\nSPARQL_UPDATE_ENDPOINT=http://www.example.com/blazegraph/namespace/kb/sparql\nKG_USERNAME=\nKG_PASSWORD=\nFILE_SERVER_ENDPOINT=http://www.example.com/FileServer/\nFILE_SERVER_USERNAME=\nFILE_SERVER_PASSWORD=\nONTOAGENT_OPERATION_HTTP_BASE_URL=http://localhost:7000/YourAgent\nREGISTER_AGENT=false\nMAX_THREAD_MONITOR_ASYNC_DERIVATIONS=1\nEMAIL_RECIPIENT=foo.1@bar.com;foo.2@bar.com\nEMAIL_SUBJECT_PREFIX=YourAgent\nEMAIL_USERNAME=your.gmail.address@gmail.com\nEMAIL_START_END_ASYNC_DERIVATIONS=false\n\nYOUR_STR_CONF=\nYOUR_INT_CONF=\nYOUR_BOOL_CONF=\n</code></pre> <p>You may want to commit this example file without credentials to git as a template for your agent configuration. At deployment, you can make a copy of this file, rename it to <code>youragent.env</code> and populate the credentials information. It is suggested to add <code>*.env</code> entry to your <code>.gitignore</code> of the agent folder, thus the renamed <code>youragent.env</code> (including credentials) will NOT be committed to git. For the usage of each default configuration, please refer to <code>twa.conf.AgentConfig</code> class.</p> <p>NOTE: you may want to provide <code>SPARQL_QUERY_ENDPOINT</code> and <code>SPARQL_UPDATE_ENDPOINT</code> as the internal port of the triple store (most likely blazegraph) docker container, e.g., <code>http://blazegraph:8080/blazegraph/namespace/kb/sparql</code>, if you would like to deploy your derivation agent and the triple store within the same docker stack (i.e. same docker-compose file, this is to be distinguished from the stack-client within The World Avatar, which is to be integrated into <code>twa</code> in the future iterations). In the endpoint, <code>blazegraph:8080</code> depends on your specification in the <code>docker-compose.yml</code> which will be introduced in Docker compose file.</p> <p>An alternative to this is to add <code>extra_hosts: - host.docker.internal:host-gateway</code> to the <code>your_agent</code> service in <code>docker-compose.yml</code> (as shown in Docker compose file) - then you can access the blazegraph via <code>http://host.docker.internal:27149/blazegraph/namespace/kb/sparql</code> (<code>host.docker.internal:27149</code> depends on your specification in the <code>docker-compose.yml</code>).</p> <p>Please also note that the host and port of <code>ONTOAGENT_OPERATION_HTTP_BASE_URL</code> (i.e., <code>localhost:7000</code> in <code>http://localhost:7000/YourAgent</code>) should match the value provided in the <code>docker-compose.yml</code> to ensure it is resolvable for handling synchronous derivations once registered in the knowledge graph.</p> <p>At deployment, configurations in this file will be picked up by <code>config_derivation_agent()</code> when instantiating the agent in <code>create_app()</code> of <code>entry_point.py</code> (see Entry point for docker).</p>"},{"location":"examples/dif/#docker-compose-file","title":"Docker compose file","text":"<p><code>docker-compose.yml</code></p> <pre><code>version: '3.8'\n\nservices:\n  # Your derivation agent\n  your_agent:\n    image: your_agent:1.0.0\n    container_name: your_agent\n    environment:\n      LOG4J_FORMAT_MSG_NO_LOOKUPS: \"true\"\n      # Add email auth json path that to be read by the yagmail service\n      EMAIL_AUTH_JSON_PATH: /run/secrets/email_auth\n    build:\n      context: .\n      dockerfile: ./Dockerfile\n    ports:\n      - 7000:5000\n    # Note that \"host.docker.internal\" is only a placeholder string, you can replace it with anything, e.g. \"localhost\" (HOWEVER, NOTE THAT \"localhost\" IS NO LONGER WORKING AS OF py4jps 1.0.23 (predecessor of twa), WHEREAS ANY OTHER PLACEHOLDER STRING STILL WORKS, AS DETAILED IN ISSUE https://github.com/cambridge-cares/TheWorldAvatar/issues/347)\n    # But please be aware that this can be unstable on some versions docker-desktop as noticed by other developers:\n    # https://github.com/docker/for-win/issues/8861\n    extra_hosts:\n      - host.docker.internal:host-gateway\n    env_file:\n      - ./youragent.env\n\n  # Blazegraph\n  blazegraph:\n    image: ghcr.io/cambridge-cares/blazegraph:1.1.0\n    container_name: \"blazegraph_test\"\n    ports:\n      - 27149:8080\n    environment:\n      # Use BLAZEGRAPH_USER and BLAZEGRAPH_PASSWORD_FILE if you would like to add authentication\n      # Otherwise, you may wish to comment them out\n      BLAZEGRAPH_USER: bg_user\n      BLAZEGRAPH_PASSWORD_FILE: /run/secrets/blazegraph_password\n    # Add a secret to set the password for BASIC authentication\n    secrets:\n      - blazegraph_password\n\n# Secrets used to set runtime passwords\nsecrets:\n  blazegraph_password:\n    file: tests/dummy_services_secrets/blazegraph_passwd.txt\n  email_auth: # You may want to add below file name to your .gitignore\n    file: tests/dummy_services_secrets/email_auth.json\n</code></pre> <p>The design of derivation agent in <code>twa</code> is continually evolving, and as the project grows, we hope to make it more accessible to developers and users.</p>"},{"location":"examples/dif/#set-up-email-notification-for-exceptions","title":"Set up email notification for exceptions","text":"<p>The <code>DerivationAgent</code> class provides the feature to send email notifications to list of recipients specified by the developer. As the agent uses yagmail package, a gmail account is required. The feature relies on OAuth2 for authorisation. A step-by-step instruction can be find here.</p>"},{"location":"examples/dif/#create-a-sync-derivations-client-side","title":"Create a-/sync derivations (client side)","text":"<p>Methods are provided in the <code>PyDerivationClient</code> to create derivation instances that are responded by agents in different timescales: synchronous (quick calculations) and asynchronous (lengthy computations).</p>"},{"location":"examples/dif/#instantiate-derivation-client","title":"Instantiate derivation client","text":"<p>The first step is to instantiate a derivation client:</p> <pre><code>from twa.data_model.iris import TWA_BASE_URL\nfrom twa.kg_operations.derivation_client import PyDerivationClient\n\n# assume the below SPARQL endpoint is available\nsparql_endpoint = 'http://localhost:9999/blazegraph/namespace/kb/sparql'\n\nderivation_client = PyDerivationClient(\n    derivation_instance_base_url=TWA_BASE_URL, # you may choose to provide your own base url\n    query_endpoint=sparql_endpoint,\n    update_endpoint=sparql_endpoint,\n    # you may also provide credentials if the above endpoint is password-protected\n    # kg_user=&lt;username&gt;,\n    # kg_password=&lt;password&gt;,\n)\n</code></pre>"},{"location":"examples/dif/#synchronous-derivations","title":"Synchronous derivations","text":"<p>Given below IRIs, two types of derivations can be marked up for synchronous agent responses.</p> <pre><code>outputs = ['https://example/kg/output_1', 'https://example/kg/output_2&gt;']\nagent_iri = 'https://example/kg/MyAgent'\ninputs = ['https://example/kg/input_1', 'https://example/kg/input_2']\n</code></pre> <ol> <li> <p>Derivation without time series     <pre><code>derivation_iri = derivation_client.createDerivation(\n    entities=outputs,\n    agentIRI=agent_iri,\n    inputs=inputs,\n)\n</code></pre></p> </li> <li> <p>Derivation with time series     <pre><code>derivation_iri = derivation_client.createDerivationWithTimeSeries(\n    entities=outputs,\n    agentIRI=agent_iri,\n    inputs=inputs,\n)\n</code></pre></p> </li> </ol> <p>Derivations can also be created for generating new information, i.e. the outputs of this derivation are to be generated (either with or without time series). When the HTTP endpoint of the agent to handle the synchronous derivation is unknown to the calling entity, one can use the below method:</p> <pre><code>from twa.data_model.iris import ONTODERIVATION_DERIVATION\nfrom twa.data_model.iris import ONTODERIVATION_DERIVATIONWITHTIMESERIES\n\n# create a derivation instance\nderivation = derivation_client.createSyncDerivationForNewInfo(\n    agentIRI=agent_iri,\n    inputsIRI=inputs,\n    derivationType=ONTODERIVATION_DERIVATION,\n    # below line can be used instead to create derivation with time series\n    # derivationType=ONTODERIVATION_DERIVATIONWITHTIMESERIES\n)\n</code></pre> <p>When calling this method, the framework will query the agent HTTP endpoint and fire an HTTP request to request for computing new information with the provided inputs.</p> <p>NONE of the <code>inputsIRI</code> should be derived information of asynchronous derivations.</p> <p>Should the developer already know the URL of the HTTP endpoint, one can provide such HTTP endpoint to the method by calling function <code>createSyncDerivationForNewInfoWithHttpUrl</code>:</p> <pre><code>derivation = derivation_client.createSyncDerivationForNewInfoWithHttpUrl(\n    agentIRI=agent_iri,\n    agentURL=agent_http_endpoint,\n    inputsIRI=inputs,\n    derivationType=ONTODERIVATION_DERIVATION,\n    # below line can be used instead to create derivation with time series\n    # derivationType=ONTODERIVATION_DERIVATIONWITHTIMESERIES\n)\n</code></pre> <p>NOTE that developer MUST make sure the provided <code>agentIRI</code> and <code>agentURL</code> matches with each other. If the developer has access to the agent object, then one can use: <code>agent.agentIRI</code> and <code>agent.syncDerivationEndpoint</code></p> <p>The returned type of the above methods is <code>twa.data_model.derivation.Derivation</code>, developer can get the IRI of the created derivation and list of IRIs of the generated outputs via:</p> <pre><code># the generated derivation IRI\nderivation_iri = derivation.getIri()\n\n# the IRIs of generated new information with a rdf:type of interest 'http://this_is_a_specific_rdfType'\noutput_iris = derivation.getBelongsToIris('http://this_is_a_specific_rdfType')\n</code></pre> <p>This initialisation thus supports creating a graph of synchronous derivations on-the-fly without creating placeholder instances in the knowledge graph when only pure inputs exist:</p> <pre><code># create a downstream derivation that takes the outputs of the derivation instance created just now as inputs\ndownstream_derivation = derivation_client.createSyncDerivationForNewInfo(\n    agentIRI=another_agent_iri,\n    inputsIRI=output_iris,\n    derivationType=ONTODERIVATION_DERIVATION\n)\n\n# again we retrieve its outputs with the interested rdf:type\n# 'http://specific_rdfType_of_downstream_derivation_outputs'\noutputs_of_downstream_derivation = downstream_derivation.getBelongsToIris(\n    'http://specific_rdfType_of_downstream_derivation_outputs'\n)\n\n# we can then combine these inputs to form yet another downstream derivation\nyet_another_downstream_derivation = derivation_client.createSyncDerivationForNewInfo(\n    agentIRI=yet_another_agent_iri,\n    inputsIRI=output_iris + outputs_of_downstream_derivation,\n    derivationType=ONTODERIVATION_DERIVATION\n)\n</code></pre>"},{"location":"examples/dif/#asynchronous-derivations","title":"Asynchronous derivations","text":"<p>Currently, asynchronous derivations only work with non time series data. To create an asynchronous derivation for new information:</p> <pre><code># assume that we are creating a downstream derivation from a normal instance and an existing derivation\ninputs_and_derivations = ['https://example/kg/input_1', 'https://example/kg/existing_derivation']\n\nderivation_iri = createAsyncDerivationForNewInfo(\n    agentIRI=agent_iri,\n    inputsAndDerivations=inputs_and_derivations\n)\n</code></pre> <p>This initialisation supports creating new derivation that depends on upstream derivations which themselves can be created for generating new information, i.e. no outputs yet:</p> <pre><code>&lt;derivation_iri&gt; OntoDerivation:isDerivedFrom &lt;https://example/kg/existing_derivation&gt;\n</code></pre> <p>Once the upstream derivation finishes generating new information, e.g. generated <code>&lt;newEntity1&gt;</code> and <code>&lt;newEntity2&gt;</code>, the derivation framework will handle the reconnection of new information to the derivation structure in the knowledge graph:</p> <pre><code>&lt;newEntity1&gt; OntoDerivation:belongsTo &lt;https://example/kg/existing_derivation&gt;\n&lt;newEntity2&gt; OntoDerivation:belongsTo &lt;https://example/kg/existing_derivation&gt;\n&lt;derivation_iri&gt; OntoDerivation:isDerivedFrom &lt;newEntity1&gt;\n&lt;derivation_iri&gt; OntoDerivation:isDerivedFrom &lt;newEntity2&gt;\n</code></pre> <p>This feature allows users to create a directed acyclic graph (DAG) of the derivation to form a workflow that is to be executed.</p>"},{"location":"examples/dif/#validate-created-derivation-dags","title":"Validate created derivation DAGs","text":"<p>Once the derivation instances are initialised using the above methods, one could use the provided method to check that the connection is valid:</p> <pre><code># returns a bool\nderivation_client.validateDerivations()\n</code></pre> <p>This method goes through all the inputs of the provided derivation, and all the subsequent inputs if the inputs are derivations. This makes sure that there are no circular dependencies, and each instance has a valid timestamp.</p>"},{"location":"examples/dif/#request-derivation-update-client-side","title":"Request derivation update (client side)","text":""},{"location":"examples/dif/#pure-synchronous-response","title":"Pure synchronous response","text":"<p>Four methods exist to request update of the derivation instances if all the derivations you want to update are synchronous derivations, i.e. instances of <code>OntoDerivation:Derivation</code> or <code>OntoDerivation:DerivationWithTimeSeries</code>:</p> <pre><code># to update a single sync derivation\nderivation_client.updatePureSyncDerivation(derivation_iri)\n\n# to update a list of sync derivations\nderivation_client.updatePureSyncDerivations(list_of_derivation_iris)\n\n# to update a list of sync derivations in parallel\nderivation_client.updatePureSyncDerivationsInParallel(list_of_derivation_iris)\n\n# to update all sync derivations in a knowledge graph\nderivation_client.updateAllSyncDerivations()\n</code></pre>"},{"location":"examples/dif/#asynchronous-operation","title":"Asynchronous operation","text":"<p>To request update of the derivation instance if the derivation you want to update is an asynchronous derivation, i.e. instance of <code>OntoDerivation:DerivationAsyn</code>.</p> <pre><code>derivation_client.updateMixedAsyncDerivation(derivation_iri)\n</code></pre>"},{"location":"examples/dif/#mixed-type-async-derivations-depend-on-sync-derivations","title":"Mixed type - async derivations depend on sync derivations","text":"<p>To update a directed acyclic graph (DAG) that consists of async derivations depending on sync derivations:</p> <pre><code>derivation_client.unifiedUpdateDerivation(derivation_iri)\n</code></pre> <p>In this mode, it will mark the derivation and all its dependencies as update <code>OntoDerivation:Requested</code> if it is determined as outdated (including sync derivations). The agent is expected to monitor the derivation that <code>OntoDerivation:isDerivedUsing</code> itself periodically and check if any requested asynchronous derivations. For those requested, the agent checks the status of its upstream derivations and will wait if any of its immediate upstream asynchronous derivations are still outdated - the agent only acts when it determined all its immediate upstream asynchronous derivations are up-to-date. It will first request update of all its upstream sync derivations (if any), and then set up job for requested. For more insights, you may refer to below for a demo.</p>"},{"location":"examples/dif/#multi-agent-system-combine-everything-above","title":"Multi-agent system - combine everything above","text":"<p>A minimal working example of a multi-agent systems combining everything above is provided in the format of dockerised integration tests. following the same context as <code>DerivationAsynExample</code>. Interested developer may refer to the README of the Java example for more context, or <code>TheWorldAvatar/JPS_BASE_LIB/python_wrapper/tests</code> for more technical details.</p> <p>To check the example in more details, one may execute below commands for each set of dockerised integration test:</p> <ul> <li> <p>Agents instantiated and run in memory, operating on a blazegraph docker container with dynamic port decided on deployment</p> <p><code>(Linux)</code> <pre><code>cd /&lt;absolute_path_to&gt;/TheWorldAvatar/JPS_BASE_LIB/python_wrapper\npytest -s tests/test_derivation_agent.py\n</code></pre></p> </li> <li> <p>All agents and blazegraph deployed within the same docker stack and they communicate via internal port address</p> <p><code>(Linux)</code> <pre><code>cd /&lt;absolute_path_to&gt;/TheWorldAvatar/JPS_BASE_LIB/python_wrapper\npytest -s tests/test_docker_integration.py\n</code></pre></p> </li> </ul> <p>Ideally, we would like to provide this set of dockerised integration test to demo how one may develop integration test for their own derivation agents. Any ideas/discussions/issues/PRs on how to make this more standardised and accessible to developers are more than welcome.</p>"},{"location":"examples/logging/","title":"Logging","text":"<p><code>agentlogging</code> is originally placed here. It is now packaged and released as part of <code>twa</code> python wrapper.</p> <p>One can import and use it as below:</p> <pre><code>from twa import agentlogging\n\ndev_logger = agentlogging.get_logger(\"dev\")\ndev_logger.debug(\"This is a DEBUG statement\")\ndev_logger.info(\"This is an INFO statement\")\n\nprod_logger = agentlogging.get_logger(\"prod\")\nprod_logger.debug(\"This is a DEBUG statement\")\nprod_logger.info(\"This is an INFO statement\")\n</code></pre> <p>For more details, see the Logging page on TWA Wiki.</p>"},{"location":"examples/ogm/","title":"Object Graph Mapper (OGM)","text":"<p><code>twa</code> package provides an implementation of Object Graph Mapper (OGM) using Pydantic to model the objects in Python memory which provides type validation, as well as rdflib to host the objects in their triple format which can then be connected to a triple store using <code>twa.PySparqlClient</code>.</p> <p>Below we provide minimal working example of how to use the OGM.</p>"},{"location":"examples/ogm/#tbox-level","title":"TBox level","text":""},{"location":"examples/ogm/#define-an-ontology-in-pydantic","title":"Define an ontology (in Pydantic)","text":"<p>To begin with, you can define the ontology that hosts all concepts and relationships as below:</p> <pre><code># Import relevant packages\nfrom __future__ import annotations\nfrom twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty\nfrom twa.data_model.iris import TWA_BASE_URL\nfrom typing import ClassVar\nfrom pydantic import Field\n\n# Your ontology needs to inherit the BaseOntology class\nclass YourOntology(BaseOntology):\n    # Below fields can be set up to provide metadata for your ontology\n    base_url: ClassVar[str] = TWA_BASE_URL\n    namespace: ClassVar[str] = 'yourontology'\n    owl_versionInfo: ClassVar[str] = '0.0.1'\n    rdfs_comment: ClassVar[str] = 'Your ontology'\n    # Since they are already defined as a ClassVar[str], one can just assign value to it\n    # i.e., simplified version:\n    # ```\n    # base_url = TWA_BASE_URL\n    # namespace = 'yourontology'\n    # owl_versionInfo = '0.0.1'\n    # rdfs_comment = 'Your ontology'\n    # ```\n</code></pre> <p>which is equivalent to the below triples in OWL:</p> <pre><code>@prefix owl: &lt;http://www.w3.org/2002/07/owl#&gt; .\n@prefix rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt; .\n@prefix xsd: &lt;http://www.w3.org/2001/XMLSchema#&gt; .\n\n&lt;https://www.theworldavatar.com/kg/yourontology&gt; a owl:Ontology ;\n    rdfs:comment \"Your ontology\" ;\n    owl:versionInfo \"0.0.1\" .\n</code></pre> <p>For simplicity, <code>&lt;https://www.theworldavatar.com/kg/yourontology/&gt;</code> (Note the <code>/</code> at the end!!!) will be replaced as prefix <code>yo</code> in the rest of this page: <pre><code>@prefix yo: &lt;https://www.theworldavatar.com/kg/yourontology/&gt; .\n</code></pre></p> <p>NOTE: if you wish to develop this in a Jupyter notebook, you might find it helpful to set the ontology to development mode using <code>YourOntology.set_dev_mode()</code>, which will allow you re-run the cell once you made changes to your classes/properties without throwing an \"class already registered\" error. Once you are happy with your ontology and wish to switch back to production mode, you may do this via <code>YourOntology.set_prod_mode()</code>.</p>"},{"location":"examples/ogm/#define-a-property-relationship","title":"Define a property (relationship)","text":"<p>To define custom object and data properties, the two base classes <code>ObjectProperty</code> and <code>DatatypeProperty</code> should be used respectively. It should be noted that the user is only required to specify the cardinality of these properties at the class defination, as their <code>rdfs:domain</code> and <code>rdfs:range</code> will be automatically handled by the class that utilises the defined properties.</p>"},{"location":"examples/ogm/#object-property","title":"Object property","text":"<p>To define a custom object property:</p> <pre><code>PointsToAnotherConcept = ObjectProperty.create_from_base(\n    class_name = 'PointsToAnotherConcept', # The name of the class that will be created and can be directly accessed in code\n    ontology = YourOntology, # The user MUST provide the ontology for which the concept `rdfs_isDefinedBy`\n    min_cardinality = 0, # 0 is the default value, indicates no cardinality restriction (this arg can be omitted)\n    max_cardinality = None, # None is the default value, indicates no cardinality restriction (this arg can be omitted)\n)\n</code></pre> <p>The above definition is equivalent to the below if one would like to follow the typical way of defining a class:</p> <pre><code>class PointsToAnotherConcept(ObjectProperty):\n    rdfs_isDefinedBy = YourOntology # `rdfs_isDefinedBy` can be directly assigned a value here\n\n    # 0 and None in the previous cell indicate no cardinality restriction\n    # They are also the default value so you can omitted them here\n    # However, if you do want to provide such value then follow the below two lines:\n    # ```\n    # owl_minQualifiedCardinality = 0\n    # owl_maxQualifiedCardinality = None\n    # ```\n</code></pre> <p>which is equivalent to the below triples in OWL:</p> <pre><code>yo:PointsToAnotherConcept a owl:ObjectProperty ;\n    rdfs:domain yo:OneConcept ;\n    rdfs:isDefinedBy &lt;https://www.theworldavatar.com/kg/yourontology&gt; ;\n    rdfs:range yo:AnotherConcept .\n</code></pre> <p>To access the IRI of the defined objective property:</p> <pre><code>PointsToAnotherConcept.predicate_iri\n</code></pre> <p>To define a property that is subproperty of another property:</p> <pre><code>AnExampleOfSubProperty = PointsToAnotherConcept.create_from_base(\n    class_name = 'AnExampleOfSubProperty',\n    ontology = YourOntology,\n    min_cardinality = 3, # if this value is provided then it overwrites the value from the calling class `PointsToAnotherConcept`\n    max_cardinality = 5, # if this value is provided then it overwrites the value from the calling class `PointsToAnotherConcept`\n)\n</code></pre> <p>Further subclassing by calling <code>AnExampleOfSubProperty.create_from_base(...)</code> is also possible.</p> <p>NOTE that the statements about <code>rdfs:domain</code> and <code>rdfs:range</code> will be automatically added when defining concept that uses this object property, e.g. assume <code>OneConcept</code> uses this object property on <code>AnotherConcept</code>, then we have triples: <code>yo:PointsToAnotherConcept rdfs:domain yo:OneConcept ; rdfs:range yo:AnotherConcept .</code></p> <p>NOTE for multiple concepts as domain of the same object property, e.g. assume both <code>OneConcept</code> and <code>SubConcept</code> are the domain, then a Blank Node of <code>owl:Class</code> will be added: <code>yo:pointsToAnotherConcept rdfs:domain [ a owl:Class ; owl:unionOf ( yo:OneConcept yo:SubConcept ) ] ;</code></p>"},{"location":"examples/ogm/#transitive-property","title":"Transitive property","text":"<p>Transitive property is a specific type of object property, it can be very useful for representing part-whole relations. To define a custom transitive property:</p> <pre><code>OneTransitiveProperty = TransitiveProperty.create_from_base('OneTransitiveProperty', YourOntology)\n# Equivalent to:\n# ```\n# class OneTransitiveProperty(TransitiveProperty):\n#     rdfs_isDefinedBy = YourOntology\n# ```\n\n# Here we also provide the class definition for the concept that makes use of `OneTransitiveProperty`\n# Please refer to later part of this documentation for more examples on how to define a class\nclass OneClassWithTransitive(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    # Note that here the range and domain of `OneTransitiveProperty` are both `OneClassWithTransitive`\n    oneTransitiveProperty: OneTransitiveProperty[OneClassWithTransitive]\n</code></pre> <p>To access the IRI of the defined transitive property:</p> <pre><code>OneClassWithTransitive.predicate_iri\n</code></pre> <p>A convenient member function is provided to retrieve all transitive objects as a <code>set</code>:</p> <pre><code># Assume we have instantiated an object `one_class_with_transitive` of class `OneClassWithTransitive`\n# As it uses transitive property `OneTransitiveProperty`, we can retrieve a set of transtive objects by:\nset_of_transitive_objects = OneTransitiveProperty.obtain_transitive_objects()\n</code></pre>"},{"location":"examples/ogm/#data-property","title":"Data property","text":"<p>To define a custom data property:</p> <pre><code>OneDatatypeProperty = DatatypeProperty.create_from_base(\n    'OneDatatypeProperty', YourOntology\n)\n\nAnotherDatatypeProperty = DatatypeProperty.create_from_base(\n    'AnotherDatatypeProperty', YourOntology, 0, 1\n    # The cardinality means maximum 1\n)\n</code></pre> <p>which is equivalent to the below triples in OWL:</p> <pre><code>yo:OneDatatypeProperty a owl:DatatypeProperty ;\n    rdfs:domain yo:OneConcept ;\n    rdfs:isDefinedBy &lt;https://www.theworldavatar.com/kg/yourontology&gt; ;\n    rdfs:range xsd:string .\n\nyo:AnotherDatatypeProperty a owl:DatatypeProperty ;\n    rdfs:domain yo:AnotherConcept ;\n    rdfs:isDefinedBy &lt;https://www.theworldavatar.com/kg/yourontology&gt; ;\n    rdfs:range xsd:integer .\n\nyo:AnotherConcept rdfs:subClassOf [\n    a owl:Restriction ;\n    owl:maxQualifiedCardinality \"1\"^^xsd:nonNegativeInteger ;\n    owl:onClass xsd:integer ;\n    owl:onProperty yo:AnotherDatatypeProperty ] .\n</code></pre> <p>To access the IRI of the defined datatype property:</p> <pre><code>OneDatatypeProperty.predicate_iri\n</code></pre> <p>NOTE that the cardinality for <code>AnotherDatatypeProperty</code> will be added as a Blank Node of <code>owl:Restriction</code> automatically to <code>AnotherConcept</code> when the class is defined.</p>"},{"location":"examples/ogm/#define-a-class-concept","title":"Define a class (concept)","text":"<p>The classes can be defined in the normal way as defining Python native classes, with the field being the object/data properties previously defined:</p> <pre><code>class OneConcept(BaseClass):\n    # Like object/data properties, `rdfs_isDefinedBy` is a compulsory field\n    rdfs_isDefinedBy = YourOntology\n    # Follow format `myDatatypeProperty: MyDatatypeProperty[str]`\n    oneDatatypeProperty: OneDatatypeProperty[str]\n    # Follow format `myObjectProperty: MyObjectProperty[MyOtherClass]`\n    pointsToAnotherConcept: PointsToAnotherConcept[AnotherConcept]\n\nclass AnotherConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    anotherDatatypeProperty: AnotherDatatypeProperty[int]\n</code></pre> <p>To access the <code>rdf:type</code> of the defined class: <pre><code>OneConcept.rdf_type\n</code></pre></p> <p>NOTE that the name of field CAN NOT be the same as the name of the corresponding Pydantic class it is referring to, i.e. <code>AnotherDatatypeProperty: AnotherDatatypeProperty</code> would be invalid.</p>"},{"location":"examples/ogm/#class-and-subclass","title":"Class and subclass","text":"<p>The subclass relationship <code>rdfs:subClassOf</code> can also be defined following the standard practice, e.g. we define a concept <code>SubConcept</code> <code>rdfs:subClassOf</code> <code>OneConcept</code>:</p> <pre><code>AdditionalDatatypeProperty = DatatypeProperty.create_from_base(\n    'AdditionalDatatypeProperty', YourOntology, 0, 1\n)\n\nclass SubConcept(OneConcept):\n    # As it inherits `OneConcept`, only additional object/data properties are required\n    additionalDatatypeProperty: AdditionalDatatypeProperty[int]\n</code></pre>"},{"location":"examples/ogm/#multiple-inheritance","title":"Multiple inheritance","text":"<p>Multiple inheritance is also possible:</p> <pre><code>YetAnotherDatatypeProperty = DatatypeProperty.create_from_base(\n    'YetAnotherDatatypeProperty', YourOntology, 0, 1\n)\n\nclass YetAnotherConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n    yetAnotherDatatypeProperty: YetAnotherDatatypeProperty[int]\n\nclass MultipleInheritanceConcept(SubConcept, YetAnotherConcept):\n    pass\n</code></pre> <p>NOTE the use of multiple inheritance is a controversial topic. It is at the developer's discretion to decide whether or not to use this feature. In any case, good engineering practice should be followed.</p>"},{"location":"examples/ogm/#custom-member-functions-and-class-methods","title":"Custom member functions and class methods","text":"<p>One of the benefits of using OGM is that it is easy to relate the data processing logic on the Python side to the data in the Knowledge Graph. To achieve this, one can define custom functions:</p> <pre><code>class YourConcept(BaseClass):\n    rdfs_isDefinedBy = YourOntology\n\n    # Member functions\n    def your_custom_function(self):\n        print('This is a custom function.')\n\n    # Class methods\n    @classmethod\n    def your_custom_classmethod(cls):\n        print(f'This is a custom classmethod of class {cls}.')\n</code></pre>"},{"location":"examples/ogm/#export-pydantic-classes-to-triples","title":"Export Pydantic classes to triples","text":"<p>Once the developer is satisfied with the class definitions in Python, there are three ways to export it to the OWL format:</p> <ul> <li> <p>Option 1: Export to a <code>rdflib.Graph</code> object <pre><code>g = YourOntology.export_to_graph()\n</code></pre></p> </li> <li> <p>Option 2: Export to a file <pre><code>YourOntology.export_to_owl('your_ontology.ttl', format='turtle')\n</code></pre></p> </li> <li> <p>Option 3: Export (upload) to a triple store <pre><code>from twa.kg_operations import PySparqlClient\nsparql_endpoint = 'http://localhost:9999/blazegraph/namespace/kb/sparql'\nsparql_client = PySparqlClient(sparql_endpoint, sparql_endpoint)\nYourOntology.export_to_triple_store(sparql_client)\n</code></pre></p> </li> </ul> <p>See Instantiation of the <code>PySparqlClient</code> for more details on how to instantiate <code>PySparqlClient</code>.</p>"},{"location":"examples/ogm/#abox-level","title":"ABox level","text":""},{"location":"examples/ogm/#instantiate-an-object-in-python","title":"Instantiate an object in Python","text":"<p>Taking the classes <code>AnotherConcept</code> and <code>OneConcept</code> as an example:</p> <pre><code>another_concept = AnotherConcept(anotherDatatypeProperty=3)\n\none_concept = OneConcept(\n    oneDatatypeProperty='this is a data property',\n    pointsToAnotherConcept=another_concept\n)\n</code></pre> <p>The IRI of the instantiated instance can be accessed via <code>one_concept.instance_iri</code>, e.g. <code>https://www.theworldavatar.com/kg/yourontology/OneConcept_6481d535-160b-43f9-811e-80924daaabe7</code></p>"},{"location":"examples/ogm/#push-new-object-to-triple-store","title":"Push new object to triple store","text":"<p>Assuming a sparql client is already instantiated, one can push the generated triples to knowledge graph:</p> <pre><code>g_to_remove, g_to_add = one_concept.push_to_kg(sparql_client, recursive_depth=-1)\n</code></pre> <p>The above call collects all triples related to the objects <code>one_concept</code> and <code>another_concept</code>. This behaviour can be controlled via the <code>recursive_depth</code> flag.</p> <p>See Instantiation of the <code>PySparqlClient</code> for more details on how to instantiate <code>PySparqlClient</code>.</p>"},{"location":"examples/ogm/#pull-from-triple-store-to-create-objects","title":"Pull from triple store to create objects","text":"<p>For instances stored in the knowledge graph, one can pull it to the Python object with its IRI and the sparql client that is connected to the correct sparql endpoint:</p> <pre><code>another_object_of_one_concept = OneConcept.pull_from_kg(\n    'https://iri-of-the-object-of-interest',\n    sparql_client,\n    recursive_depth=-1\n)\n</code></pre> <p>NOTE the pulled objects will be stored in a list.</p> <p>NOTE the developer should be aware of the <code>recursive_depth</code> that one is using to pull the triples from the knowledge graph.</p>"},{"location":"examples/ogm/#note-when-pulling-instances-with-multiple-rdftype-definitions","title":"NOTE when pulling instances with multiple <code>rdf:type</code> definitions","text":"<p>For instances defined with multiple <code>rdf:type</code>, this pulling function instantiates the Python object using the deepest subclass found in the intersection of the subclasses of the calling class and those specified by <code>rdf:type</code>. If multiple deepest subclasses coexist (e.g., when subclasses from different branches of the inheritance tree are identified), the code raises an error. To prevent this, you can pull the object directly using the desired subclass.</p> <p>For a concrete example using the class hierarchy below, assume an instance is defined with <code>rdf:type</code> of both class <code>C</code> and <code>E</code>. Pulling this instance using <code>A.pull_from_kg()</code> will result in an error because both <code>C</code> and <code>E</code> are identified as potential classes for instantiation, but they belong to different branches of the inheritance tree. A workaround is to pull the instance explicitly using either class <code>C</code> or <code>E</code>. Alternatively, if a class <code>F</code> exist as subclass of both <code>C</code> and <code>E</code>, pulling the instance with <code>A.pull_from_kg()</code> would succeed, as class <code>F</code> would be identified as the new \"deepest\" subclass.</p> <pre><code>classDiagram\n    class A\n    class B\n    class C\n    class D\n    class E\n\n    A &lt;|-- B\n    B &lt;|-- C\n    A &lt;|-- D\n    D &lt;|-- E\n</code></pre>"},{"location":"examples/ogm/#update-existing-objects-in-triple-store","title":"Update existing objects in triple store","text":"<p>To make changes to the local objects and update it in the triple store:</p> <pre><code># Examples changes:\n# Adding a new data property\none_concept.oneDatatypeProperty.add('this is a new data property')\n# Removing the object property\none_concept.pointsToAnotherConcept.remove(another_concept)\n\n# Push the changes to the triple store\none_concept.push_to_kg(sparql_client, recursive_depth=-1)\n</code></pre> <p>NOTE the range of both object/data property are stored as <code>set</code>, which can be processed using built-in set operations.</p> <p>NOTE make sure the <code>recursive_depth</code> is specified correctly that all intended changes are pushed to the knowledge graph.</p>"},{"location":"examples/ogm/#revert-local-changes","title":"Revert local changes","text":"<p>Conflicts can arise between local changes and remote updates when the knowledge graph is modified by multiple agents. This is a possible scenario given the distributed nature of our dynamic knowledge graph approach. An analogous situation is code conflicts in a Git repository when multiple people made changes to the same file. To address this, we provide a convenient function for developers to revert local changes:</p> <pre><code>one_concept.revert_local_changes()\n</code></pre>"},{"location":"examples/ogm/#notes-for-future-development","title":"Notes for future development","text":"<ul> <li>How to generate Python script given an OWL file</li> <li>Add support for many-to-many cardinality constraints?</li> <li>Mermaid codes</li> <li>Type hint for object/datatype properties</li> <li>Allocate set or single instances when accessing object/datatype properties</li> <li>Handle rdf:type when it's a class</li> </ul>"},{"location":"examples/python_java/","title":"Python-Java communications","text":""},{"location":"examples/python_java/#supply-custom-arguments-when-launching-java-gateway","title":"Supply custom arguments when launching Java gateway","text":"<p>The code below shows an example <code>twa.JPSGateway.launchGateway</code> method call with custom arguments <code>redirect_stdout</code> and <code>redirect_stderr</code> that might be useful for debugging purposes (both are optional <code>py4j.java_gateway.JavaGateway.launch_gateway</code> arguments):</p> <pre><code># The file paths are exemplary only, please change\n# according to your needs\nstdout_file_handle = open('D:\\\\stdout_file.out','w')\nsterr_file_handle = open('D:\\\\stderr_file.out','w')\n\nyourGateway.launchGateway(**{'redirect_stdout':stdout_file_handle, 'redirect_stderr':sterr_file_handle})\n</code></pre>"},{"location":"examples/python_java/#jvm-module-views","title":"JVM module views","text":"<p><code>Py4j</code> allows importing Java packages so that you do not have to type the fully qualified names of the classes you want to access. However, any such import statement is global in Python, e.g., the <code>JVM</code> instance can be shared across multiple Python modules. Therefore, the recommended way is to use one Java Virtual Machine View (JVMView) per Python module (file). </p> <p>Taking the <code>JpsBaseLib</code> as an example, follow the below example to create a module view (see py4j documentation for further details on module views):</p> <p>Note that it is recommended to have ONLY ONE gateway object in your Python application per java resource you wish to access. As the <code>jpsBaseLibGW</code> is already instantiated and started in <code>twa.kg_operations.gateway</code>, one can import it to any other module that requires it.</p> <pre><code># Import gateway object of JpsBaseLib\nfrom twa.kg_operations.gateway import jpsBaseLibGW\n# Create the module view\njpsBaseLib_view = jpsBaseLibGW.createModuleView()\n</code></pre> <p>For any other given resources, the same principle can be applied: <pre><code>moduleViewInstance = resGateway.createModuleView()\n</code></pre> where the <code>resGateway</code> is the gateway of a resource we wish to create the module view for.</p> <p>It is recommended to create the module view for each Python module in your application that requires access to the java resource, followed by any desired import statements (see Accessing Java classes and methods in Python). The name of the module view is arbitrary, though it is recommended to name it after your parent resource to avoid confusion.</p>"},{"location":"examples/python_java/#accessing-java-classes-and-methods-in-python","title":"Accessing Java classes and methods in Python","text":"<p>Once your resource gateway is launched you can access any public classes and methods. Here is an example on how to access the <code>RemoteStoreClient</code> class:</p> <p>NOTE that this is NOT RECOMMENDED. For the recommended method please see below.</p> <pre><code>RemoteStoreClient = jpsBaseLibGW.gateway.jvm.uk.ac.cam.cares.jps.base.query.RemoteStoreClient\n</code></pre> <p>As can be seen, the gateway's JVM class serves as an entry point to any java classes and objects you wish to access. Simply provide the fully qualified name of the resource to access it. The <code>uk.ac.cam.cares.jps.base.query.StoreRouter</code> path is for example purposes only. Please note that though accessing objects via their fully qualified names is possible, it is NOT RECOMMENDED. A much simpler way exists, through the java import statements explained in the JVM module views, i.e. once can create the module view and use it to import the desired java classes using the <code>importPackages</code> method, e.g:</p> <p>NOTE that any such import will be global, i.e. it will be carried everywhere the gateway object is imported.</p> <pre><code># Import classes into the module view\njpsBaseLibGW.importPackages(jpsBaseLib_view, \"uk.ac.cam.cares.jps.base.query.*\")\n\n# Once classes are imported, they can be accesses as follows\nRemoteStoreClient = jpsBaseLib_view.RemoteStoreClient\n</code></pre> <p>It is also important to understand the difference in accessing the java static and non-static methods. The former can be done without the object instantiation, e.g.</p> <pre><code># jpsBaseLibGW.gateway.jvm.uk.ac.cam.cares.jps.base.query.StoreRouter\n# Same as:\nStoreRouter = jpsBaseLib_view.StoreRouter\n# static method `getStoreClient` can be called without the `StoreRouter` instantiation\nStoreRouter.getStoreClient('http://kb/ontokin', True, False)\n</code></pre> <p>The non-static methods can only be accessed once the object is instantiated, e.g</p> <pre><code># Create a FileUtil instance to access its non static getDirectoryFiles method\nFileUtil = jpsBaseLib_view.FileUtil()\n# Call the non-static getDirectoryFiles method\noutput = FileUtil.getDirectoryFiles(method_arguments)\n</code></pre>"},{"location":"examples/python_java/#python-java-objects-translation","title":"Python-Java objects translation","text":"<p>It is important to understand that calling the Java methods from Python requires a bit of attention to the type of arguments on the Java side. The simplest case is when the Java method arguments are of any primitive type (e.g. int, float, String, etc..). Then on the Python side, it is enough to pass Python primitives (e.g 5 - int, 3.4 - float, 'a_string', etc..) without even declaring their types. Primitives are automatically converted between Python and Java. Another case is when the Java method arguments are of any collections type (e.g., Array, java.util.List, java.util.Set, etc..). If the <code>py4j.java_gateway.JavaGateway</code> option <code>auto_convert</code> is set to True (which is the case by default in <code>twa.JPSGateway</code>), then the Python - Java collections objects translation happens automatically. Please see the py4j documentation for a detailed explanation of what is converted into what. Here are some code examples: <pre><code># Example of calling a Java aMethod1 with an int argument\nmoduleViewInstance.aMethod1(5)\n# Example of calling a Java aMethod2 with a float argument\nmoduleViewInstance.aMethod2(3.4)\n# Example of calling a Java aMethod3 with a string argument\nmoduleViewInstance.aMethod3('a_string')\n# Example of calling a Java aMethod4 with a list of strings argument\n# This only works because the auto_convert option is enabled by default in twa\nmoduleViewInstance.aMethod4(['a_string'])\n</code></pre></p> <p>However, there could be cases where a Java object of a specific type needs to be created for the method call. As an example, the <code>FileUtil</code> class in the <code>JpsBaseLib</code> resource has a method called <code>getDirectoryFiles</code>. The method simply returns a list of files in a directory that matches the provided file extensions. Here is its Java interface: <pre><code>public List&lt;File&gt; getDirectoryFiles(File folder, List&lt;String&gt; fileExtensions)\n</code></pre></p> <p>As can be seen, the first argument is of type <code>File</code>, and the second is of type <code>List&lt;String&gt;</code>. Additionally, the method is not static so the <code>FileUtil</code> object needs to be instantiated first to be able to access this method. This requires creating a Java <code>File</code> object on the Python side so that the method can be called with the correct arguments. Now it is important to understand that the launched resource gateway allows you to not only access the classes and methods in the resources we packaged, but also any default Java classes and methods. This can be done in two ways: either via the <code>jpsBaseLibGW.gateway.jvm</code> field (not recommended) or via the created resource module view instance <code>jpsBaseLib_view</code> (recommended). Here is an example:</p> <pre><code># Import gateway object of JpsBaseLib\nfrom twa.kg_operations.gateway import jpsBaseLibGW\n# Create the module view\njpsBaseLib_view = jpsBaseLibGW.createModuleView()\n# Import required Java packages into the created JVM view\njpsBaseLibGW.importPackages(jpsBaseLibGW_view,'uk.ac.cam.cares.jps.base.util.*')\n\n# Create a FileUtil instance to access its non-static methods\n# Compare it with the StoreRouter example, where there was no need to add\n# () brackets to the router, so we were only retrieving the StoreRouter class\nFileUtil = jpsBaseLibGW_view.FileUtil()\n\n# Create the required `File folder` argument to be passed to the `getDirectoryFiles` method\n\n# Option 1 - NOT RECOMMENDED\n# not recommended use of a gateway.jvm class to access the default java classes and methods\n# here we are instantiating the java.io.File class\njavaFolder = jpsBaseLibGW.gateway.jvm.java.io.File('D:\\\\my_dir')\n\n# Option 2 - RECOMMENDED\n# recommended use of JVM view to access default java classes and methods\njavaFolder = jpsBaseLibGW_view.java.io.File('D:\\\\my_dir')\n\n# Call the getDirectoryFiles\n# Note that the `List&lt;String&gt; fileExtensions` argument can be passed\n# as a simple Python list of strings given the enabled auto conversion\nfileListArray = FileUtil.getDirectoryFiles(javaFolder, [\".txt\"])\n\n# The returned object is of Java List&lt;File&gt; type. So, one needs to know a bit\n# of Java to extract information. Here is an example:\nfiles_list = []\nfor i in range(fileListArray.size()):\n    files_list.append(fileListArray.get(i).toString())\n\n# An extra example\n# If the Java method requires as an input a list of Java objects,\n# where the objects are not primitives e.g a list of file objects\n# that is returned as an output from the getDirectoryFiles call.\n# Then one can simply create such list as follows:\n\njavaFileObj = jpsBaseLibGW_view.java.io.File(path_to_a_folder)\n# This creates a Python List which stores a javaFileObj inside\nPythonList = [javaFileObj]\n\n# or\n\n# This creates a javaArray which stores the javaFileObj inside\n# this example, however, is not needed given the auto conversion\n# so, one can simply pass the PythonList created above to the method\njavaArray = jpsBaseLibGW_view.java.util.ArrayList()\njavaArray.append(javaFileObj)\n</code></pre>"},{"location":"examples/sparql/","title":"Perform knowledge graph operations","text":""},{"location":"examples/sparql/#spin-up-docker-containers","title":"Spin up docker containers","text":"<p>Spinning up docker containers requires knowledge about docker, please refer to Setting up Docker and Docker SDK for Python if you do not have relevant experience.</p> <p>Please refer to Blazegraph and Fileserver for technical details, brief example of how to use them are provided below.</p>"},{"location":"examples/sparql/#blazegraph","title":"Blazegraph","text":"<p>Among many available triple stores, Blazegraph is commonly used within <code>TheWorldAvatar</code> and we have provided a convenient docker image <code>ghcr.io/cambridge-cares/blazegraph:1.1.0</code> for users to deploy.</p> <p>To spin up a Blazegraph docker container locally using Python:</p> <pre><code>import docker\n# Connect to Docker using the default socket or the configuration in your environment:\nclient = docker.from_env()\n\n# Run Blazegraph container\n# It returns a Container object that we will need later for stopping it\nblazegraph = client.containers.run(\n    'ghcr.io/cambridge-cares/blazegraph:1.1.0',\n    ports={'8080/tcp': 9999}, # this binds the internal port 8080/tcp to the external port 9999\n    detach=True # this runs the container in the background\n)\n</code></pre> <p>The Blazegraph should now be accessible at the below endpoint for both query and update:</p> <p>SPARQL query and update endpoint might differ for other triple stores, e.g. RDF4J.</p> <pre><code># This is the default namespace `kb`\n# Note the port we are accessing is 9999 as specified when spinning it up\nsparql_endpoint = 'http://localhost:9999/blazegraph/namespace/kb/sparql'\n</code></pre> <p>To stop the blazegraph docker container after all operations:</p> <pre><code>blazegraph.stop()\n</code></pre>"},{"location":"examples/sparql/#fileserver","title":"Fileserver","text":"<p>Similarly, we have provided a convenient docker image of fileserver <code>ghcr.io/cambridge-cares/fileserver:1.1.0</code> for users to deploy.</p> <p>To spin up a Fileserver docker container locally using Python:</p> <pre><code>import docker\n# Connect to Docker using the default socket or the configuration in your environment:\nclient = docker.from_env()\n\n# Run Fileserver container\n# It returns a Container object that we will need later for stopping it\nfileserver = client.containers.run(\n    'ghcr.io/cambridge-cares/fileserver:1.1.0',\n    ports={'8080/tcp': 9998}, # this binds the internal port 8080/tcp to the external port 9998\n    detach=True # this runs the container in the background\n)\n</code></pre> <p>The Fileserver should now be accessible at the below endpoint for upload and download:</p> <pre><code># Note the port we are accessing is 9998 as specified when spinning it up\nfs_url = 'http://localhost:9998/FileServer/'\n# The fileserver image comes with a default username and password\nfs_user = 'fs_user'\nfs_password = 'fs_pass'\n</code></pre> <p>For how to interact with Fileserver, please see examples in the section Interact with fileserver below.</p> <p>To stop the fileserver docker container after all operations:</p> <pre><code>fileserver.stop()\n</code></pre>"},{"location":"examples/sparql/#use-docker-composeyml","title":"Use <code>docker-compose.yml</code>","text":"<p>If you wish to use <code>docker-compose.yml</code> instead, you may create the below yml file and compose it up:</p> <p>NOTE please remember to create the file <code>./secrets/blazegraph_password.txt</code> and <code>./secrets/fileserver_password.txt</code> with your desired password populated.</p> <p>NOTE the default username of blazegraph and fileserver are <code>bg_user</code> and <code>fs_user</code> respectively.</p> <pre><code>version: \"3.8\"\n\nservices:\n  # Blazegraph\n  blazegraph:\n    image: ghcr.io/cambridge-cares/blazegraph:1.1.0\n    container_name: \"blazegraph\"\n    ports:\n      - 9999:8080\n    environment:\n      BLAZEGRAPH_PASSWORD_FILE: /run/secrets/blazegraph_password\n    # Add a secret to set the password for BASIC authentication\n    secrets:\n      - blazegraph_password\n\n  # File server\n  fileserver:\n    image: ghcr.io/cambridge-cares/fileserver:1.1.0\n    container_name: \"fileserver\"\n    ports:\n      - 9998:8080\n    # Add secret to set BASIC authentication password\n    secrets:\n      - file_server_password\n\n# Secrets used to set runtime passwords\nsecrets:\n  blazegraph_password:\n    file: ./secrets/blazegraph_password.txt\n  file_server_password:\n    file: ./secrets/fileserver_password.txt\n</code></pre> <p>For more details on how to use <code>docker compose</code>, plese refer to Docker Compose overview.</p>"},{"location":"examples/sparql/#instantiation-of-the-pysparqlclient","title":"Instantiation of the <code>PySparqlClient</code>","text":"<p>To initialise a SPARQL client with the above <code>sparql_endpoint</code> and <code>fs_url</code> with the basic authentication:</p> <p>NOTE remember to populate the passwords <code>&lt;your_blazegraph_password&gt;</code> and <code>&lt;your_fileserver_password&gt;</code> based on those provided in your secret files.</p> <pre><code>from twa.kg_operations import PySparqlClient\n\n# sparql_endpoint = 'http://localhost:9999/blazegraph/namespace/kb/sparql'\n# fs_url = 'http://localhost:9998/FileServer/'\nsparql_client = PySparqlClient(\n    query_endpoint = sparql_endpoint,\n    update_endpoint = sparql_endpoint,\n    kg_user = 'bg_user',\n    kg_password = '&lt;your_blazegraph_password&gt;',\n    fs_url = fs_url,\n    fs_user = 'fs_user',\n    fs_pwd = '&lt;your_fileserver_password&gt;'\n)\n</code></pre> <p>We can swap <code>sparql_endpoint</code> with URL of any other SPARQL endpoint what one wish to query/update.</p>"},{"location":"examples/sparql/#sparql-query-and-update","title":"SPARQL query and update","text":"<p>There are a few convenient functions provided in <code>PySparqlClient</code> that we can use, e.g. to get the total amount of triples in the SPARQL endpoint:</p> <pre><code>num_of_triples = sparql_client.get_amount_of_triples()\n</code></pre> <p>To perform custom update and query: <pre><code># Update the triple store by inserting data\nsparql_client.perform_update(\n    'INSERT DATA {&lt;https://s&gt; &lt;https://p&gt; &lt;https://o&gt;.}'\n)\n\n# Query the first 10 triples in the triple store\ntriples = sparql_client.perform_query(\n    'SELECT * WHERE {?s ?p ?o} LIMIT 10'\n)\n</code></pre></p> <p>For tutorials of SPARQL operations, please refer to the official W3C documentation. Some useful tips and tricks can be found at SPARQL tips and tricks.</p>"},{"location":"examples/sparql/#use-rdflibgraph-object","title":"Use <code>rdflib.Graph</code> object","text":"<p>Python package <code>rdflib</code> is a convenient tool to work with RDF data. It has <code>rdflib.Graph</code> object which can be used as a knowledge graph in memory to temporarily host data before uploading it to a triple store. It is more <code>pythonic</code> compared to writing out the triples manually when constructing the SPARQL insert clause.</p> <p>To add triples to <code>rdflib.Graph</code> object and upload it to a triple store: <pre><code>from rdflib import Graph, URIRef, Literal\nfrom rdflib.namespace import FOAF, RDF\n\n# Instantiate a rdflib.Graph object\ng = Graph()\n\n# Create dummy data\nbob = URIRef(\"http://example.org/people/Bob\")\nname = Literal(\"Bob\")\nage = Literal(24)\n\n# Add data to rdflib.Graph object\ng.add((bob, RDF.type, FOAF.Person))\ng.add((bob, FOAF.name, name))\ng.add((bob, FOAF.age, age))\n\n# Upload the triples to triple store\nsparql_client.upload_graph(g)\n</code></pre></p> <p>For more tutorials on how to use <code>rdflib</code>, please refer to rdflib 7.0.0.</p>"},{"location":"examples/sparql/#upload-tbox-from-a-given-url-to-a-triple-store","title":"Upload TBox from a given URL to a triple store","text":"<p>In some use cases, in addition to data in ABox, we may want to upload the TBox to the same triple store to perform reasoning. We can again make use of <code>rdflib.Graph</code>:</p> <pre><code># Here we take OntoDoE as an example\ntbox_url = 'https://raw.githubusercontent.com/cambridge-cares/TheWorldAvatar/main/JPS_Ontology/ontology/ontodoe/OntoDoE.owl'\n\n# Parse the TBox to rdflib.Graph object\ntbox_g = Graph()\ntbox_g.parse(tbox_url, format='xml')\n\n# Upload it to triple store\nsparql_client.upload_graph(tbox_g)\n</code></pre>"},{"location":"examples/sparql/#interact-with-fileserver","title":"Interact with fileserver","text":"<p>For use cases involving processing raw files, e.g. reports from HPLC jobs, one can use the below to upload/download files to/from the fileserver:</p> <p>Authentication is required to interact with fileserver docker container, the default username is <code>fs_user</code> and the default password is <code>fs_pass</code>.</p> <pre><code># Upload local file to remote fileserver\nlocal_file_path = '&lt;local_file_path&gt;'\nremote_file_path, timestamp_upload = sparql_client.upload_file(local_file_path)\n\n# Download remote file to local machine with user-specified file path\ndownloaded_file_path = '&lt;downloaded_file_path&gt;'\nsparql_client.download_file(remote_file_path, downloaded_file_path)\n</code></pre> <p>NOTE this function does NOT instantiate relevant triples of the uploaded files in the triple store. A feature request exist for this which will be addressed in the next release. Please see here for a preliminary example attempted in another project.</p> <p>For all available operations over Fileserver, please visit its technical details.</p>"},{"location":"examples/sparql/#create-custom-sparql-client","title":"Create custom sparql client","text":"<p>Depends on use cases, users may want to define custom SPARQL queries/updates that can be re-used across different Python modules. One way to do this could be inheriting the <code>PySparqlClient</code> class:</p> <pre><code># Define custom sparql client class\nclass OntoKinSparqlClient(PySparqlClient):\n    def get_reaction_mechanisms(self, limit: int = 10):\n        query = f\"\"\"\n            PREFIX ontokin: &lt;http://www.theworldavatar.com/ontology/ontokin/OntoKin.owl#&gt;\n            PREFIX rdf: &lt;http://www.w3.org/1999/02/22-rdf-syntax-ns#&gt;   SELECT ?mechanismIRI\n            WHERE   {{ ?mechanismIRI rdf:type ontokin:ReactionMechanism . }} LIMIT {limit}\n        \"\"\"\n        response = self.perform_query(query)\n        return [list(res.values())[0] for res in response]\n\n\n# Initialise custom sparql client in the same way as PySparqlClient\nontokin_sparql_client = OntoKinSparqlClient(sparql_endpoint, sparql_endpoint)\n\n# Perform custom queries\nontokin_sparql_client.get_reaction_mechanisms()\n</code></pre>"}]}