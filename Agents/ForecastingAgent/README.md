# Forecasting Agent

This `Forecasting Agent` can be used to predict instantiated time series from The World Avatar (TWA), and instantiate the forecasts back into the knowledge graph (KG) using the [OntoTimeSeries] ontology. Reading and writing time series from/into the KG relies on the [TimeSeriesClient].

As of version `2.0.0` the agent is implemented using the [Derived Information Framework]'s (DIF) `DerivationWithTimeSeries` concept to ensure proper data provenance. The required input instances to derive a forecast are described in the [required derivation markup](#13-required-derivation-markup) section below. The agent is designed to be deployed as a Docker container and can be deployed either as standalone version or as part of a larger Docker stack.

The Python library [Darts] is used to create the forecasts (and similarly to define, train, and store forecasting models). It contains a variety of models, from classics such as ARIMA over [Facebook Prophet] to deep neural networks and transformers.


&nbsp;
# 1. Setup

This section specifies the minimum requirements to build and deploy the Docker image. 

## 1.1 Agent Settings

The dockerised agent can be deployed as "standalone" version (i.e., outside a larger Docker stack) or deployed to an (existing) stack. Several key environment variables need to be set in the
- [docker compose file] for "standalone" deployment
- [stack manager input config file] for deployment using the [Stack manager]

```bash
ROUNDING                      # Number of wanted decimal places (int) of forecast values (optional)

#--- Deployment specific parameters ---#
# Required for Stack deployment (can be left blank for "standalone" deployment)
STACK_NAME                    # Will be set automatically when deployed via stack-manager
NAMESPACE                     # Blazegraph namespace (within Stack) to monitor
DATABASE                      # PostGIS/PostgreSQL database name (default: `postgres`)
# Required for "standalone" deployment (can be left blank for Stack deployment)
STACK_NAME                    # to be left blank for "standalone" deployment
DB_URL                        # PostGIS/PostgreSQL URL
DB_USER                       # PostGIS/PostgreSQL username
DB_PASSWORD                   # PostGIS/PostgreSQL password

#--- Derivation Agent parameters ---#
SPARQL_QUERY_ENDPOINT         # SPARQL endpoint to monitor/update
SPARQL_UPDATE_ENDPOINT        # SPARQL endpoint to monitor/update
ONTOAGENT_SERVICE_IRI         # IRI of OntoAgent service
ONTOAGENT_OPERATION_HTTP_URL  # Port needs to match port specified in `docker-compose.yml`
DERIVATION_INSTANCE_BASE_URL  # Base IRI of all instanced generated by agent
DERIVATION_PERIODIC_TIMESCALE # Interval in which to check for updated KG information (in s)
                              # (irrelevant as Forecasting Agent uses synchronous derivations only)
REGISTER_AGENT                # Boolean flag whether to register agent in KG (`true` required to detect derivations)
# Required inputs for DerivationAgent to start, although not relevant for ForecastingAgent (i.e., shall be left blank)
KG_USERNAME
KG_PASSWORD
FILE_SERVER_ENDPOINT
FILE_SERVER_USERNAME
FILE_SERVER_PASSWORD
```

The `STACK_NAME` variable is used to identify the deployment mode of the agent: In case the `STACK_NAME` is left blank, Postgres and Blazegraph endpoint settings will be taken from the `docker-compose file` values. Otherwise they will be retrieved using the StackClients based on the provided `NAMESPACE` and `DATABASE` variables.

Please note: 
- The `DB_URL` is optional as the agent will first try to retrieve the database endpoint instantiated for the time series IRI to forecast from the KG (and only use the specified environment variable as fallback)
- When deployed via the Stack manager, the `STACK_NAME` environment variable is set automatically and can be omitted in the config file
- `SPARQL_QUERY_ENDPOINT` and `SPARQL_UPDATE_ENDPOINT` are both required inputs even for stack deployment (due to default derivation agent config); however, as the actual values for initialising the Forecasting Agent are retrieved via the Stack Clients, they can be left blank.

## 1.2 Miscellaneous

**Only relevant** if you intend to build (and publish) the Docker image:

- Ensure access to CMCL Docker registry: 
    The required `stack-clients-*.jar` resource to be added to [py4jps] during building the Docker image is retrieved from the Stack-Clients docker image published on `docker.cmclinnovations.com`. Hence, access to the CMCL Docker registry is required from the machine building the agent image. For more information regarding the registry, see the [CMCL Docker registry wiki page].

- Ensure access to Github container registry:
    A `publish_docker_image.sh` convenience script is provided to build and publish the agent image to the [Github container registry]. To publish a new image, your github user name and [personal access token] (which must have a `scope` that [allows you to publish and install packages]) needs to be provided. 

If you intend to use a forecasting model pre-trained with [Darts]: Please be aware of potential issues when loading the model, in case of version clashes between the current environment and the one used for training.

## 1.3 Required Derivation Markup

Before any forecast can be created (and instantiated), all required inputs need to be properly instantiated. This includes:
- 1 `om:Quantity` or `owl:Thing`: the instance associated with the time series to be forecasted. This instance must pertain to a type that is either a direct or nested subclass of `om:Quantity` (priority 1) or `owl:Thing` (priority 2). Although most instances to be forecasted will likely be of (sub-)class `om:Quantity`, the support for the more general `owl:Thing` ensures that also concepts from other ontologies can be forecasted.
- 1 `ts:ForecastingModel`: the forecasting model to be used (i.e., Prophet, pre-trained transformer, ...)
- 1 `ts:Frequency`: the frequency of the forecast to be created (i.e., spacing of time steps)
- 1 `time:Interval`: the interval to forecast (i.e., defining start and end time of the forecast to be created, both bounds inclusive)
- 1 `time:Duration`: the historical data length to use (i.e., duration prior to start time to use for model fitting and/or scaling of data for pre-trained models)


The following snippet provides an overview of the expected instantiation structure of required forecast derivation inputs (further examples can be found in the integration tests): 

```xml
###   Required inputs   ###
<IRI_to_forecast> rdf:type owl:Thing ; 
                  ts:hasTimeSeries <IRI_of_time_series> . 
<IRI_of_time_series> rdf:type ts:TimeSeries ; 
                     ts:hasRDB <Postgres_URL> . 
<IRI_of_forecasting_model> rdf:type ts:ForecastingModel ; 
                           rdfs:label <Model_name> . 
<IRI_of_interval_to_forecast> rdf:type time:Interval ; 
                              time:hasBeginning <IRI_of_start_time_instant> ; 
                              time:hasEnd <IRI_of_end_time_instant> .
<IRI_of_forecast_frequency> rdf:type ts:Frequency .
<IRI_of_historical_data_length> rdf:type time:Duration .

# All time Instants needs to be represented as follows
<IRI_of_time_instant> rdf:type time:Instant ; 
                      time:inTimePosition <IRI_of_time_position> .
<IRI_of_time_position> rdf:type time:TimePosition ; 
                       time:numericPosition <xsd:decimal> ;
                       time:hasTRS <http://dbpedia.org/resource/Unix_time> .

# Both Frequency and Duration need to be represented as follows
<IRI_of_Duration> time:numericDuration <xsd:decimal> ;
                  ts:unitType <time:unitHour> .
# Alternative unit concepts: time:unitDay, time:unitMinute, time:unitSecond


###   Optional inputs   ###
<IRI_to_forecast> om:hasUnit <IRI_of_OM_unit> . 
<IRI_of_forecasting_model> ts:scaleData <xsd:boolean> ;
                           ts:hasModelURL <model_path_link> ;
                           ts:hasCheckpointURL <model_chkpt_link> ;
                           ts:hasCovariate <IRI_of_covariate> . 
<IRI_of_covariate> rdf:type owl:Thing ; 
                   ts:hasTimeSeries <IRI_of_time_series> . 
<IRI_of_forecast_frequency> ts:resampleData <xsd:boolean> .
```

To use the default forecasting model (i.e., [Prophet] without covariates), the following triples are required:
```xml
<IRI_of_forecasting_model> rdf:type ts:ForecastingModel ; 
                           rdfs:label "Prophet" ;
                           ts:scaleData "False"^^xsd:boolean .
```
Covariates can be added to the model (i.e., [Prophet] with 2 covariates) by adding a triple for each covariate:
```xml
<IRI_of_forecasting_model> rdf:type ts:ForecastingModel ; 
                           rdfs:label "Prophet" ;
                           ts:scaleData "False"^^xsd:boolean ;
                           ts:hasCovariate <IRI_of_covariate1> ; 
                           ts:hasCovariate <IRI_of_covariate2> .
```

Used namespaces:
```xml
om    : http://www.ontology-of-units-of-measure.org/resource/om-2/
owl   : http://www.w3.org/2002/07/owl#
rdf   : http://www.w3.org/1999/02/22-rdf-syntax-ns#
rdfs  : http://www.w3.org/2000/01/rdf-schema#
xsd   : http://www.w3.org/2001/XMLSchema#
time  : http://www.w3.org/2006/time#
ts    : https://www.theworldavatar.com/kg/ontotimeseries/
deriv : https://www.theworldavatar.com/kg/ontoderivation/
```

&nbsp;
# 2. Agent Operation

The agent is implemented as [derivation agent] using `DerivationWithTimeSeries`. Please note: 1) derivations with time series are currently restricted to synchronous derivations, i.e., derivations which get computed immediately upon request and 2) derivations with time series do not return any specific output triples, as all updates to the time series are expected to be conducted within the agent logic. Initial derivation output triples will only be generated when creating new derivation using `createSyncDerivationForNewInfo`.

**NOTE**: To align most closely with the intended use of the [Derived Information Framework], newly created forecasts automatically overwrite previously instantiated ones (i.e., overwrite entire time series table and update input/output intervals in KG). This behaviour can be changed by setting the optional environment variable `OVERWRITE_FORECAST=false`. In that case a new forecast will be created each time and the outdated forecast instance will be disconnected from the derivation, but remains to exists in the KG. **This setting must be used with caution and is generally not recommended!**

The following code snippet provides an overview of how to create new and update existing forecast derivations:
```python
# Create derivation client
from pyderivationagent.data_model.iris import ONTODERIVATION_DERIVATIONWITHTIMESERIES
from pyderivationagent.kg_operations import PyDerivationClient
deriv_client = PyDerivationClient(derivation_instance_base_url, query_endpoint, update_endpoint)

# Create new forecast derivation
agent_iri = <ONTOAGENT_SERVICE_IRI of target Forecasting Agent instance>
derivation_input_set = [
    <IRI of om:Quantity or owl:Thing instance>, 
    <IRI of ts:ForecastingModel instance>, 
    <IRI of ts:Frequency instance>, 
    <IRI of time:Interval instance>, 
    <IRI of time:Duration instance>
]
derivation_type = ONTODERIVATION_DERIVATIONWITHTIMESERIES
# NOTE: It is recommended to import the derivation type from pyderivation agent directly;
#       however, string reference of the full IRI works as well
#derivation_type = "https://www.theworldavatar.com/kg/ontoderivation/DerivationWithTimeSeries"

# Markup derivation inputs and immediately compute and instantiate forecast
derivation = deriv_client.createSyncDerivationForNewInfo(agent_iri, derivation_input_set, derivation_type)
derivation_iri = derivation.getIri()

# Update existing forecast derivation
deriv_client.unifiedUpdateDerivation(derivation_iri)
```


## 2.1 Forecasting Logic

Upon invocation, the agent first verifies the suitability of received inputs to derive a forecast. If so, the agent queries all relevant inputs from the KG and creates an overarching configuration dictionary `cfg` describing the forecast to create. The `fc_model` node of this dictionary describes the target forecasting model: If the `name` entry equals `prophet` (irrespective of capitalisation), the default [Prophet] model will be used for forecasting. Otherwise, the agent will try to load a custom pre-trained model as specified in the [model mapping] file (for details see [usage of custom forecast models](#22-usage-of-custom-forecasting-models) below).

After creating the forecast configuration, the agent loads the time series data (including covariates if specified) using the [TimeSeriesClient]. Afterwards, it loads the pre-trained model or creates a new Prophet model (and fits it to the retireved time series) to predict the data. Subsequently, the forecast is created for the specified `time:Interval` (with both bounds being inclusive). If the forecasting model requires scaled data, both the time series and covariates (if applicable) are scaled based on their historical values during `time:Duration` prior to the forecast start date. Subsequently, the forecasted values are transformed back to their original scale.

Lastly, the forecasted time series is instantiated/updated in the KG: For that purpose a new `Forecast IRI` is created and attached to the `om:Quantity` or `owl:Thing` instance which has been forecasted. Further metadata, e.g., which data and models are used, are included as well using the [OntoTimeSeries] and [OntoDerivation] ontology.

The following UML diagram provides an overview of how the agent works:
<p align="center">
    <img src="https://lucid.app/publicSegments/view/721f9fea-c153-45bb-8478-0178a457f55e/image.png" alt="drawing" width="500"/>
</p>


## 2.2 Usage of Custom Forecasting Models

To use pre-trained/custom models, both a model loading and covariate loading function need to be specified in the [model mapping] file, and referenced in the `FC_MODELS` dictionary. Specify any custom loading functions following the example of the `tft_pirmasens_heat_demand` model configuration. [Building the agent](#31-building-the-agent) again after adding custom models is not necessary. However, for the agent to recognize and use these added models, the content of fcmodels must be available locally. This ensures it can be mapped correctly according to the bind mount paths, regardless of whether you're deploying the agent locally or using a pulled Docker image.


## 2.3 Forecast Error Evaluation

The agent also provides an HTTP endpoint to assess multiple error metrics of created forecasts (i.e., errors between any two time series). It is triggered by receiving an HTTP `POST` request with a JSON body. An example request is provided in [HTTP forecast error request]: 

```
{ "query": {
      "tsIRI_target": <IRI of time series 1>,
      "tsIRI_fc" : <IRI of time series 2>
    }
}
```

&nbsp;
# 3. Using the Agent

## 3.1 Building the Agent

To build and publish the agent Docker image (e.g., after changing the agent) please use the following commands. Please note that both commands are bundled in the  `publish_docker_image.sh` convenience script.

```bash
# Building the (production) image
docker compose -f docker-compose.yml build
# Publish the Docker image to the Github container registry
docker image push ghcr.io/cambridge-cares/<image tag>:<version>
```

Time out issues have been observed when building the image. If this happens, please try pulling the required stack-clients image first by `docker pull docker.cmclinnovations.com/stack-client:1.6.2`.

## 3.2 Deploying the Agent

It is recommended to pull the published Docker image from [Github container registry] for sole deployment (i.e., in case no modifications to the agent are needed):

```bash
# Pull published (production) image
docker pull ghcr.io/cambridge-cares/forecasting-agent:2.1.1
```

###  **Standalone Deployment**

Deploy the dockerised agent by running the following command from the same location where this README is located (ideally, use a bash terminal to avoid potential issues with inconsistent path separators). 

```bash
# Deploy the Docker image locally
docker compose -f docker-compose.yml up
```

To verify the correct startup of the agent, open the URL address the agent is running on, e.g., `http://localhost:5001/` in your browser. 


### **Stack Deployment**

If you want to spin up this agent as part of a stack, do the following:
1) Build OR pull the (production) image using the commands provided above (do not spin up the image)
2) Copy the `forecasting-agent.json` file from the [stack-manager-input-config] folder into the `inputs/config/services` folder of the stack manager
3) Start the stack manager as usual (i.e. `bash ./stack.sh start <STACK_NAME>` from the stack-manager repo). This should start the container. Please use a bash terminal to avoid potential issues with inconsistent path separators.
4) The agent shall become available at `http://<HOST>:<PORT>/forecastingAgent/`


## 3.3 Notes on Debugging

To debug the agent within the stack, follow these steps (a similar appraoch should work for the standalone version)

1) Overwrite command specified in Dockerfile by providing `tail -f /dev/null` `Command` in stack-manager config file (this keeps the container alive indefinitely while doing nothing). An amended `forecasting-agent_debug` config is provided in the [stack-manager-input-config] folder.
2) Start stack-manager as usual
3) Right click on running agent container -> select "Attach Visual Studio Code"
4) Install required VSCode extensions inside the container
5) Start local debugging session inside container by running `entry_point.py` in debug mode; if HTTP requests from outside do not reach the container, send requests locally from inside the container as workaround


&nbsp;
# 4. Dockerised Agent Tests

Both dockerised unit and integration tests are provided. Tests check for expected behaviour of the forecasting agents with and without overwriting existing forecasts. Hence, 4 containers will be created when running the tests:
- Forecasting Agent, which overwrites existing forecasts when creating new ones
- Forecasting Agent, which does not overwrite existing forecasts (this container also runs pytest)
- Blazegraph and Postgis instances (spun up via Docker in Docker using testcontainers)

```bash
# Build and run dockerised agent tests
docker compose -f "docker-compose-test_dockerised.yml" up -d --build
```

To run the dockerised tests in Debug mode, please run the below script to start up both testing agents and pytest in separate containers (to allow for debugging of the overwriting/non-overwriting forecasting agent versions separately). Subsequently, attach the Debugger(s) using the provided `Python: Debug dockerised tests` and `Python: Debug dockerised agent...` configurations as required (provided in `.vscode` subfolder). Attaching the `Python: Debug dockerised tests` debugger is required to start the tests, while attaching debuggers to both agents under tests are optional:

```bash
# Build and run dockerised agent tests in debug mode
bash run_debug_tests.sh
```

Running the integration tests, will create some forecast error plots in the [test_plots] repository for visual inspection (if wanted); however, these plots will automatically be deleted by the script after finishing all tests.


&nbsp;
# Authors #
Markus Hofmeister (mh807@cam.ac.uk), August 2023

Magnus Mueller (mm2692@cam.ac.uk), November 2022


<!-- Links -->
<!-- websites -->
[allows you to publish and install packages]: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-apache-maven-registry#authenticating-to-github-packages
[CMCL Docker registry wiki page]: https://github.com/cambridge-cares/TheWorldAvatar/wiki/Using-Docker-images
[py4jps]: https://pypi.org/project/py4jps/#description
[TimeSeriesClient]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/timeseries
[Darts]: https://unit8co.github.io/darts/index.html
[Prophet]: https://unit8co.github.io/darts/generated_api/darts.models.forecasting.prophet_model.html
[Facebook Prophet]: https://github.com/facebook/prophet
[Github container registry]: https://ghcr.io
[personal access token]: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
[Derived Information Framework]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/derivation
[Stack manager]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/Deploy/stacks/dynamic/stack-manager
[derivation agent]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/python_derivation_agent

[OntoTimeSeries]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_Ontology/ontology/ontotimeseries
[OntoDerivation]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_Ontology/ontology/ontoderivation

<!-- files -->
[HTTP forecast error request]: ./resources/HTTP_evaluate_errors.http
[model mapping]: ./forecastingagent/fcmodels/model_mapping.py
[docker compose file]: ./docker-compose.yml
[stack manager input config file]: ./stack-manager-input-config/forecasting-agent.json
[stack-manager-input-config]: ./stack-manager-input-config
[test_plots]: tests/test_plots/
