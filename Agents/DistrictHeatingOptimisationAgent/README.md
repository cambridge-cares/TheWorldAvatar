# District Heating Optimisation Agent

This `District Heating Optimisation Agent` can be used to (recurringly) optimise the total heat generation cost for a district heating (DH) system comprised of multiple gas boilers, a gas turbine, and external sourcing from an energy-from-waste (EfW) plant. The implemented optimisation logic is based on the previous SWPS project and detailed in [preprint 275]; however, this implementation leverages the [Derived Information Framework]'s (DIF) `DerivationWithTimeSeries` concept for synchronous derivations. The required input instances for an optimisation are described in the [required derivation markup](#13-required-derivation-markup) section below. The agent is designed to be deployed as a Docker container and can be deployed either as standalone version or as part of a larger Docker stack.

The overall use case relies on both the [OntoHeatNet] and [OntoTimeSeries] ontology and uses [chained derivations] to connect the optimisation inputs and outputs with further agents, e.g., for required heat demand and grid temperature forecasts. Further details about [stack deployment] can be found in the (private) Pirmasens repository.

&nbsp;
# 1. Setup

This section specifies the minimum requirements to build and deploy the Docker image. 


## 1.1 Agent Settings

The dockerised agent can be deployed as "standalone" version (i.e., outside a larger Docker stack) or deployed to an (existing) stack. Several key environment variables need to be set in the
- [docker compose file] for "standalone" deployment
- [stack manager input config file] for deployment using the [Stack manager]

```bash
#--- Deployment specific parameters ---#
# Required for Stack deployment (can be left blank for "standalone" deployment)
NAMESPACE                     # Blazegraph namespace (within Stack) to monitor
DATABASE                      # PostGIS/PostgreSQL database name (default: `postgres`)
# Required for "standalone" deployment (can be left blank for Stack deployment)
STACK_NAME                    # to be left blank for "standalone" deployment
DB_URL                        # PostGIS/PostgreSQL URL
DB_USER                       # PostGIS/PostgreSQL username
DB_PASSWORD                   # PostGIS/PostgreSQL password

#--- Derivation Agent parameters ---#
SPARQL_QUERY_ENDPOINT         # SPARQL endpoint to monitor/update
SPARQL_UPDATE_ENDPOINT        # SPARQL endpoint to monitor/update
ONTOAGENT_SERVICE_IRI         # IRI of OntoAgent service
ONTOAGENT_OPERATION_HTTP_URL  # Port needs to match port specified in `docker-compose.yml`
DERIVATION_INSTANCE_BASE_URL  # Base IRI of all instanced generated by agent
DERIVATION_PERIODIC_TIMESCALE # Interval in which to check for updated KG information (in s)
                              # (irrelevant as DH Optimisation Agent uses synchronous derivations only)
REGISTER_AGENT                # Boolean flag whether to register agent in KG (`true` required to detect derivations)
# Required inputs for DerivationAgent to start, although not relevant for DH Optimisation Agent (i.e., shall be left blank)
KG_USERNAME
KG_PASSWORD
FILE_SERVER_ENDPOINT
FILE_SERVER_USERNAME
FILE_SERVER_PASSWORD
```

The `STACK_NAME` variable is used to identify the deployment mode of the agent: In case the `STACK_NAME` is left blank, Postgres and Blazegraph endpoint settings will be taken from the `docker-compose file` values. Otherwise they will be retrieved using the StackClients based on the provided `NAMESPACE` and `DATABASE` variables.

Please note: 
- When deployed via the Stack manager, the `STACK_NAME` environment variable is set automatically and can be omitted in the config file
- `SPARQL_QUERY_ENDPOINT` and `SPARQL_UPDATE_ENDPOINT` are both required inputs even for stack deployment (due to default derivation agent config); however, as the actual values for initialising the DH Optimisation Agent are retrieved via the Stack Clients, they can be left blank.


## 1.2 Miscellaneous

**Only relevant** if you intend to build (and publish) the Docker image: Ensure access to Github container registry, as
- the required `stack-clients-*.jar` resource to be added to [py4jps] during building the Docker image is retrieved from the published Stack-Clients docker image
- a `publish_docker_image.sh` convenience script is provided to build and publish the agent image to the [Github container registry]. To publish a new image, your github user name and [personal access token] (which must have a `scope` that [allows you to publish and install packages]) needs to be provided. 


## 1.3 Required Derivation Markup

Before any optimisation can be created (and instantiated), all required inputs need to be properly instantiated in the KG. This includes the following 6 instances:
- 1 `time:Interval`: the interval to optimise (i.e., defining start and end time of the optimisation to be created, both bounds inclusive)
- 5 `ts:Forecast`s : time series dataIRIs for the forecasted `ohn:HeatDemand` and 4 `om:Temperature`s, denoting flow and return temperatures at the EfW and municipal heating plant, respectively (the mapping between the provided forecast IRIs and their respective meaning is done internally inside the agent based on associated rdf type and triple patterns)

While the instantiation of the input instances itself is use case specific and beyond the scope of this agent, the instantiation of the required markup is described in the [using the agent](#21-generation-optimisation) section below. Furthermore, an end-to-end example (incl. instantiating all required inputs followed by subsequent optimisation) is provided in the district heating [stack deployment] project in the (private) Pirmasens repository.

Used namespaces:
```xml
time  : http://www.w3.org/2006/time#
ts    : https://www.theworldavatar.com/kg/ontotimeseries/
om    : http://www.ontology-of-units-of-measure.org/resource/om-2/
ohn   : https://www.theworldavatar.com/kg/ontoheatnetwork/
```

&nbsp;
# 2. Using the Agent

The agent is implemented as [derivation agent] using `DerivationWithTimeSeries`. Please note: 1) derivations with time series are currently restricted to synchronous derivations, i.e., derivations which get computed immediately upon request and 2) derivations with time series do not return any specific output triples, as all updates to the time series are expected to be conducted within the agent logic. Initial derivation output triples will only be generated when creating new derivation using `createSyncDerivationForNewInfo`.


## 2.1 Generation Optimisation

The implemented optimisation logic is described in detail in [preprint 275]. To create a new optimisation/or update an existing optimisation derivation, please follow the example below. Please note that the agent needs to be available and registered within the KG beforehand (done automatically on agent startup if specified in the docker-compose/stack-manager config file). The required derivation inputs need to be instantiated according to the [OntoHeatNet] ontology; for a successful derivation design, please see the [chained derivations markup] example.

```bash
# Define IRIs/URL to use
agent_iri = <ONTOAGENT_SERVICE_IRI of target optimisation agent instance>
derivation_instance_base_url = <base url to be used when creating derivation instance>

# Create derivation client
from pyderivationagent import PyDerivationClient
from pyderivationagent.data_model.iris import ONTODERIVATION_DERIVATIONWITHTIMESERIES
deriv_client = PyDerivationClient(derivation_instance_base_url, 
                                  sparql_query_endpoint, sparql_query_endpoint)

# Define set of input instances for new optimisation derivation
derivation_input_set = [
    <IRI of time:Interval instance>, 
    <IRI of ts:Forecast instance of ohn:HeatDemands>, 
    <IRI of ts:Forecast instance of "flow temperature" at EfW plant>
    <IRI of ts:Forecast instance of "return temperature" at EfW plant>
    <IRI of ts:Forecast instance of "flow temperature" at municipal heating plant>
    <IRI of ts:Forecast instance of "return temperature" at municipal heating plant>
]

# Create new optimisation derivation: mark up derivation inputs and 
# immediately compute and instantiate optimisation results (as forecasts)
derivation = deriv_client.createSyncDerivationForNewInfo(agent_iri, 
                          derivation_input_set, ONTODERIVATION_DERIVATIONWITHTIMESERIES)
derivation_iri = derivation.getIri()

# Update existing optimisation derivation
deriv_client.unifiedUpdateDerivation(derivation_iri)
```


Upon successful optimisation, the following results are written back into the KG according to the [OntoHeatNet] ontology:
- `ohn:ProvidedHeatAmount`: heat amount sourced from the EfW plant
- `ohn:GeneratedHeatAmount`: heat amount provided by a certain heat generator, i.e., conventional gas boiler or co-gen gas turbine (instantiated for each heat generator)
- `ohn:ConsumedGasAmount`: gas amount consumed by a certain heat generator to provide the required amount of heat (instantiated for each heat generator)
- `ohn:CoGenElectricityAmount`: amount of co-generated electricty while providing required amount of heat (only relevant for gas turbine)
- `ohn:Availability`: anticipated availability of a certain heat provider (instantiated for each heat generator and EfW plant)

All optimisation outputs are instantiated as `ts:Forecast` instances for the respective concept (i.e., to not interfere with actual historical data instantiated via `om:hasValue` relationships). Newly created optimisation outputs automatically overwrite previously instantiated ones.

Upon first invocation of the agent, historical gas consumption, heat generation, and (if applicable) electricity co-generation data is queried to fit generator specific gas consumption and co-gen models to be used during the optimisation. Those models will be reused for all subsequent optimisation requests.

The agent is designed to handle each optimisation request individually, i.e., indipendent from any previous request. The only exception to this behaviour is when two subsequent requests are exactly +1h apart from one another. In this case, the second request will be considered dependent of the previous one to allow for MPC-style optimisation (i.e., keep track of gas turbine operation and previously accumulated benefit from current gas turbine activity).


## 2.2 Optimisation Evaluation

The agent also provides a separate HTTP endpoint to evaluate the total cost of the optimised vs. historical heat generation. It returns the cumulative generation cost over the entire optimisation interval as well as total and daily potential savings from the optimisation. It is triggered by receiving an empty HTTP `GET` request at the `/compare_cost` route. An example [cost comparison request] is provided.


&nbsp;
# 3. Deploying the Agent


## 3.1 Building the Agent

To build and publish the agent Docker image please use the following commands. Please note that both commands are bundled in the  `publish_docker_image.sh` convenience script.

```bash
# Building the (production) image
docker compose -f docker-compose.yml build
# Publish the Docker image to the Github container registry
docker image push ghcr.io/cambridge-cares/<image tag>:<version>
```


## 3.2 Deploying the Agent

It is recommended to pull the published Docker image from [Github container registry] for sole deployment (i.e., in case no modifications to the agent are needed):

```bash
# Pull published (production) image
docker pull ghcr.io/cambridge-cares/dh-optimisation-agent:1.0.0
```

###  **Standalone Deployment**

Deploy the dockerised agent by running the following command from the same location where this README is located (ideally, use a bash terminal to avoid potential issues with inconsistent path separators). 

```bash
# Deploy the Docker image locally
docker compose -f docker-compose.yml up
```

### **Stack Deployment**

If you want to spin up this agent as part of a stack, do the following:
1) Build OR pull the (production) image using the commands provided above (do not spin up the image)
2) Copy the `dh-optimisation-agent.json` file from the [stack-manager-input-config] folder into the `inputs/config/services` folder of the stack manager
3) Add the service to a corresponding stack configuration json in `inputs/config` folder
4) Start the stack manager as usual (i.e. `bash ./stack.sh start <STACK_NAME>` from the stack-manager repo). This should start the container. Please use a bash terminal to avoid potential issues with inconsistent path separators.


## 3.3 Notes on Debugging

To debug the agent within the stack, follow these steps (a similar approach should work for the standalone version)

1) Overwrite command specified in Dockerfile by providing `tail -f /dev/null` `Command` in stack-manager config file (this keeps the container alive indefinitely while doing nothing). An amended `dh-optimisation-agent-debug.josn` config is provided in the [stack-manager-input-config] folder.
2) Start stack-manager as usual
3) Right click on running agent container -> select "Attach Visual Studio Code"
4) Install required VSCode extensions inside the container (i.e., Python)
5) Start local debugging session inside container by running `entry_point.py` in debug mode
6) Follow instructions in [debug script] to create a new optimisation derivation in debug mode

**Please note**:
- This approach also works for already running agent containers; however, the port number in `entry_point.py` needs to be changed before starting a second agent instance for debugging
- After debugging, the instantiated agent URL needs to be reset to the original in case the non-debug agent instance is required again


&nbsp;
# Authors #
Markus Hofmeister (mh807@cam.ac.uk), November 2023


<!-- Links -->
<!-- websites -->
[allows you to publish and install packages]: https://docs.github.com/en/packages/working-with-a-github-packages-registry/working-with-the-apache-maven-registry#authenticating-to-github-packages
[py4jps]: https://pypi.org/project/py4jps/#description
[Github container registry]: https://ghcr.io
[personal access token]: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens
[Derived Information Framework]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/src/main/java/uk/ac/cam/cares/jps/base/derivation
[Stack manager]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/Deploy/stacks/dynamic/stack-manager
[derivation agent]: https://github.com/cambridge-cares/TheWorldAvatar/tree/main/JPS_BASE_LIB/python_derivation_agent
[preprint 275]: https://como.ceb.cam.ac.uk/preprints/275/
[chained derivations]: https://lucid.app/publicSegments/view/a00b553e-d9d1-4845-97b7-f480e980898e/image.png
[chained derivations markup]: https://lucid.app/publicSegments/view/de4041e1-aee2-44d9-82ca-fffca25f5133/image.png
[OntoTimeSeries]: https://miro.com/app/board/uXjVPFaO5As=/
[OntoHeatNet]: https://miro.com/app/board/uXjVOhnB9_4=/
[stack deployment]: https://github.com/cambridge-cares/pirmasens/tree/main/districtheating_stack

<!-- files -->
[docker compose file]: ./docker-compose.yml
[stack manager input config file]: ./stack-manager-input-config/dh-optimisation-agent.json
[stack-manager-input-config]: ./stack-manager-input-config
[debug script]: ./dhoptimisation/debug_script.py
[cost comparison request]: ./dhoptimisation/resources/cost_request.http
