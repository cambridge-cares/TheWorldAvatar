import os
import json
from openai import OpenAI
import utils
import parameters as para
import json_schemas as jschem
import llm_prompts as llmp
import secrets.secret_parameter as spara

class ChatGPTAPI:
    """
    A class to interact with the OpenAI API for generating structured and unstructured responses.

    Attributes:
    api_key (str): The API key for OpenAI authentication.
    client (OpenAI): The OpenAI client instance for making API calls.
    """
    
    def __init__(self):
        """
        Initializes the ChatGPTAPI class by setting up the OpenAI client with the API key.
        """
        self.api_key    = spara.API_KEY                 # Retrieve the API key from a configuration module  
        self.client     = OpenAI(api_key=self.api_key)  # Initialize the OpenAI client

    def make_llm_call(self, message):
        """
        Makes an API call to OpenAI's chat model for generating a free-form response.

        Parameters:
        message (list): A list of message dictionaries in OpenAI's chat format, containing
                        system, user, and assistant roles.

        Returns:
        str: The content of the first response message generated by the model.
        """
        response = self.client.chat.completions.create(
        model=para.MODEL_NAME,                          # Specify the model name
        messages=message,                               # Provide the conversation history
        temperature=0.2,                                # Controls randomness (lower value = more deterministic)
        top_p=0.1                                       # Limits the probability mass selection for more focused responses
              )
        return response.choices[0].message.content      # Extract and return the response text
    
    def make_llm_call_structured(self, prompt, schema):
        """
        Makes an API call to OpenAI's chat model for generating a structured JSON response.

        Parameters:
        prompt (str): The input prompt to be processed by the model.
        schema (dict): The expected response schema for structuring the output.

        Returns:
        str: The structured JSON response as a string.
        """
        # Construct the message list for the structured API call
        message     =[
        {"role": "system","content": "You will be provided with unstructured data, and your task is to parse it into json format."},
        {"role": "user", "content": prompt} ]   
        response    = self.client.chat.completions.create(
        model=para.MODEL_NAME,                              # Specify the model name
        response_format=schema,                             # Apply the provided schema for structured output
        messages=message,                                   # Provide the conversation input
        temperature=0.2,                                    # Controls randomness for structured responses
        top_p=0.1                                           # Limits probability mass selection for precise output
              )
        return response.choices[0].message.content          # Extract and return the structured response


def extract_chemicals(file_path, output_dir):
    """
    Extracts chemical information from a given synthesis text file using an LLM-based structured response.
    
    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted chemical data will be saved.
    
    Returns:
    None: The function writes the extracted data to a JSON file in the specified output directory.
    """
    # Extract the DOI (Digital Object Identifier) from the file path
    doi                                 = utils.doi_from_path(file_path)
    # Read the content of the synthesis text file
    with open(file_path, "r", encoding="utf-8") as file:
      file_content                      = file.read()
    # Generate a prompt using the DOI to provide context for the LLM
    prompt                              = llmp.chemical_prompt(doi)
    # Construct the full prompt by appending the synthesis text content
    full_prompt                         = f"{prompt}\n\n{file_content}"
    # Initialize the ChatGPT API client
    chatgpt_api                         = ChatGPTAPI()
    # Retrieve the expected chemical data schema for structuring the response
    schema                              = jschem.chemical_schema()
    # Make an LLM call with the structured prompt and schema
    response                            = chatgpt_api.make_llm_call_structured(full_prompt, schema)
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                = doi.replace("/", "_")
    # Write the extracted chemical information to a JSON file in the specified output directory
    with open(output_dir+"/"+name+".json", "w", encoding="utf-8") as txt_file:
        txt_file.write(response) 

def extract_steps(file_path, output_dir):
    """
    Extracts synthesis steps from a given text file using an LLM-based structured response.

    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted step data will be saved.

    Returns:
    None: The function writes the extracted synthesis steps to a JSON file in the specified output directory.
    """
    # Extract the DOI (Digital Object Identifier) from the file path
    doi                                 = utils.doi_from_path(file_path) 
    # Read the synthesis text file content      
    with open(file_path, "r", encoding="utf-8") as file:
            file_content                = file.read()
    # Retrieve the schema for extracting expected step types
    schema_adaptive                     = jschem.adaptive_schema()
    # Generate a prompt string to guide the LLM in identifying synthesis step types
    prompt_step_types                   = llmp.step_types_prompt()
    # Combine the prompt with the synthesis text for context
    adaptive_prompt                     = f"{prompt_step_types}\n\n{file_content}"
    # Initialize the ChatGPT API client
    chatgpt_api                         = ChatGPTAPI()
    # Make an API call to extract the relevant step types from the synthesis text
    response                            = chatgpt_api.make_llm_call_structured(adaptive_prompt, schema_adaptive)
    # Parse the JSON response to obtain dynamic step types
    dynamic_prompt                      = json.loads(response)
    # Generate an updated prompt incorporating the extracted step types
    prompt                              = llmp.step_prompt(doi, dynamic_prompt)
    # Append the synthesis text to the updated prompt
    full_prompt                         = f"{prompt}\n\n{file_content}"
    # Retrieve the schema for extracting detailed step information based on the identified step types
    schema                              = jschem.step_schema(dynamic_prompt)
    # Make another LLM call to extract detailed synthesis steps
    response_steps                      = chatgpt_api.make_llm_call_structured(full_prompt, schema)
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                                = doi.replace("/", "_")
    # Write the extracted synthesis steps to a JSON file in the specified output directory
    with open(output_dir+"/"+name+".json", "w", encoding="utf-8") as txt_file:
        txt_file.write(response_steps) 

def extract_pre_steps(file_path, output_dir):
    """
    Extracts pre-synthesis steps from a given text file using an LLM-based structured response.

    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted pre-steps text will be saved.

    Returns:
    None: The function writes the extracted pre-steps text to a file in the specified output directory.
    """
    # Extract the DOI (Digital Object Identifier) from the file path
    doi                                 = utils.doi_from_path(file_path)   
    # Read the synthesis text file content     
    with open(file_path, "r", encoding="utf-8") as file:
            file_content                = file.read()
    # Initialize the ChatGPT API client
    chatgpt_api                         = ChatGPTAPI()
    # Generate a predefined prompt for extracting pre-synthesis steps (without dynamic modification)
    prompt                              = llmp.pre_steps_prompt()
    # Combine the prompt with the synthesis text for context
    full_prompt                         = f"{prompt}\n\n{file_content}"
    # Construct the message structure for the LLM API request
    messages    =[
      {"role": "system","content": "You will be provided with synthesis text and your task is to extract text based on the instruction."},
      {"role": "user", "content": full_prompt} ]
    # Make an API call to extract the pre-synthesis steps
    response                            = chatgpt_api.make_llm_call(messages)    
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                = doi.replace("/", "_")
    # Write the extracted pre-steps text to a file in the specified output directory
    with open(output_dir+"/"+name+".txt", "w", encoding="utf-8") as txt_file:
        txt_file.write(response) 

def extract_procedure(file_path, output_dir):
    """
    Extracts the procedural steps from a given synthesis text file using an LLM-based structured response.

    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted procedure text will be saved.

    Returns:
    None: The function writes the extracted procedure to a text file in the specified output directory.
    """
    # Extract the DOI (Digital Object Identifier) from the file path
    doi                         = utils.doi_from_path(file_path)  
    # Read the content of the synthesis text file          
    with open(file_path, "r", encoding="utf-8") as file:
            file_content        = file.read()
    # Generate a prompt to guide the LLM in extracting procedure-related information
    prompt                      = llmp.procedure_prompt(doi)
    # Combine the prompt with the synthesis text for context
    full_prompt                 = f"{prompt}\n\n{file_content}"
    # Construct the message structure for the LLM API request
    messages    =[
      {"role": "system","content": "You will be provided with synthesis text and your task is to extract text based on the instruction."},
      {"role": "user", "content": full_prompt} ]
    # Initialize the ChatGPT API client
    chatgpt_api                 = ChatGPTAPI()
    # Make an API call to extract the procedure from the synthesis text
    response                    = chatgpt_api.make_llm_call(messages)
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                = doi.replace("/", "_")
    # Write the extracted procedure to a text file in the specified output directory
    with open(f"{output_dir}/{name}.txt", "w", encoding="utf-8") as txt_file:
        txt_file.write(response) 
        
def extract_cbu(file_path, output_dir):
    """
    Extracts chemical building unit (CBU) information from a given synthesis text file 
    using an LLM-based structured response.

    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted CBU data will be saved.

    Returns:
    None: The function writes the extracted CBU data to a JSON file in the specified output directory.
          If the prompt generation is unsuccessful, the function exits without writing a file.
    """

    # Extract the DOI (Digital Object Identifier) from the file path
    doi                         = utils.doi_from_path(file_path)   
    # Read the content of the synthesis text file         
    with open(file_path, "r", encoding="utf-8") as file:
            file_content        = file.read()
    # Generate a prompt for extracting CBU-related information
    # The function returns a success flag, so the process is only continued if successful
    prompt, successful          = llmp.cbu_prompt(doi)
    if not successful:
        return                  # Exit the function if the prompt generation was not successful
    # Initialize the ChatGPT API client
    chatgpt_api                 = ChatGPTAPI()
    # Retrieve the schema defining the expected structure of the CBU extraction response
    schema                      = jschem.cbu_schema()
    # Make an LLM API call to extract the CBU details in a structured format
    response                    = chatgpt_api.make_llm_call_structured(prompt, schema)
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                = doi.replace("/", "_")
    # Write the extracted CBU data to a JSON file in the specified output directory
    with open(f"{output_dir}/{name}.json", "w", encoding="utf-8") as txt_file:
        txt_file.write(response) 

def extract_characterization(file_path, output_dir):
    """
    Extracts characterization data from a given synthesis text file using an LLM-based structured response.

    Parameters:
    file_path (str): The path to the synthesis text file.
    output_dir (str): The directory where the extracted characterization data will be saved.

    Returns:
    None: The function writes the extracted characterization data to a JSON file in the specified output directory.
    """
    # Extract the DOI (Digital Object Identifier) from the file path
    doi                         = utils.doi_from_path(file_path)  
    # Read the content of the synthesis text file        
    with open(file_path, "r", encoding="utf-8") as file:
      file_content        = file.read()
    # Initialize the ChatGPT API client
    chatgpt_api             = ChatGPTAPI()
    # Generate a prompt to extract characterization-related information using the DOI
    prompt                  = llmp.characterisation_prompt(doi)
    # Combine the prompt with the synthesis text for context
    full_prompt             = f"{prompt}\n\n{file_content}"
    # Retrieve the schema defining the expected structure of the characterization response
    schema                  = jschem.characterisation_schema
    # Make an API call to extract the characterization data in a structured format
    response                = chatgpt_api.make_llm_call_structured(full_prompt, schema)
    # Generate a valid filename from the DOI by replacing slashes with underscores
    name                = doi.replace("/", "_")
    # Write the extracted characterization data to a JSON file in the specified output directory
    with open(output_dir+"/"+name+".json", "w", encoding="utf-8") as txt_file:
        txt_file.write(response) 
